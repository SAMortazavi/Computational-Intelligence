{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jUzakkgkZCDO"
      },
      "source": [
        "# Deep learning model compression for agricultural devices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "FNu1tg3ZRHlx",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import tempfile\n",
        "import zipfile\n",
        "from __future__ import division, print_function, absolute_import\n",
        "from keras.models import Sequential,Model\n",
        "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers.convolutional import Conv2D, MaxPooling2D, AveragePooling2D\n",
        "\n",
        "from keras.optimizers import SGD\n",
        "import numpy as np\n",
        "import cv2\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "id": "eqzv6-Dyy2MA",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "from keras.layers import BatchNormalization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        },
        "id": "o-OWt9Qde6xm",
        "outputId": "6b3f0c0e-a855-4581-ad3d-b890ca08cd68",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "7yQuhZH_jpJM"
      },
      "source": [
        "# DATA"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Quyan36mwizz"
      },
      "source": [
        "## This code load dataset from googleDrinve"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "id": "eBeKsd-UhuO0",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "import zipfile, os\n",
        "zip_ref = zipfile.ZipFile('/content/train.zip', 'r')\n",
        "zip_ref.extractall('Data')\n",
        "zip_ref.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6CS8oKhyPBKr"
      },
      "source": [
        "return the content of the dataset\n",
        "\n",
        "Traning images and labels, test images and labes, and and the number of class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "id": "KXBGV7haeqT1",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "def load_dataset(rootDir):\n",
        "    root=rootDir\n",
        "    folders = os.listdir(root)\n",
        "    nb = len(folders)\n",
        "    x_data=[]\n",
        "    y_label=[]\n",
        "    xt_data=[]\n",
        "    yt_label=[]\n",
        "    for x in range(nb):\n",
        "        label=np.zeros(nb)\n",
        "        label[x]=1\n",
        "        PlantPath=os.listdir(root+\"/\"+folders[x])\n",
        "        plants=[root+\"/\"+folders[x]+\"/\"+f for f in PlantPath if (f.endswith(\".png\") or f.endswith(\".jpg\") or f.endswith(\".JPG\"))]\n",
        "        i=0\n",
        "        for plant in plants:\n",
        "            imgs=cv2.imread(plant)\n",
        "            imgs= cv2.resize(imgs,(50,50))\n",
        "            if(i%5==0):\n",
        "                xt_data.extend([imgs])\n",
        "                yt_label.extend([label])\n",
        "            else:\n",
        "                x_data.extend([imgs])\n",
        "                y_label.extend([label])\n",
        "            i=i+1\n",
        "    return (np.asarray(x_data), np.asarray(y_label), np.asarray(xt_data), np.asarray(yt_label), nb)\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "gi_xqKOhiqnr"
      },
      "source": [
        "# Pruning CallBack"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "id": "qqryqcNoiqOv",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "class PruningCallback(tf.keras.callbacks.Callback):\n",
        "\tdef __init__(self, init_step, end_step, init_sparsity, end_sparsity, pruning_step):\n",
        "\t\tself.init_step=init_step; self.end_step=end_step\n",
        "\t\tself.init_sparsity=init_sparsity; self.end_sparsity=end_sparsity\n",
        "\t\tself.pruning_step=pruning_step\n",
        "\t\tself.W_mask=[]\n",
        "\t\tsuper().__init__()\n",
        "\tdef on_train_begin(self, logs=None):\n",
        "\t\tfor layer in self.model.layers:\n",
        "\t\t\tif(\"filters\" in layer.get_config()):\n",
        "\t\t\t\tself.W_mask.append(np.ones(layer.get_weights()[0].shape))\n",
        "\t\t\n",
        "\tdef decayed_sparsity_level(self,step):\n",
        "\t\tstep = min(step-self.init_step, self.end_step)\n",
        "\t\treturn ((self.init_sparsity-self.end_sparsity) *\n",
        "          (1 - step / (self.end_step-self.init_step)) ** (1)\n",
        "          ) + self.end_sparsity\n",
        "\n",
        "\tdef on_epoch_end(self, epoch, logs={}):\n",
        "\t\tif((epoch)%self.pruning_step==0 and (epoch)>=self.init_step and (epoch)<=self.end_step):\n",
        "\t\t\tprint('\\n pruning [', end=' ')\n",
        "\t\ti=0\n",
        "\t\tlayers=self.model.layers\n",
        "\t\tfor l in range(len(layers)):\n",
        "\t\t\tif(\"filters\" in layers[l].get_config()):\n",
        "\t\t\t\tw_m=tf.convert_to_tensor(self.W_mask[i], dtype=tf.float32)\n",
        "\t\t\t\tw_l=tf.convert_to_tensor(self.model.layers[l].get_weights()[0], dtype=tf.float32)\n",
        "\t\t\t\tw_l2=tf.multiply(w_m,w_l).numpy()\n",
        "\t\t\t\tb=self.model.layers[l].get_weights()[1]\n",
        "\t\t\t\tself.model.layers[l].set_weights([w_l2,b])\n",
        "\t\t\t\t#Pruninf\n",
        "\t\t\t\tprint('=', end=' ')\n",
        "\t\t\t\tif((epoch)%self.pruning_step==0  and (epoch)>=self.init_step and (epoch)<=self.end_step):\n",
        "\t\t\t\t\tfilters_sum=np.abs(tf.reduce_sum(w_l2, [0, 1, 2]).numpy())\n",
        "\t\t\t\t\tWs=tf.sort(filters_sum,  axis=-1, direction='ASCENDING', name=None).numpy()\n",
        "\t\t\t\t\tstep_sparsty=self.decayed_sparsity_level(epoch)\n",
        "\t\t\t\t\tthreshold=Ws[int(len(Ws)*step_sparsty)]\n",
        "\t\t\t\t\te=np.where(filters_sum <= threshold)\n",
        "\t\t\t\t\te=np.array(e).reshape(-1)\n",
        "\t\t\t\t\tfor ex in e:\n",
        "\t\t\t\t\t\tif(len(self.W_mask[i].shape)==4):\n",
        "\t\t\t\t\t\t\tself.W_mask[i][:,:,:,ex]=0\n",
        "\t\t\t\t\t\t\tb[ex]=0\n",
        "\t\t\t\t#setting weights\n",
        "\t\t\t\tw_m=tf.convert_to_tensor(self.W_mask[i], dtype=tf.float32)\n",
        "\t\t\t\tw_l2=tf.multiply(w_m,w_l).numpy()\n",
        "\t\t\t\ti=i+1\n",
        "\t\t\t\tself.model.layers[l].set_weights([w_l2,b])\n",
        "\t\t\t\t\n",
        "\t\t\tif  isinstance(layers[l], tf.keras.layers.Dense):\n",
        "\t\t\t\tw_l=layers[l].get_weights()[0]\n",
        "\t\t\t\tbias=layers[l].get_weights()[1]\n",
        "\t\t\t\ts_mask=tf.reduce_sum(self.W_mask[-1], [0, 1, 2]).numpy()\n",
        "\t\t\t\tindx=np.where(s_mask ==0.)\n",
        "\t\t\t\tindx=np.array(indx).reshape(-1)\n",
        "\t\t\t\tli=int(w_l.shape[0]/len(s_mask))\n",
        "\t\t\t\tind_fc=[]\n",
        "\t\t\t\tfor ind in indx:\n",
        "\t\t\t\t\tx=np.arange(li*ind, li*(ind+1))\n",
        "\t\t\t\t\tind_fc.append(x)\n",
        "\t\t\t\tind_fc=np.array(ind_fc).reshape(-1)\n",
        "\t\t\t\tfor ind_fc_ in ind_fc:\n",
        "\t\t\t\t\tw_l[ind_fc_,:]=0\n",
        "\t\t\t\tself.model.layers[l].set_weights([w_l,bias])\n",
        "\t\t\n",
        "\t\t\tif isinstance(layers[l], tf.keras.layers.BatchNormalization):\n",
        "\t\t\t\tw_l=layers[l].get_weights()\n",
        "\t\t\t\ts_mask=tf.reduce_sum(self.W_mask[i-1], [0, 1, 2]).numpy()\n",
        "\t\t\t\tindx=np.where(s_mask ==0.)\n",
        "\t\t\t\tindx=np.array(indx).reshape(-1)\n",
        "\t\t\t\tfor ind in indx:\n",
        "\t\t\t\t\tw_l[0][ind]=0\n",
        "\t\t\t\t\tw_l[1][ind]=0\n",
        "\t\t\t\t\tw_l[2][ind]=0\n",
        "\t\t\t\t\tw_l[3][ind]=0\n",
        "\t\t\t\tself.model.layers[l].set_weights(w_l)\n",
        "\t\t\n",
        "\t\tif((epoch)%self.pruning_step==0 and (epoch)>=self.init_step and (epoch)<=self.end_step):\n",
        "\t\t\tprint(']')\n",
        "\t\n",
        "\t#Transfert create a new model without pruned filters \n",
        "\tdef get_thinner_model(self):\n",
        "\t\toriginal_model=self.model\n",
        "\t\tW_mask=self.W_mask\n",
        "\t\tself.preview=[3]\n",
        "\t\tself.mask_ind=[0]\n",
        "\t\tcompressed_model = tf.keras.models.clone_model(original_model,\tclone_function=self.build_compressed_CNN,)\n",
        "\t\tself.preview_w=[[0,1,2]]\n",
        "\t\tcompressed_model.compile(loss=tf.keras.losses.categorical_crossentropy, optimizer=\"sgd\", metrics=['accuracy'])\n",
        "\t\tmask_i=0\n",
        "\t\tfor l_index in range( len(original_model.layers)):\n",
        "\t\t\tlayer=original_model.layers[l_index]\n",
        "\t\t\tif isinstance(layer, tf.keras.layers.Conv2D):\n",
        "\t\t\t\tw_l=layer.get_weights()[0]\n",
        "\t\t\t\tbias=layer.get_weights()[1]\n",
        "\t\t\t\tfilters_sum=np.abs(tf.reduce_sum(w_l, [0, 1, 2]).numpy())\n",
        "\t\t\t\tindx=np.where(filters_sum !=0.)\n",
        "\t\t\t\tindxz=np.array(np.where(filters_sum ==0.)).reshape(-1)\n",
        "\t\t\t\tindx=np.array(indx).reshape(-1)\n",
        "\t\t\t\tif (l_index!=0):\n",
        "\t\t\t\t\tw_l=w_l[:,:,self.preview_w[-1],:]\n",
        "\t\t\t\tw_l_r=w_l[:,:,:,indxz]\n",
        "\t\t\t\tw_l=w_l[:,:,:,indx]\n",
        "\t\t\t\tprint(w_l.shape)\n",
        "\t\t\t\tprint(np.sum(w_l), np.sum(w_l_r))\n",
        "\t\t\t\tself.preview_w.append(indx)\n",
        "\t\t\t\tbias=np.array([bias[i] for i in indx])\n",
        "\t\t\t\tcompressed_model.layers[l_index].set_weights([w_l,bias])\n",
        "\t\t\t\tmask_i=mask_i+1\n",
        "\t\t\tif isinstance(layer, tf.keras.layers.BatchNormalization):\n",
        "\t\t\t\tw_l=layer.get_weights()\n",
        "\t\t\t\t#print(w_l)\n",
        "\t\t\t\tw_l[0]=np.array([w_l[0][i] for i in self.preview_w[-1]])\n",
        "\t\t\t\tw_l[1]=np.array([w_l[1][i] for i in self.preview_w[-1]])\n",
        "\t\t\t\tw_l[2]=np.array([w_l[2][i] for i in self.preview_w[-1]])\n",
        "\t\t\t\tw_l[3]=np.array([w_l[3][i] for i in self.preview_w[-1]])\n",
        "\t\t\t\tcompressed_model.layers[l_index].set_weights(w_l)\n",
        "\t\t\tif isinstance(layer, tf.keras.layers.Dense):\n",
        "\t\t\t\tw_l=layer.get_weights()[0]\n",
        "\t\t\t\tbias=layer.get_weights()[1]\n",
        "\t\t\t\ts_mask=tf.reduce_sum(self.W_mask[-1], [0, 1, 2]).numpy()\n",
        "\t\t\t\tindx=np.where(s_mask !=0.)\n",
        "\t\t\t\tindx=np.array(indx).reshape(-1)\n",
        "\t\t\t\tw_l=w_l.reshape(-1,len(s_mask),len(bias))\n",
        "\t\t\t\tw_l=w_l[:,indx,:]\n",
        "\t\t\t\tw_l=w_l.reshape(-1,len(bias))\n",
        "\t\t\t\tcompressed_model.layers[l_index].set_weights([w_l,bias])\n",
        "\t\treturn compressed_model\n",
        "\n",
        "\t#buld\n",
        "\tdef build_compressed_CNN(self,layer):\n",
        "\t\tif isinstance(layer, tf.keras.layers.Conv2D):\n",
        "\t\t\tw_l=layer.get_weights()[0]\n",
        "\t\t\tfilters_sum=np.abs(tf.reduce_sum(self.W_mask[self.mask_ind[-1]], [0, 1, 2]).numpy())\n",
        "\t\t\tindx=np.where(filters_sum !=0.)\n",
        "\t\t\tindx=np.array(indx).reshape(-1)\n",
        "\t\t\tself.mask_ind.append(self.mask_ind[-1]+1)\n",
        "\t\t\tinput_shape=layer.input_shape\n",
        "\t\t\tinput_s=(input_shape[0],input_shape[1],input_shape[2], self.preview[-1])\n",
        "\t\t\tl=tf.keras.layers.Conv2D(len(indx), 3, padding='same', trainable=False, activation=layer.activation, input_shape=input_s, kernel_regularizer='l2')\n",
        "\t\t\tself.preview.append(len(indx))\n",
        "\t\t\treturn l\n",
        "\t\tif isinstance(layer, tf.keras.layers.BatchNormalization):\n",
        "\t\t\treturn tf.keras.layers.BatchNormalization()\n",
        "\t\tif isinstance(layer, tf.keras.layers.Dense):\n",
        "\t\t\treturn tf.keras.layers.Dense(nb_classes, activation='softmax', trainable=False)\n",
        "\t\tif isinstance(layer, tf.keras.layers.MaxPool2D):\n",
        "\t\t\treturn tf.keras.layers.MaxPooling2D((2, 2), (2, 2), padding='same')\n",
        "\t\tif isinstance(layer, tf.keras.layers.AveragePooling2D):\n",
        "\t\t\treturn tf.keras.layers.AveragePooling2D()\n",
        "\t\tif isinstance(layer, tf.keras.layers.Flatten):\n",
        "\t\t\treturn tf.keras.layers.Flatten()\n",
        "\t\treturn layer\n",
        "\t\t\t\t"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# building compressed CNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "id": "C2m-vfLaxEHV",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "def build_compressed_CNN(layer):\n",
        "  if isinstance(layer, tf.keras.layers.Conv2D):\n",
        "    w_l=layer.get_weights()[0]\n",
        "    #print(W_mask[mask_ind[-1]].shape)\n",
        "    filters_sum=np.abs(tf.reduce_sum(W_mask[mask_ind[-1]], [0, 1, 2]).numpy())\n",
        "    indx=np.where(filters_sum !=0.)\n",
        "    indx=np.array(indx).reshape(-1)\n",
        "    mask_ind.append(mask_ind[-1]+1)\n",
        "    input_shape=layer.input_shape\n",
        "    input_s=(input_shape[0],input_shape[1],input_shape[2], preview[-1])\n",
        "    l=tf.keras.layers.Conv2D(len(indx), 3, padding='same', trainable=False, activation=layer.activation, input_shape=input_s, kernel_regularizer='l2')\n",
        "    preview.append(len(indx))\n",
        "    return l\n",
        "  if isinstance(layer, tf.keras.layers.BatchNormalization):\n",
        "    return tf.keras.layers.BatchNormalization()\n",
        "  if isinstance(layer, tf.keras.layers.Dense):\n",
        "    return tf.keras.layers.Dense(nb_classes, activation='softmax', trainable=False)\n",
        "  if isinstance(layer, tf.keras.layers.MaxPool2D):\n",
        "    return tf.keras.layers.MaxPooling2D((2, 2), (2, 2), padding='same')\n",
        "  if isinstance(layer, tf.keras.layers.AveragePooling2D):\n",
        "    return tf.keras.layers.AveragePooling2D()\n",
        "  if isinstance(layer, tf.keras.layers.Flatten):\n",
        "    return tf.keras.layers.Flatten()\n",
        "  return layer"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# transfering model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "id": "RIc4af6CqWKn",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "def transfert_weights(original_model, compressed_model):\n",
        "  preview_w=[[0,1,2]]\n",
        "  compressed_model.compile(loss=tf.keras.losses.categorical_crossentropy, optimizer=\"sgd\", metrics=['accuracy'])\n",
        "  mask_i=0\n",
        "  for l_index in range( len(original_model.layers)):\n",
        "    layer=original_model.layers[l_index]\n",
        "    if isinstance(layer, tf.keras.layers.Conv2D):\n",
        "      w_l=layer.get_weights()[0]\n",
        "      bias=layer.get_weights()[1]\n",
        "      filters_sum=np.abs(tf.reduce_sum(W_mask[mask_i], [0, 1, 2]).numpy())\n",
        "      indx=np.where(filters_sum !=0.)\n",
        "      indx=np.array(indx).reshape(-1)\n",
        "      if (l_index!=0):\n",
        "        w_l=np.array([w_l[:,:,i,:] for i in preview_w[-1]])\n",
        "      w_l=np.array([w_l[:,:,:,i] for i in indx]).T\n",
        "      preview_w.append(indx)\n",
        "      print(\"w \", w_l.shape)\n",
        "      bias=np.array([bias[i] for i in indx])\n",
        "      compressed_model.layers[l_index].set_weights([w_l,bias])\n",
        "      mask_i=mask_i+1\n",
        "    if isinstance(layer, tf.keras.layers.BatchNormalization):\n",
        "      w_l=layer.get_weights()\n",
        "      print(w_l)\n",
        "      w_l[0]=np.array([w_l[0][i] for i in preview_w[-1]])\n",
        "      w_l[1]=np.array([w_l[1][i] for i in preview_w[-1]])\n",
        "      w_l[2]=np.array([w_l[2][i] for i in preview_w[-1]])\n",
        "      w_l[3]=np.array([w_l[3][i] for i in preview_w[-1]])\n",
        "      compressed_model.layers[l_index].set_weights(w_l)\n",
        "    if isinstance(layer, tf.keras.layers.Dense):\n",
        "      w_l=layer.get_weights()[0]\n",
        "      bias=layer.get_weights()[1]\n",
        "      s_mask=tf.reduce_sum(W_mask[-1], [0, 1, 2]).numpy()\n",
        "      indx=np.where(s_mask !=0.)\n",
        "      indx=np.array(indx).reshape(-1)\n",
        "      li=int(w_l.shape[0]/len(s_mask))\n",
        "      ind_fc=[]\n",
        "      for ind in indx:\n",
        "        x=np.arange(li*ind, li*(ind+1))\n",
        "        ind_fc.append(x)\n",
        "      ind_fc=np.array(ind_fc).reshape(-1)\n",
        "      w_l=np.array([w_l[i] for i in ind_fc])\n",
        "      print(w_l)\n",
        "      compressed_model.layers[l_index].set_weights([w_l,bias])\n",
        "  return compressed_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "id": "2115jfi_r4O5",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "\n",
        "class ModelProfiler():\n",
        "  def cuntPrunedWith(self, model):\n",
        "    ind_x,ind_0=0,0\n",
        "    layers=model.layers\n",
        "    for layer in layers:\n",
        "      i1,i2=self.cuntLayerPrunedWith(layer)\n",
        "      ind_x,ind_0=ind_x+i1,ind_0+i2\n",
        "    return ind_x, ind_0\n",
        "\n",
        "  def cuntPrunedWithArry(self, model):\n",
        "    ind_x,ind_0,ind_t=[],[],[]\n",
        "    layers=model.layers\n",
        "    for layer in layers:\n",
        "      i1,i2=self.cuntLayerPrunedWith(layer)\n",
        "      ind_x.append(i1);ind_0.append(i2), ind_t.append(i1+i2)\n",
        "    return np.array(ind_t),np.array(ind_x), np.array(ind_0)\n",
        "\n",
        "  def cuntLayerPrunedWith(self, layer):\n",
        "    ind_x,ind_0=0,0\n",
        "    if(layer.get_weights()==[]):\n",
        "      return 0,0\n",
        "    w_l=layer.get_weights()\n",
        "    for w in w_l:\n",
        "      ind_x+=np.where(np.abs(w) > 0.)[0].shape[0]\n",
        "      ind_0+=np.where(w == 0.)[0].shape[0]\n",
        "    return ind_x, ind_0"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "sh-RA0Aqw6KY"
      },
      "source": [
        "# AlexNet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "id": "YyMnhKIIratm",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "def alexnet(nb_classes=38, input_shape=[]):\n",
        "    l = tf.keras.layers\n",
        "    input_shape=(50,50,3)\n",
        "    model = tf.keras.Sequential([\n",
        "                                 l.Conv2D( 64, 3, padding='same', activation='relu', input_shape=input_shape),\n",
        "                                 l.MaxPooling2D((2, 2), (2, 2), padding='same'),\n",
        "                                 l.BatchNormalization(),\n",
        "                                 \n",
        "                                 l.Conv2D( 128, 3, padding='same', activation='relu', input_shape=input_shape),\n",
        "                                 l.MaxPooling2D((2, 2), (2, 2), padding='same'),\n",
        "                                 l.BatchNormalization(),\n",
        "\n",
        "                                 l.Conv2D( 192, 3, padding='same', activation='relu', input_shape=input_shape),\n",
        "                                 l.MaxPooling2D((2, 2), (2, 2), padding='same'),\n",
        "                                 l.BatchNormalization(),\n",
        "\n",
        "                                 l.Conv2D( 256, 3, padding='same', activation='relu', input_shape=input_shape),\n",
        "                                 l.MaxPooling2D((2, 2), (2, 2), padding='same'),\n",
        "                                 l.BatchNormalization(),\n",
        "                                 l.AveragePooling2D(),\n",
        "                                 \n",
        "                                 l.Flatten(),\n",
        "                                 \n",
        "                                 l.Dense(nb_classes, activation='softmax')\n",
        "                                 ])\n",
        "    return model\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "This code defines a function called \"alexnet\" that creates a \n",
        "convolutional neural network (CNN) architecture inspired by \n",
        "the AlexNet architecture. The function takes in two optional parameters: \"nb_classes\" which is the number of classes the model will classify, and \"input_shape\" which is the shape of the input images. The default value for \"nb_classes\" is set to 38, and the input_shape is set to be 50x50x3.\n",
        "The code creates a new instance of a Sequential model from \n",
        "the TensorFlow's Keras library, which is a linear stack of \n",
        "layers. The code then adds several layers to the model:\n",
        "\n",
        "- Four 2D convolutional layers with 64, 128, 192, and 256 filters respectively. Each layer has a kernel size of 3x3 and uses \"same\" padding, which means that the output feature map has the same size as the input. The activation function used is \"relu\".\n",
        "- Four max pooling layers, each with a pool size of 2x2 and a stride of 2x2.\n",
        "- Four BatchNormalization layers.\n",
        "- An average pooling layer\n",
        "- A flatten layer\n",
        "- A dense layer with nb_classes units, using a 'softmax' activation function.\n",
        "\n",
        "\n",
        "\n",
        "The function then returns the model.\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mHI_dzJDZ5fX"
      },
      "source": []
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "GdrKYGQ-ixhs"
      },
      "source": [
        "# Init and train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0zG86f0v4Vr5"
      },
      "source": [
        "simple model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "id": "ev0RiuK6Oxro",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "img_dim=(50,50)\n",
        "(X_train_50, y_train, X_test_50, y_test, nb_classes ) =load_dataset(\"/content/Data\")\n",
        "X_train_50 = X_train_50.astype('float32')\n",
        "X_test_50 = X_test_50.astype('float32')\n",
        "X_train_50 /= 255\n",
        "X_test_50 /= 255\n",
        "epochs = 100\n",
        "batch_size=50"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "id": "4YBLScgJO7it",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "dim_50=(50,50,3)\n",
        "sgd=tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.001, nesterov=False, name='SGD')\n",
        "\"\"\"\n",
        "This code creates an instance of the \"SGD\" optimizer \n",
        "from TensorFlow's Keras library. The optimizer is a \n",
        "variant of Stochastic Gradient Descent, which is a\n",
        "widely used optimization algorithm for training\n",
        "deep learning models.\n",
        "\n",
        "The following parameters are set for the optimizer:\n",
        "\n",
        "learning_rate: 0.01, which determines the step size at which the optimizer makes updates to the model's parameters. A smaller learning rate results in smaller steps and slower convergence, while a larger learning rate results in larger steps and faster convergence but may also overshoot the optimal solution.\n",
        "momentum: 0.001, which is a term used to smooth out the updates to the model's parameters. It helps the optimizer to converge faster and avoid getting stuck in local optima.\n",
        "nesterov: False, which is a boolean flag that determines whether to use the Nesterov variant of SGD or not. When set to True, it uses a slightly different update rule that improves the optimization performance.\n",
        "name: 'SGD', which is a string that can be used as a name for the optimizer.\n",
        "This optimizer will be used later on to train the model.\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "tf.random.set_seed(1234)\n",
        "model_simple = alexnet(nb_classes=nb_classes,input_shape=dim_50)\n",
        "model_simple.compile(\n",
        "    loss=tf.keras.losses.categorical_crossentropy,\n",
        "    optimizer=sgd,\n",
        "    metrics=['accuracy'])\n",
        "\n",
        "tf.random.set_seed(1234)\n",
        "model_to_prune_0 = alexnet(nb_classes=nb_classes,input_shape=dim_50)\n",
        "model_to_prune_0.compile(\n",
        "    loss=tf.keras.losses.categorical_crossentropy,\n",
        "    optimizer=sgd,\n",
        "    metrics=['accuracy'])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "This code creates two instances of the alexnet model, \n",
        "one called \"model_simple\" and the other called \"model_to_prune_0\". \n",
        "The input shape passed to the function is dim_50,\n",
        "which is set to be (50,50,3) and the number of classes passed \n",
        "is nb_classes. The code also sets the seed of the random number\n",
        "generator using tf.random.set_seed(1234) for both models, so that\n",
        "the models are initialized with the same random weights.\n",
        "\n",
        "Both of the models are then compiled with the following settings:\n",
        "\n",
        "Loss function: \"categorical_crossentropy\" which is commonly used for multi-class classification problems.\n",
        "Optimizer: \"SGD\" (Stochastic Gradient Descent) with a learning rate of 0.01, momentum of 0.001, and nesterov is set to False.\n",
        "Metrics: 'accuracy' is used to measure the performance of the model.\n",
        "The main difference between the two models is that one is called \"model_simple\" and the other \"model_to_prune_0\", which implies that the latter model may be used for pruning later on.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "id": "yYP1A0aTEzfg",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "#sgd=tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.001, nesterov=False, name='SGD')\n",
        "tf.random.set_seed(1234)\n",
        "model_to_prune_1 = alexnet(nb_classes=nb_classes,input_shape=dim_50)\n",
        "model_to_prune_1.compile(\n",
        "    loss=tf.keras.losses.categorical_crossentropy,\n",
        "    optimizer=sgd,\n",
        "    metrics=['accuracy'])\n",
        "\n",
        "tf.random.set_seed(1234)\n",
        "model_to_prune_2 = alexnet(nb_classes=nb_classes,input_shape=dim_50)\n",
        "model_to_prune_2.compile(\n",
        "    loss=tf.keras.losses.categorical_crossentropy,\n",
        "    optimizer=sgd,\n",
        "    metrics=['accuracy'])\n",
        "\n",
        "tf.random.set_seed(1234)\n",
        "model_to_prune_3 = alexnet(nb_classes=nb_classes,input_shape=dim_50)\n",
        "model_to_prune_3.compile(\n",
        "    loss=tf.keras.losses.categorical_crossentropy,\n",
        "    optimizer=sgd,\n",
        "    metrics=['accuracy'])\n",
        "\n",
        "\n",
        "tf.random.set_seed(1234)\n",
        "model_to_prune_4 = alexnet(nb_classes=nb_classes,input_shape=dim_50)\n",
        "model_to_prune_4.compile(\n",
        "    loss=tf.keras.losses.categorical_crossentropy,\n",
        "    optimizer=sgd,\n",
        "    metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2qc41nM5Iiwi"
      },
      "source": [
        "##Training of the simple model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LV_QA_1elER7",
        "outputId": "16bb0348-a38b-47ff-fad3-95525767630c",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n",
            "5/5 [==============================] - 1s 69ms/step - loss: 2.8278 - accuracy: 0.1018 - val_loss: 2.6389 - val_accuracy: 0.0781\n",
            "Epoch 2/500\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 2.0500 - accuracy: 0.3496 - val_loss: 2.6428 - val_accuracy: 0.0625\n",
            "Epoch 3/500\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 1.5564 - accuracy: 0.6327 - val_loss: 2.6432 - val_accuracy: 0.0625\n",
            "Epoch 4/500\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 1.2247 - accuracy: 0.7611 - val_loss: 2.6459 - val_accuracy: 0.0781\n",
            "Epoch 5/500\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.9601 - accuracy: 0.8717 - val_loss: 2.6517 - val_accuracy: 0.0938\n",
            "Epoch 6/500\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.7792 - accuracy: 0.9425 - val_loss: 2.6601 - val_accuracy: 0.1250\n",
            "Epoch 7/500\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5985 - accuracy: 0.9779 - val_loss: 2.6670 - val_accuracy: 0.0938\n",
            "Epoch 8/500\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.4842 - accuracy: 0.9823 - val_loss: 2.6765 - val_accuracy: 0.0625\n",
            "Epoch 9/500\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.4081 - accuracy: 0.9956 - val_loss: 2.6842 - val_accuracy: 0.1094\n",
            "Epoch 10/500\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.3394 - accuracy: 0.9956 - val_loss: 2.6965 - val_accuracy: 0.1094\n",
            "Epoch 11/500\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.2832 - accuracy: 0.9956 - val_loss: 2.7079 - val_accuracy: 0.0781\n",
            "Epoch 12/500\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.2434 - accuracy: 1.0000 - val_loss: 2.7128 - val_accuracy: 0.0938\n",
            "Epoch 13/500\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.2120 - accuracy: 1.0000 - val_loss: 2.7262 - val_accuracy: 0.0469\n",
            "Epoch 14/500\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.1874 - accuracy: 1.0000 - val_loss: 2.7357 - val_accuracy: 0.0938\n",
            "Epoch 15/500\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.1680 - accuracy: 1.0000 - val_loss: 2.7496 - val_accuracy: 0.1094\n",
            "Epoch 16/500\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.1485 - accuracy: 1.0000 - val_loss: 2.7629 - val_accuracy: 0.0781\n",
            "Epoch 17/500\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.1378 - accuracy: 1.0000 - val_loss: 2.7753 - val_accuracy: 0.0781\n",
            "Epoch 18/500\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.1268 - accuracy: 1.0000 - val_loss: 2.7876 - val_accuracy: 0.0625\n",
            "Epoch 19/500\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.1202 - accuracy: 1.0000 - val_loss: 2.7952 - val_accuracy: 0.0625\n",
            "Epoch 20/500\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.1037 - accuracy: 1.0000 - val_loss: 2.8115 - val_accuracy: 0.0781\n",
            "Epoch 21/500\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0952 - accuracy: 1.0000 - val_loss: 2.8260 - val_accuracy: 0.0781\n",
            "Epoch 22/500\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0923 - accuracy: 1.0000 - val_loss: 2.8436 - val_accuracy: 0.0625\n",
            "Epoch 23/500\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0872 - accuracy: 1.0000 - val_loss: 2.8627 - val_accuracy: 0.0625\n",
            "Epoch 24/500\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.0837 - accuracy: 1.0000 - val_loss: 2.8785 - val_accuracy: 0.0625\n",
            "Epoch 25/500\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.0766 - accuracy: 1.0000 - val_loss: 2.8887 - val_accuracy: 0.0625\n",
            "Epoch 26/500\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.0699 - accuracy: 1.0000 - val_loss: 2.9061 - val_accuracy: 0.0625\n",
            "Epoch 27/500\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.0679 - accuracy: 1.0000 - val_loss: 2.9217 - val_accuracy: 0.0625\n",
            "Epoch 28/500\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.0638 - accuracy: 1.0000 - val_loss: 2.9348 - val_accuracy: 0.0625\n",
            "Epoch 29/500\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.0628 - accuracy: 1.0000 - val_loss: 2.9452 - val_accuracy: 0.0625\n",
            "Epoch 30/500\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.0595 - accuracy: 1.0000 - val_loss: 2.9625 - val_accuracy: 0.0938\n",
            "Epoch 31/500\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.0588 - accuracy: 1.0000 - val_loss: 2.9803 - val_accuracy: 0.0625\n",
            "Epoch 32/500\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.0579 - accuracy: 1.0000 - val_loss: 2.9904 - val_accuracy: 0.0625\n",
            "Epoch 33/500\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.0537 - accuracy: 1.0000 - val_loss: 2.9980 - val_accuracy: 0.0625\n",
            "Epoch 34/500\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.0531 - accuracy: 1.0000 - val_loss: 3.0145 - val_accuracy: 0.0625\n",
            "Epoch 35/500\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0486 - accuracy: 1.0000 - val_loss: 3.0294 - val_accuracy: 0.0625\n",
            "Epoch 36/500\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.0467 - accuracy: 1.0000 - val_loss: 3.0430 - val_accuracy: 0.0625\n",
            "Epoch 37/500\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0434 - accuracy: 1.0000 - val_loss: 3.0540 - val_accuracy: 0.0625\n",
            "Epoch 38/500\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0441 - accuracy: 1.0000 - val_loss: 3.0612 - val_accuracy: 0.0781\n",
            "Epoch 39/500\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0437 - accuracy: 1.0000 - val_loss: 3.0721 - val_accuracy: 0.0781\n",
            "Epoch 40/500\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0414 - accuracy: 1.0000 - val_loss: 3.0879 - val_accuracy: 0.0781\n",
            "Epoch 41/500\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.0433 - accuracy: 1.0000 - val_loss: 3.0906 - val_accuracy: 0.0781\n",
            "Epoch 42/500\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.0383 - accuracy: 1.0000 - val_loss: 3.1046 - val_accuracy: 0.0938\n",
            "Epoch 43/500\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.0368 - accuracy: 1.0000 - val_loss: 3.1149 - val_accuracy: 0.0938\n",
            "Epoch 44/500\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.0369 - accuracy: 1.0000 - val_loss: 3.1232 - val_accuracy: 0.0938\n",
            "Epoch 45/500\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.0356 - accuracy: 1.0000 - val_loss: 3.1381 - val_accuracy: 0.0938\n",
            "Epoch 46/500\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.0347 - accuracy: 1.0000 - val_loss: 3.1496 - val_accuracy: 0.0938\n",
            "Epoch 47/500\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.0341 - accuracy: 1.0000 - val_loss: 3.1553 - val_accuracy: 0.0938\n",
            "Epoch 48/500\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0325 - accuracy: 1.0000 - val_loss: 3.1641 - val_accuracy: 0.0938\n",
            "Epoch 49/500\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.0323 - accuracy: 1.0000 - val_loss: 3.1723 - val_accuracy: 0.0938\n",
            "Epoch 50/500\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.0315 - accuracy: 1.0000 - val_loss: 3.1754 - val_accuracy: 0.0938\n",
            "Epoch 51/500\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0310 - accuracy: 1.0000 - val_loss: 3.1885 - val_accuracy: 0.0938\n",
            "Epoch 52/500\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0298 - accuracy: 1.0000 - val_loss: 3.1923 - val_accuracy: 0.0938\n",
            "Epoch 53/500\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0285 - accuracy: 1.0000 - val_loss: 3.2031 - val_accuracy: 0.0781\n",
            "Epoch 54/500\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.0288 - accuracy: 1.0000 - val_loss: 3.2025 - val_accuracy: 0.0781\n",
            "Epoch 55/500\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.0279 - accuracy: 1.0000 - val_loss: 3.2037 - val_accuracy: 0.0781\n",
            "Epoch 56/500\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0267 - accuracy: 1.0000 - val_loss: 3.2076 - val_accuracy: 0.0781\n",
            "Epoch 57/500\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0268 - accuracy: 1.0000 - val_loss: 3.2075 - val_accuracy: 0.0938\n",
            "Epoch 58/500\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0260 - accuracy: 1.0000 - val_loss: 3.2078 - val_accuracy: 0.0938\n",
            "Epoch 59/500\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.0291 - accuracy: 1.0000 - val_loss: 3.2068 - val_accuracy: 0.1094\n",
            "Epoch 60/500\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.0250 - accuracy: 1.0000 - val_loss: 3.2040 - val_accuracy: 0.0938\n",
            "Epoch 61/500\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.0266 - accuracy: 1.0000 - val_loss: 3.2005 - val_accuracy: 0.0938\n",
            "Epoch 62/500\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.0253 - accuracy: 1.0000 - val_loss: 3.1938 - val_accuracy: 0.0938\n",
            "Epoch 63/500\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.0243 - accuracy: 1.0000 - val_loss: 3.1925 - val_accuracy: 0.0938\n",
            "Epoch 64/500\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.0249 - accuracy: 1.0000 - val_loss: 3.1928 - val_accuracy: 0.0938\n",
            "Epoch 65/500\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.0233 - accuracy: 1.0000 - val_loss: 3.1893 - val_accuracy: 0.0938\n",
            "Epoch 66/500\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.0223 - accuracy: 1.0000 - val_loss: 3.1834 - val_accuracy: 0.1250\n",
            "Epoch 67/500\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.0221 - accuracy: 1.0000 - val_loss: 3.1810 - val_accuracy: 0.1250\n",
            "Epoch 68/500\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.0223 - accuracy: 1.0000 - val_loss: 3.1699 - val_accuracy: 0.1406\n",
            "Epoch 69/500\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.0214 - accuracy: 1.0000 - val_loss: 3.1610 - val_accuracy: 0.1406\n",
            "Epoch 70/500\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.0229 - accuracy: 1.0000 - val_loss: 3.1509 - val_accuracy: 0.1406\n",
            "Epoch 71/500\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.0206 - accuracy: 1.0000 - val_loss: 3.1394 - val_accuracy: 0.1406\n",
            "Epoch 72/500\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0206 - accuracy: 1.0000 - val_loss: 3.1272 - val_accuracy: 0.1406\n",
            "Epoch 73/500\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0197 - accuracy: 1.0000 - val_loss: 3.1215 - val_accuracy: 0.1406\n",
            "Epoch 74/500\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0196 - accuracy: 1.0000 - val_loss: 3.1100 - val_accuracy: 0.1562\n",
            "Epoch 75/500\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0189 - accuracy: 1.0000 - val_loss: 3.0977 - val_accuracy: 0.1562\n",
            "Epoch 76/500\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0199 - accuracy: 1.0000 - val_loss: 3.0847 - val_accuracy: 0.1562\n",
            "Epoch 77/500\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0188 - accuracy: 1.0000 - val_loss: 3.0690 - val_accuracy: 0.1875\n",
            "Epoch 78/500\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.0190 - accuracy: 1.0000 - val_loss: 3.0597 - val_accuracy: 0.1719\n",
            "Epoch 79/500\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0176 - accuracy: 1.0000 - val_loss: 3.0434 - val_accuracy: 0.1875\n",
            "Epoch 80/500\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0174 - accuracy: 1.0000 - val_loss: 3.0267 - val_accuracy: 0.1875\n",
            "Epoch 81/500\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.0171 - accuracy: 1.0000 - val_loss: 3.0128 - val_accuracy: 0.1875\n",
            "Epoch 82/500\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.0168 - accuracy: 1.0000 - val_loss: 2.9972 - val_accuracy: 0.1875\n",
            "Epoch 83/500\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.0175 - accuracy: 1.0000 - val_loss: 2.9800 - val_accuracy: 0.1875\n",
            "Epoch 84/500\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.0167 - accuracy: 1.0000 - val_loss: 2.9626 - val_accuracy: 0.1875\n",
            "Epoch 85/500\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.0174 - accuracy: 1.0000 - val_loss: 2.9454 - val_accuracy: 0.1875\n",
            "Epoch 86/500\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.0162 - accuracy: 1.0000 - val_loss: 2.9270 - val_accuracy: 0.1875\n",
            "Epoch 87/500\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.0161 - accuracy: 1.0000 - val_loss: 2.9135 - val_accuracy: 0.1875\n",
            "Epoch 88/500\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.0163 - accuracy: 1.0000 - val_loss: 2.8859 - val_accuracy: 0.1875\n",
            "Epoch 89/500\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.0161 - accuracy: 1.0000 - val_loss: 2.8715 - val_accuracy: 0.1875\n",
            "Epoch 90/500\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.0153 - accuracy: 1.0000 - val_loss: 2.8462 - val_accuracy: 0.2031\n",
            "Epoch 91/500\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.0153 - accuracy: 1.0000 - val_loss: 2.8324 - val_accuracy: 0.2031\n",
            "Epoch 92/500\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.0156 - accuracy: 1.0000 - val_loss: 2.7962 - val_accuracy: 0.2031\n",
            "Epoch 93/500\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.0151 - accuracy: 1.0000 - val_loss: 2.7830 - val_accuracy: 0.2031\n",
            "Epoch 94/500\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.0148 - accuracy: 1.0000 - val_loss: 2.7610 - val_accuracy: 0.2031\n",
            "Epoch 95/500\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.0146 - accuracy: 1.0000 - val_loss: 2.7294 - val_accuracy: 0.2188\n",
            "Epoch 96/500\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.0143 - accuracy: 1.0000 - val_loss: 2.7120 - val_accuracy: 0.2188\n",
            "Epoch 97/500\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.0143 - accuracy: 1.0000 - val_loss: 2.6935 - val_accuracy: 0.2188\n",
            "Epoch 98/500\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.0142 - accuracy: 1.0000 - val_loss: 2.6707 - val_accuracy: 0.2188\n",
            "Epoch 99/500\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.0146 - accuracy: 1.0000 - val_loss: 2.6508 - val_accuracy: 0.2188\n",
            "Epoch 100/500\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.0141 - accuracy: 1.0000 - val_loss: 2.6340 - val_accuracy: 0.2188\n",
            "Epoch 101/500\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.0139 - accuracy: 1.0000 - val_loss: 2.6117 - val_accuracy: 0.2188\n",
            "Epoch 102/500\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.0133 - accuracy: 1.0000 - val_loss: 2.5923 - val_accuracy: 0.2188\n",
            "Epoch 103/500\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.0138 - accuracy: 1.0000 - val_loss: 2.5677 - val_accuracy: 0.2188\n",
            "Epoch 104/500\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.0140 - accuracy: 1.0000 - val_loss: 2.5416 - val_accuracy: 0.2344\n",
            "Epoch 105/500\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.0132 - accuracy: 1.0000 - val_loss: 2.5281 - val_accuracy: 0.2344\n",
            "Epoch 106/500\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.0132 - accuracy: 1.0000 - val_loss: 2.5111 - val_accuracy: 0.2344\n",
            "Epoch 107/500\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0133 - accuracy: 1.0000 - val_loss: 2.4950 - val_accuracy: 0.2344\n",
            "Epoch 108/500\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.0127 - accuracy: 1.0000 - val_loss: 2.4705 - val_accuracy: 0.2500\n",
            "Epoch 109/500\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.0128 - accuracy: 1.0000 - val_loss: 2.4587 - val_accuracy: 0.2500\n",
            "Epoch 110/500\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.0123 - accuracy: 1.0000 - val_loss: 2.4328 - val_accuracy: 0.2500\n",
            "Epoch 111/500\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.0125 - accuracy: 1.0000 - val_loss: 2.4170 - val_accuracy: 0.2344\n",
            "Epoch 112/500\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.0126 - accuracy: 1.0000 - val_loss: 2.3999 - val_accuracy: 0.2344\n",
            "Epoch 113/500\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.0123 - accuracy: 1.0000 - val_loss: 2.3846 - val_accuracy: 0.2500\n",
            "Epoch 114/500\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.0124 - accuracy: 1.0000 - val_loss: 2.3711 - val_accuracy: 0.2344\n",
            "Epoch 115/500\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.0116 - accuracy: 1.0000 - val_loss: 2.3498 - val_accuracy: 0.2344\n",
            "Epoch 116/500\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0116 - accuracy: 1.0000 - val_loss: 2.3421 - val_accuracy: 0.2500\n",
            "Epoch 117/500\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0118 - accuracy: 1.0000 - val_loss: 2.3308 - val_accuracy: 0.2500\n",
            "Epoch 118/500\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0113 - accuracy: 1.0000 - val_loss: 2.3150 - val_accuracy: 0.2656\n",
            "Epoch 119/500\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0115 - accuracy: 1.0000 - val_loss: 2.2996 - val_accuracy: 0.2656\n",
            "Epoch 120/500\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.0117 - accuracy: 1.0000 - val_loss: 2.2921 - val_accuracy: 0.2500\n",
            "Epoch 121/500\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.0117 - accuracy: 1.0000 - val_loss: 2.2840 - val_accuracy: 0.2500\n",
            "Epoch 122/500\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.0111 - accuracy: 1.0000 - val_loss: 2.2749 - val_accuracy: 0.2656\n",
            "Epoch 123/500\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.0108 - accuracy: 1.0000 - val_loss: 2.2643 - val_accuracy: 0.2812\n",
            "Epoch 124/500\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0116 - accuracy: 1.0000 - val_loss: 2.2565 - val_accuracy: 0.2812\n",
            "Epoch 125/500\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.0113 - accuracy: 1.0000 - val_loss: 2.2464 - val_accuracy: 0.2969\n",
            "Epoch 126/500\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.0103 - accuracy: 1.0000 - val_loss: 2.2355 - val_accuracy: 0.2969\n",
            "Epoch 127/500\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.0108 - accuracy: 1.0000 - val_loss: 2.2254 - val_accuracy: 0.2812\n",
            "Epoch 128/500\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.0105 - accuracy: 1.0000 - val_loss: 2.2211 - val_accuracy: 0.2969\n",
            "Epoch 129/500\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.0103 - accuracy: 1.0000 - val_loss: 2.2106 - val_accuracy: 0.2812\n",
            "Epoch 130/500\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.0108 - accuracy: 1.0000 - val_loss: 2.2042 - val_accuracy: 0.2969\n",
            "Epoch 131/500\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.0105 - accuracy: 1.0000 - val_loss: 2.2008 - val_accuracy: 0.2969\n",
            "Epoch 132/500\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.0101 - accuracy: 1.0000 - val_loss: 2.2011 - val_accuracy: 0.3125\n",
            "Epoch 133/500\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.0102 - accuracy: 1.0000 - val_loss: 2.1956 - val_accuracy: 0.2969\n",
            "Epoch 134/500\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.0103 - accuracy: 1.0000 - val_loss: 2.1931 - val_accuracy: 0.3125\n",
            "Epoch 135/500\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.0100 - accuracy: 1.0000 - val_loss: 2.1876 - val_accuracy: 0.3281\n",
            "Epoch 136/500\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.0099 - accuracy: 1.0000 - val_loss: 2.1819 - val_accuracy: 0.3594\n",
            "Epoch 137/500\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.0097 - accuracy: 1.0000 - val_loss: 2.1811 - val_accuracy: 0.3594\n",
            "Epoch 138/500\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.0101 - accuracy: 1.0000 - val_loss: 2.1758 - val_accuracy: 0.3438\n",
            "Epoch 139/500\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.0098 - accuracy: 1.0000 - val_loss: 2.1734 - val_accuracy: 0.3594\n",
            "Epoch 140/500\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0097 - accuracy: 1.0000 - val_loss: 2.1672 - val_accuracy: 0.3594\n",
            "Epoch 141/500\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0093 - accuracy: 1.0000 - val_loss: 2.1627 - val_accuracy: 0.3438\n",
            "Epoch 142/500\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.0096 - accuracy: 1.0000 - val_loss: 2.1603 - val_accuracy: 0.3438\n",
            "Epoch 143/500\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.0103 - accuracy: 1.0000 - val_loss: 2.1555 - val_accuracy: 0.3438\n",
            "Epoch 144/500\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.0092 - accuracy: 1.0000 - val_loss: 2.1600 - val_accuracy: 0.3594\n",
            "Epoch 145/500\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.0091 - accuracy: 1.0000 - val_loss: 2.1601 - val_accuracy: 0.3594\n",
            "Epoch 146/500\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.0101 - accuracy: 1.0000 - val_loss: 2.1581 - val_accuracy: 0.3438\n",
            "Epoch 147/500\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.0088 - accuracy: 1.0000 - val_loss: 2.1550 - val_accuracy: 0.3438\n",
            "Epoch 148/500\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.0092 - accuracy: 1.0000 - val_loss: 2.1507 - val_accuracy: 0.3438\n",
            "Epoch 149/500\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.0088 - accuracy: 1.0000 - val_loss: 2.1493 - val_accuracy: 0.3281\n",
            "Epoch 150/500\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.0093 - accuracy: 1.0000 - val_loss: 2.1449 - val_accuracy: 0.3125\n",
            "Epoch 151/500\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.0089 - accuracy: 1.0000 - val_loss: 2.1457 - val_accuracy: 0.3281\n",
            "Epoch 152/500\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0086 - accuracy: 1.0000 - val_loss: 2.1444 - val_accuracy: 0.3281\n",
            "Epoch 153/500\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0085 - accuracy: 1.0000 - val_loss: 2.1443 - val_accuracy: 0.3281\n",
            "Epoch 154/500\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0086 - accuracy: 1.0000 - val_loss: 2.1440 - val_accuracy: 0.3281\n",
            "Epoch 155/500\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0091 - accuracy: 1.0000 - val_loss: 2.1445 - val_accuracy: 0.3281\n",
            "Epoch 156/500\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.0089 - accuracy: 1.0000 - val_loss: 2.1436 - val_accuracy: 0.3281\n",
            "Epoch 157/500\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.0087 - accuracy: 1.0000 - val_loss: 2.1384 - val_accuracy: 0.3281\n",
            "Epoch 158/500\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 2.1385 - val_accuracy: 0.3281\n",
            "Epoch 159/500\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.0084 - accuracy: 1.0000 - val_loss: 2.1398 - val_accuracy: 0.3281\n",
            "Epoch 160/500\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.0085 - accuracy: 1.0000 - val_loss: 2.1370 - val_accuracy: 0.3281\n",
            "Epoch 161/500\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 2.1402 - val_accuracy: 0.3281\n",
            "Epoch 162/500\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.0085 - accuracy: 1.0000 - val_loss: 2.1386 - val_accuracy: 0.3281\n",
            "Epoch 163/500\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: 2.1374 - val_accuracy: 0.3125\n",
            "Epoch 164/500\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.0082 - accuracy: 1.0000 - val_loss: 2.1389 - val_accuracy: 0.3125\n",
            "Epoch 165/500\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 2.1390 - val_accuracy: 0.3125\n",
            "Epoch 166/500\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 2.1370 - val_accuracy: 0.3125\n",
            "Epoch 167/500\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: 2.1402 - val_accuracy: 0.3125\n",
            "Epoch 168/500\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 2.1393 - val_accuracy: 0.3125\n",
            "Epoch 169/500\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 2.1381 - val_accuracy: 0.3125\n",
            "Epoch 170/500\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 2.1407 - val_accuracy: 0.3125\n",
            "Epoch 171/500\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: 2.1363 - val_accuracy: 0.3125\n",
            "Epoch 172/500\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 2.1385 - val_accuracy: 0.3125\n",
            "Epoch 173/500\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 2.1373 - val_accuracy: 0.3125\n",
            "Epoch 174/500\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 2.1395 - val_accuracy: 0.3125\n",
            "Epoch 175/500\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 2.1384 - val_accuracy: 0.3125\n",
            "Epoch 176/500\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: 2.1366 - val_accuracy: 0.3281\n",
            "Epoch 177/500\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 2.1393 - val_accuracy: 0.3125\n",
            "Epoch 178/500\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 2.1433 - val_accuracy: 0.3125\n",
            "Epoch 179/500\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 2.1406 - val_accuracy: 0.3125\n",
            "Epoch 180/500\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 2.1405 - val_accuracy: 0.3125\n",
            "Epoch 181/500\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 2.1409 - val_accuracy: 0.3125\n",
            "Epoch 182/500\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 2.1402 - val_accuracy: 0.3125\n",
            "Epoch 183/500\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 2.1397 - val_accuracy: 0.3281\n",
            "Epoch 184/500\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 2.1369 - val_accuracy: 0.3281\n",
            "Epoch 185/500\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 2.1410 - val_accuracy: 0.3281\n",
            "Epoch 186/500\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 2.1415 - val_accuracy: 0.3281\n",
            "Epoch 187/500\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 2.1391 - val_accuracy: 0.3125\n",
            "Epoch 188/500\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 2.1415 - val_accuracy: 0.3125\n",
            "Epoch 189/500\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 2.1420 - val_accuracy: 0.3125\n",
            "Epoch 190/500\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 2.1438 - val_accuracy: 0.3125\n",
            "Epoch 191/500\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 2.1424 - val_accuracy: 0.3125\n",
            "Epoch 192/500\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 2.1418 - val_accuracy: 0.3125\n",
            "Epoch 193/500\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 2.1454 - val_accuracy: 0.3125\n",
            "Epoch 194/500\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 2.1434 - val_accuracy: 0.3125\n",
            "Epoch 195/500\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 2.1425 - val_accuracy: 0.3125\n",
            "Epoch 196/500\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 2.1437 - val_accuracy: 0.3125\n",
            "Epoch 197/500\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 2.1413 - val_accuracy: 0.3125\n",
            "Epoch 198/500\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 2.1421 - val_accuracy: 0.3281\n",
            "Epoch 199/500\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 2.1424 - val_accuracy: 0.3281\n",
            "Epoch 200/500\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 2.1428 - val_accuracy: 0.3281\n",
            "Epoch 201/500\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 2.1421 - val_accuracy: 0.3281\n",
            "Epoch 202/500\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 2.1407 - val_accuracy: 0.3125\n",
            "Epoch 203/500\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 2.1401 - val_accuracy: 0.3125\n",
            "Epoch 204/500\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 2.1412 - val_accuracy: 0.3281\n",
            "Epoch 205/500\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 2.1399 - val_accuracy: 0.3281\n",
            "Epoch 206/500\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 2.1411 - val_accuracy: 0.3281\n",
            "Epoch 207/500\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 2.1380 - val_accuracy: 0.3281\n",
            "Epoch 208/500\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 2.1394 - val_accuracy: 0.3281\n",
            "Epoch 209/500\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 2.1384 - val_accuracy: 0.3281\n",
            "Epoch 210/500\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 2.1401 - val_accuracy: 0.3438\n",
            "Epoch 211/500\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 2.1418 - val_accuracy: 0.3281\n",
            "Epoch 212/500\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 2.1395 - val_accuracy: 0.3281\n",
            "Epoch 213/500\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 2.1409 - val_accuracy: 0.3281\n",
            "Epoch 214/500\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 2.1444 - val_accuracy: 0.3281\n",
            "Epoch 215/500\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 2.1438 - val_accuracy: 0.3438\n",
            "Epoch 216/500\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 2.1418 - val_accuracy: 0.3281\n",
            "Epoch 217/500\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 2.1449 - val_accuracy: 0.3125\n",
            "Epoch 218/500\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 2.1406 - val_accuracy: 0.3125\n",
            "Epoch 219/500\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 2.1423 - val_accuracy: 0.3125\n",
            "Epoch 220/500\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 2.1447 - val_accuracy: 0.3125\n",
            "Epoch 221/500\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 2.1434 - val_accuracy: 0.3438\n",
            "Epoch 222/500\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 2.1454 - val_accuracy: 0.3281\n",
            "Epoch 223/500\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 2.1464 - val_accuracy: 0.3125\n",
            "Epoch 224/500\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 2.1501 - val_accuracy: 0.3281\n",
            "Epoch 225/500\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 2.1507 - val_accuracy: 0.3438\n",
            "Epoch 226/500\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 2.1493 - val_accuracy: 0.3281\n",
            "Epoch 227/500\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 2.1473 - val_accuracy: 0.3281\n",
            "Epoch 228/500\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 2.1474 - val_accuracy: 0.3125\n",
            "Epoch 229/500\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 2.1458 - val_accuracy: 0.3125\n",
            "Epoch 230/500\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 2.1437 - val_accuracy: 0.3125\n",
            "Epoch 231/500\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 2.1446 - val_accuracy: 0.3281\n",
            "Epoch 232/500\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 2.1457 - val_accuracy: 0.3125\n",
            "Epoch 233/500\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 2.1450 - val_accuracy: 0.3125\n",
            "Epoch 234/500\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 2.1446 - val_accuracy: 0.3125\n",
            "Epoch 235/500\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 2.1443 - val_accuracy: 0.3125\n",
            "Epoch 236/500\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 2.1433 - val_accuracy: 0.3125\n",
            "Epoch 237/500\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 2.1445 - val_accuracy: 0.3125\n",
            "Epoch 238/500\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 2.1446 - val_accuracy: 0.3281\n",
            "Epoch 239/500\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 2.1450 - val_accuracy: 0.3281\n",
            "Epoch 240/500\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 2.1442 - val_accuracy: 0.3281\n",
            "Epoch 241/500\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 2.1478 - val_accuracy: 0.3281\n",
            "Epoch 242/500\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 2.1454 - val_accuracy: 0.3281\n",
            "Epoch 243/500\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 2.1479 - val_accuracy: 0.3281\n",
            "Epoch 244/500\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 2.1467 - val_accuracy: 0.3125\n",
            "Epoch 245/500\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 2.1461 - val_accuracy: 0.3438\n",
            "Epoch 246/500\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 2.1438 - val_accuracy: 0.3125\n",
            "Epoch 247/500\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 2.1455 - val_accuracy: 0.3281\n",
            "Epoch 248/500\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 2.1460 - val_accuracy: 0.3125\n",
            "Epoch 249/500\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 2.1458 - val_accuracy: 0.3281\n",
            "Epoch 250/500\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 2.1454 - val_accuracy: 0.3281\n",
            "Epoch 251/500\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 2.1464 - val_accuracy: 0.3438\n",
            "Epoch 252/500\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 2.1444 - val_accuracy: 0.3281\n",
            "Epoch 253/500\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 2.1442 - val_accuracy: 0.3438\n",
            "Epoch 254/500\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 2.1437 - val_accuracy: 0.3438\n",
            "Epoch 255/500\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 2.1450 - val_accuracy: 0.3281\n",
            "Epoch 256/500\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 2.1408 - val_accuracy: 0.3438\n",
            "Epoch 257/500\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 2.1347 - val_accuracy: 0.3281\n",
            "Epoch 258/500\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 2.1425 - val_accuracy: 0.3281\n",
            "Epoch 259/500\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 2.1437 - val_accuracy: 0.3438\n",
            "Epoch 260/500\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 2.1457 - val_accuracy: 0.3281\n",
            "Epoch 261/500\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 2.1470 - val_accuracy: 0.3281\n",
            "Epoch 262/500\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 2.1457 - val_accuracy: 0.3281\n",
            "Epoch 263/500\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 2.1463 - val_accuracy: 0.3281\n",
            "Epoch 264/500\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 2.1442 - val_accuracy: 0.3281\n",
            "Epoch 265/500\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 2.1461 - val_accuracy: 0.3281\n",
            "Epoch 266/500\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 2.1443 - val_accuracy: 0.3281\n",
            "Epoch 267/500\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 2.1467 - val_accuracy: 0.3281\n",
            "Epoch 268/500\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 2.1485 - val_accuracy: 0.3281\n",
            "Epoch 269/500\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 2.1493 - val_accuracy: 0.3438\n",
            "Epoch 270/500\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 2.1482 - val_accuracy: 0.3438\n",
            "Epoch 271/500\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 2.1483 - val_accuracy: 0.3438\n",
            "Epoch 272/500\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 2.1477 - val_accuracy: 0.3438\n",
            "Epoch 273/500\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 2.1473 - val_accuracy: 0.3281\n",
            "Epoch 274/500\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 2.1481 - val_accuracy: 0.3438\n",
            "Epoch 275/500\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 2.1468 - val_accuracy: 0.3281\n",
            "Epoch 276/500\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 2.1467 - val_accuracy: 0.3281\n",
            "Epoch 277/500\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 2.1463 - val_accuracy: 0.3281\n",
            "Epoch 278/500\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 2.1478 - val_accuracy: 0.3438\n",
            "Epoch 279/500\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 2.1478 - val_accuracy: 0.3281\n",
            "Epoch 280/500\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 2.1477 - val_accuracy: 0.3281\n",
            "Epoch 281/500\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 2.1478 - val_accuracy: 0.3438\n",
            "Epoch 282/500\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 2.1493 - val_accuracy: 0.3281\n",
            "Epoch 283/500\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 2.1504 - val_accuracy: 0.3281\n",
            "Epoch 284/500\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 2.1502 - val_accuracy: 0.3281\n",
            "Epoch 285/500\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 2.1481 - val_accuracy: 0.3281\n",
            "Epoch 286/500\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 2.1485 - val_accuracy: 0.3281\n",
            "Epoch 287/500\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 2.1456 - val_accuracy: 0.3281\n",
            "Epoch 288/500\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 2.1481 - val_accuracy: 0.3281\n",
            "Epoch 289/500\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 2.1450 - val_accuracy: 0.3281\n",
            "Epoch 290/500\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 2.1453 - val_accuracy: 0.3438\n",
            "Epoch 291/500\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 2.1457 - val_accuracy: 0.3281\n",
            "Epoch 292/500\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 2.1474 - val_accuracy: 0.3281\n",
            "Epoch 293/500\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 2.1464 - val_accuracy: 0.3281\n",
            "Epoch 294/500\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 2.1473 - val_accuracy: 0.3281\n",
            "Epoch 295/500\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 2.1478 - val_accuracy: 0.3281\n",
            "Epoch 296/500\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 2.1481 - val_accuracy: 0.3281\n",
            "Epoch 297/500\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 2.1483 - val_accuracy: 0.3281\n",
            "Epoch 298/500\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 2.1489 - val_accuracy: 0.3281\n",
            "Epoch 299/500\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 2.1485 - val_accuracy: 0.3438\n",
            "Epoch 300/500\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 2.1485 - val_accuracy: 0.3281\n",
            "Epoch 301/500\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 2.1469 - val_accuracy: 0.3281\n",
            "Epoch 302/500\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 2.1495 - val_accuracy: 0.3281\n",
            "Epoch 303/500\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 2.1500 - val_accuracy: 0.3281\n",
            "Epoch 304/500\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 2.1506 - val_accuracy: 0.3281\n",
            "Epoch 305/500\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 2.1506 - val_accuracy: 0.3281\n",
            "Epoch 306/500\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 2.1514 - val_accuracy: 0.3281\n",
            "Epoch 307/500\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 2.1502 - val_accuracy: 0.3281\n",
            "Epoch 308/500\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 2.1486 - val_accuracy: 0.3281\n",
            "Epoch 309/500\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 2.1447 - val_accuracy: 0.3281\n",
            "Epoch 310/500\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 2.1448 - val_accuracy: 0.3281\n",
            "Epoch 311/500\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 2.1460 - val_accuracy: 0.3281\n",
            "Epoch 312/500\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 2.1465 - val_accuracy: 0.3281\n",
            "Epoch 313/500\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 2.1428 - val_accuracy: 0.3281\n",
            "Epoch 314/500\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 2.1434 - val_accuracy: 0.3281\n",
            "Epoch 315/500\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 2.1460 - val_accuracy: 0.3281\n",
            "Epoch 316/500\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 2.1442 - val_accuracy: 0.3438\n",
            "Epoch 317/500\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 2.1456 - val_accuracy: 0.3438\n",
            "Epoch 318/500\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 2.1464 - val_accuracy: 0.3438\n",
            "Epoch 319/500\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 2.1489 - val_accuracy: 0.3438\n",
            "Epoch 320/500\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 2.1471 - val_accuracy: 0.3438\n",
            "Epoch 321/500\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 2.1489 - val_accuracy: 0.3438\n",
            "Epoch 322/500\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 2.1489 - val_accuracy: 0.3281\n",
            "Epoch 323/500\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 2.1498 - val_accuracy: 0.3281\n",
            "Epoch 324/500\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 2.1493 - val_accuracy: 0.3281\n",
            "Epoch 325/500\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 2.1467 - val_accuracy: 0.3281\n",
            "Epoch 326/500\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 2.1475 - val_accuracy: 0.3438\n",
            "Epoch 327/500\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 2.1499 - val_accuracy: 0.3438\n",
            "Epoch 328/500\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 2.1496 - val_accuracy: 0.3438\n",
            "Epoch 329/500\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 2.1499 - val_accuracy: 0.3438\n",
            "Epoch 330/500\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 2.1493 - val_accuracy: 0.3438\n",
            "Epoch 331/500\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 2.1494 - val_accuracy: 0.3438\n",
            "Epoch 332/500\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 2.1468 - val_accuracy: 0.3438\n",
            "Epoch 333/500\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 2.1475 - val_accuracy: 0.3438\n",
            "Epoch 334/500\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 2.1481 - val_accuracy: 0.3438\n",
            "Epoch 335/500\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 2.1472 - val_accuracy: 0.3438\n",
            "Epoch 336/500\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 2.1476 - val_accuracy: 0.3281\n",
            "Epoch 337/500\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 2.1487 - val_accuracy: 0.3281\n",
            "Epoch 338/500\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 2.1468 - val_accuracy: 0.3438\n",
            "Epoch 339/500\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 2.1481 - val_accuracy: 0.3438\n",
            "Epoch 340/500\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 2.1510 - val_accuracy: 0.3438\n",
            "Epoch 341/500\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 2.1522 - val_accuracy: 0.3438\n",
            "Epoch 342/500\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 2.1522 - val_accuracy: 0.3438\n",
            "Epoch 343/500\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 2.1527 - val_accuracy: 0.3438\n",
            "Epoch 344/500\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 2.1519 - val_accuracy: 0.3438\n",
            "Epoch 345/500\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 2.1499 - val_accuracy: 0.3438\n",
            "Epoch 346/500\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 2.1506 - val_accuracy: 0.3438\n",
            "Epoch 347/500\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 2.1501 - val_accuracy: 0.3438\n",
            "Epoch 348/500\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 2.1509 - val_accuracy: 0.3438\n",
            "Epoch 349/500\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 2.1520 - val_accuracy: 0.3438\n",
            "Epoch 350/500\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 2.1509 - val_accuracy: 0.3438\n",
            "Epoch 351/500\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 2.1490 - val_accuracy: 0.3438\n",
            "Epoch 352/500\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 2.1511 - val_accuracy: 0.3438\n",
            "Epoch 353/500\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 2.1507 - val_accuracy: 0.3438\n",
            "Epoch 354/500\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 2.1497 - val_accuracy: 0.3438\n",
            "Epoch 355/500\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 2.1486 - val_accuracy: 0.3438\n",
            "Epoch 356/500\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 2.1505 - val_accuracy: 0.3438\n",
            "Epoch 357/500\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 2.1503 - val_accuracy: 0.3438\n",
            "Epoch 358/500\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 2.1491 - val_accuracy: 0.3438\n",
            "Epoch 359/500\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 2.1495 - val_accuracy: 0.3438\n",
            "Epoch 360/500\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 2.1512 - val_accuracy: 0.3438\n",
            "Epoch 361/500\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 2.1527 - val_accuracy: 0.3438\n",
            "Epoch 362/500\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 2.1507 - val_accuracy: 0.3438\n",
            "Epoch 363/500\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 2.1509 - val_accuracy: 0.3438\n",
            "Epoch 364/500\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 2.1511 - val_accuracy: 0.3438\n",
            "Epoch 365/500\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 2.1525 - val_accuracy: 0.3438\n",
            "Epoch 366/500\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 2.1524 - val_accuracy: 0.3438\n",
            "Epoch 367/500\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 2.1517 - val_accuracy: 0.3438\n",
            "Epoch 368/500\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 2.1537 - val_accuracy: 0.3438\n",
            "Epoch 369/500\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 2.1536 - val_accuracy: 0.3281\n",
            "Epoch 370/500\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 2.1552 - val_accuracy: 0.3438\n",
            "Epoch 371/500\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 2.1572 - val_accuracy: 0.3438\n",
            "Epoch 372/500\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 2.1579 - val_accuracy: 0.3438\n",
            "Epoch 373/500\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 2.1572 - val_accuracy: 0.3438\n",
            "Epoch 374/500\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 2.1551 - val_accuracy: 0.3281\n",
            "Epoch 375/500\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 2.1560 - val_accuracy: 0.3281\n",
            "Epoch 376/500\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 2.1550 - val_accuracy: 0.3281\n",
            "Epoch 377/500\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 2.1539 - val_accuracy: 0.3281\n",
            "Epoch 378/500\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 2.1524 - val_accuracy: 0.3281\n",
            "Epoch 379/500\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 2.1525 - val_accuracy: 0.3281\n",
            "Epoch 380/500\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 2.1535 - val_accuracy: 0.3281\n",
            "Epoch 381/500\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 2.1549 - val_accuracy: 0.3438\n",
            "Epoch 382/500\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 2.1532 - val_accuracy: 0.3281\n",
            "Epoch 383/500\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 2.1535 - val_accuracy: 0.3438\n",
            "Epoch 384/500\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 2.1525 - val_accuracy: 0.3438\n",
            "Epoch 385/500\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 2.1527 - val_accuracy: 0.3438\n",
            "Epoch 386/500\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 2.1517 - val_accuracy: 0.3438\n",
            "Epoch 387/500\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 2.1521 - val_accuracy: 0.3438\n",
            "Epoch 388/500\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 2.1531 - val_accuracy: 0.3438\n",
            "Epoch 389/500\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 2.1524 - val_accuracy: 0.3438\n",
            "Epoch 390/500\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 2.1534 - val_accuracy: 0.3438\n",
            "Epoch 391/500\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 2.1546 - val_accuracy: 0.3438\n",
            "Epoch 392/500\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 2.1542 - val_accuracy: 0.3438\n",
            "Epoch 393/500\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 2.1539 - val_accuracy: 0.3438\n",
            "Epoch 394/500\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 2.1541 - val_accuracy: 0.3438\n",
            "Epoch 395/500\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 2.1550 - val_accuracy: 0.3438\n",
            "Epoch 396/500\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 2.1574 - val_accuracy: 0.3438\n",
            "Epoch 397/500\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 2.1577 - val_accuracy: 0.3438\n",
            "Epoch 398/500\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 2.1561 - val_accuracy: 0.3438\n",
            "Epoch 399/500\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 2.1563 - val_accuracy: 0.3438\n",
            "Epoch 400/500\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 2.1567 - val_accuracy: 0.3438\n",
            "Epoch 401/500\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 2.1558 - val_accuracy: 0.3281\n",
            "Epoch 402/500\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 2.1558 - val_accuracy: 0.3438\n",
            "Epoch 403/500\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 2.1544 - val_accuracy: 0.3438\n",
            "Epoch 404/500\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 2.1544 - val_accuracy: 0.3438\n",
            "Epoch 405/500\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 2.1515 - val_accuracy: 0.3281\n",
            "Epoch 406/500\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 2.1519 - val_accuracy: 0.3281\n",
            "Epoch 407/500\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 2.1521 - val_accuracy: 0.3281\n",
            "Epoch 408/500\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 2.1536 - val_accuracy: 0.3281\n",
            "Epoch 409/500\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 2.1539 - val_accuracy: 0.3438\n",
            "Epoch 410/500\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 2.1555 - val_accuracy: 0.3438\n",
            "Epoch 411/500\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 2.1558 - val_accuracy: 0.3438\n",
            "Epoch 412/500\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 2.1564 - val_accuracy: 0.3438\n",
            "Epoch 413/500\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 2.1531 - val_accuracy: 0.3438\n",
            "Epoch 414/500\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 2.1546 - val_accuracy: 0.3281\n",
            "Epoch 415/500\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 2.1544 - val_accuracy: 0.3281\n",
            "Epoch 416/500\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 2.1551 - val_accuracy: 0.3281\n",
            "Epoch 417/500\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 2.1560 - val_accuracy: 0.3281\n",
            "Epoch 418/500\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 2.1560 - val_accuracy: 0.3281\n",
            "Epoch 419/500\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 2.1555 - val_accuracy: 0.3281\n",
            "Epoch 420/500\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 2.1584 - val_accuracy: 0.3281\n",
            "Epoch 421/500\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 2.1595 - val_accuracy: 0.3281\n",
            "Epoch 422/500\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 2.1570 - val_accuracy: 0.3281\n",
            "Epoch 423/500\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 2.1551 - val_accuracy: 0.3281\n",
            "Epoch 424/500\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 2.1552 - val_accuracy: 0.3281\n",
            "Epoch 425/500\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 2.1567 - val_accuracy: 0.3438\n",
            "Epoch 426/500\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 2.1557 - val_accuracy: 0.3438\n",
            "Epoch 427/500\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 2.1563 - val_accuracy: 0.3438\n",
            "Epoch 428/500\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 2.1578 - val_accuracy: 0.3438\n",
            "Epoch 429/500\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 2.1568 - val_accuracy: 0.3438\n",
            "Epoch 430/500\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 2.1576 - val_accuracy: 0.3438\n",
            "Epoch 431/500\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 2.1579 - val_accuracy: 0.3438\n",
            "Epoch 432/500\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 2.1578 - val_accuracy: 0.3438\n",
            "Epoch 433/500\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 2.1567 - val_accuracy: 0.3438\n",
            "Epoch 434/500\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 2.1569 - val_accuracy: 0.3438\n",
            "Epoch 435/500\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 2.1553 - val_accuracy: 0.3438\n",
            "Epoch 436/500\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 2.1557 - val_accuracy: 0.3438\n",
            "Epoch 437/500\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 2.1570 - val_accuracy: 0.3438\n",
            "Epoch 438/500\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 2.1548 - val_accuracy: 0.3438\n",
            "Epoch 439/500\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 2.1553 - val_accuracy: 0.3438\n",
            "Epoch 440/500\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 2.1546 - val_accuracy: 0.3438\n",
            "Epoch 441/500\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 2.1528 - val_accuracy: 0.3438\n",
            "Epoch 442/500\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 2.1545 - val_accuracy: 0.3438\n",
            "Epoch 443/500\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 2.1539 - val_accuracy: 0.3438\n",
            "Epoch 444/500\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 2.1540 - val_accuracy: 0.3438\n",
            "Epoch 445/500\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 2.1544 - val_accuracy: 0.3438\n",
            "Epoch 446/500\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 2.1554 - val_accuracy: 0.3281\n",
            "Epoch 447/500\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 2.1551 - val_accuracy: 0.3281\n",
            "Epoch 448/500\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 2.1538 - val_accuracy: 0.3281\n",
            "Epoch 449/500\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 2.1546 - val_accuracy: 0.3281\n",
            "Epoch 450/500\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 2.1554 - val_accuracy: 0.3281\n",
            "Epoch 451/500\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 2.1556 - val_accuracy: 0.3281\n",
            "Epoch 452/500\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 2.1551 - val_accuracy: 0.3281\n",
            "Epoch 453/500\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 2.1516 - val_accuracy: 0.3281\n",
            "Epoch 454/500\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 2.1533 - val_accuracy: 0.3281\n",
            "Epoch 455/500\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 2.1541 - val_accuracy: 0.3281\n",
            "Epoch 456/500\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 2.1548 - val_accuracy: 0.3281\n",
            "Epoch 457/500\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 2.1554 - val_accuracy: 0.3281\n",
            "Epoch 458/500\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 2.1545 - val_accuracy: 0.3281\n",
            "Epoch 459/500\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 2.1540 - val_accuracy: 0.3281\n",
            "Epoch 460/500\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 2.1533 - val_accuracy: 0.3281\n",
            "Epoch 461/500\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 2.1542 - val_accuracy: 0.3281\n",
            "Epoch 462/500\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 2.1524 - val_accuracy: 0.3438\n",
            "Epoch 463/500\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 2.1530 - val_accuracy: 0.3438\n",
            "Epoch 464/500\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 2.1538 - val_accuracy: 0.3438\n",
            "Epoch 465/500\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 2.1561 - val_accuracy: 0.3281\n",
            "Epoch 466/500\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 2.1559 - val_accuracy: 0.3281\n",
            "Epoch 467/500\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 2.1565 - val_accuracy: 0.3281\n",
            "Epoch 468/500\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 2.1573 - val_accuracy: 0.3281\n",
            "Epoch 469/500\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 2.1596 - val_accuracy: 0.3438\n",
            "Epoch 470/500\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 2.1602 - val_accuracy: 0.3438\n",
            "Epoch 471/500\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 2.1574 - val_accuracy: 0.3438\n",
            "Epoch 472/500\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 2.1581 - val_accuracy: 0.3281\n",
            "Epoch 473/500\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 2.1585 - val_accuracy: 0.3281\n",
            "Epoch 474/500\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 2.1582 - val_accuracy: 0.3281\n",
            "Epoch 475/500\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 2.1581 - val_accuracy: 0.3281\n",
            "Epoch 476/500\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 2.1592 - val_accuracy: 0.3438\n",
            "Epoch 477/500\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 2.1614 - val_accuracy: 0.3281\n",
            "Epoch 478/500\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 2.1618 - val_accuracy: 0.3281\n",
            "Epoch 479/500\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 2.1615 - val_accuracy: 0.3281\n",
            "Epoch 480/500\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 2.1610 - val_accuracy: 0.3438\n",
            "Epoch 481/500\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 2.1609 - val_accuracy: 0.3438\n",
            "Epoch 482/500\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 2.1611 - val_accuracy: 0.3281\n",
            "Epoch 483/500\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 2.1610 - val_accuracy: 0.3281\n",
            "Epoch 484/500\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 2.1597 - val_accuracy: 0.3281\n",
            "Epoch 485/500\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 2.1592 - val_accuracy: 0.3281\n",
            "Epoch 486/500\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 2.1625 - val_accuracy: 0.3281\n",
            "Epoch 487/500\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 2.1616 - val_accuracy: 0.3281\n",
            "Epoch 488/500\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 2.1599 - val_accuracy: 0.3438\n",
            "Epoch 489/500\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 2.1595 - val_accuracy: 0.3438\n",
            "Epoch 490/500\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 2.1601 - val_accuracy: 0.3281\n",
            "Epoch 491/500\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 2.1600 - val_accuracy: 0.3281\n",
            "Epoch 492/500\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 2.1612 - val_accuracy: 0.3281\n",
            "Epoch 493/500\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 2.1604 - val_accuracy: 0.3281\n",
            "Epoch 494/500\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 2.1589 - val_accuracy: 0.3281\n",
            "Epoch 495/500\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 2.1586 - val_accuracy: 0.3281\n",
            "Epoch 496/500\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 2.1588 - val_accuracy: 0.3281\n",
            "Epoch 497/500\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 2.1585 - val_accuracy: 0.3281\n",
            "Epoch 498/500\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 2.1594 - val_accuracy: 0.3438\n",
            "Epoch 499/500\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 2.1613 - val_accuracy: 0.3281\n",
            "Epoch 500/500\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 2.1618 - val_accuracy: 0.3281\n"
          ]
        }
      ],
      "source": [
        " tf.random.set_seed(1234)\n",
        " \n",
        " \"\"\"\n",
        " \n",
        " This line of code sets the seed of TensorFlow's random number generator to 1234. \n",
        " When the seed is set, the random number generator will produce the same random \n",
        " numbers every time the program runs, which can be useful for reproducibility \n",
        " and debugging.\n",
        "\n",
        "In this case, the seed is set so that the same initial weights will be generated\n",
        "for the model every time the program runs, this is useful for reproducing the \n",
        "same results when training a model, comparing different models, or debugging.\n",
        "This is useful for reproducibility and debugging.\n",
        "\n",
        "It's important to note that this line of code only affects the random number\n",
        "generator used by TensorFlow, and not the random number generator used by \n",
        "Python or any other library used in the script.\n",
        " \"\"\"\n",
        " \n",
        " \n",
        "early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=0,restore_best_weights=True)\n",
        "hist_s=model_simple.fit(X_train_50.reshape(-1,dim_50[0],dim_50[0],3), y_train, \n",
        "                     batch_size=50, epochs=500,\n",
        "                     #callbacks=[early_stop],\n",
        "                     validation_data=(X_test_50.reshape(-1,dim_50[0],dim_50[0],3),y_test),verbose=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UGmZ-27P0mhf",
        "outputId": "b3cd07a5-e532-47ce-bddf-82c3d04cf50e",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n",
            "5/5 [==============================] - 1s 86ms/step - loss: 2.8277 - accuracy: 0.1018 - val_loss: 2.6389 - val_accuracy: 0.0781\n",
            "Epoch 2/500\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 2.0351 - accuracy: 0.3628 - val_loss: 2.6426 - val_accuracy: 0.0625\n",
            "Epoch 3/500\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 1.5675 - accuracy: 0.6239 - val_loss: 2.6428 - val_accuracy: 0.0625\n",
            "Epoch 4/500\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 1.2044 - accuracy: 0.7832 - val_loss: 2.6463 - val_accuracy: 0.0781\n",
            "Epoch 5/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.9521 - accuracy: 0.8938 - val_loss: 2.6523 - val_accuracy: 0.1094\n",
            "Epoch 6/500\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.7874 - accuracy: 0.9248 - val_loss: 2.6601 - val_accuracy: 0.1250\n",
            "Epoch 7/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.5939 - accuracy: 0.9823 - val_loss: 2.6671 - val_accuracy: 0.0938\n",
            "Epoch 8/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.4812 - accuracy: 0.9823 - val_loss: 2.6762 - val_accuracy: 0.0625\n",
            "Epoch 9/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.4126 - accuracy: 0.9956 - val_loss: 2.6848 - val_accuracy: 0.0781\n",
            "Epoch 10/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.3486 - accuracy: 0.9956 - val_loss: 2.6969 - val_accuracy: 0.1250\n",
            "Epoch 11/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.2884 - accuracy: 0.9956 - val_loss: 2.7075 - val_accuracy: 0.0938\n",
            "Epoch 12/500\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.2476 - accuracy: 1.0000 - val_loss: 2.7121 - val_accuracy: 0.1250\n",
            "Epoch 13/500\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 0.2138 - accuracy: 1.0000 - val_loss: 2.7262 - val_accuracy: 0.0938\n",
            "Epoch 14/500\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 0.1915 - accuracy: 1.0000 - val_loss: 2.7354 - val_accuracy: 0.1094\n",
            "Epoch 15/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.1679 - accuracy: 1.0000 - val_loss: 2.7500 - val_accuracy: 0.1406\n",
            "Epoch 16/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.1499 - accuracy: 1.0000 - val_loss: 2.7632 - val_accuracy: 0.0938\n",
            "Epoch 17/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.1390 - accuracy: 1.0000 - val_loss: 2.7759 - val_accuracy: 0.0781\n",
            "Epoch 18/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.1268 - accuracy: 1.0000 - val_loss: 2.7881 - val_accuracy: 0.0938\n",
            "Epoch 19/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.1194 - accuracy: 1.0000 - val_loss: 2.7960 - val_accuracy: 0.0469\n",
            "Epoch 20/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.1050 - accuracy: 1.0000 - val_loss: 2.8121 - val_accuracy: 0.0625\n",
            "Epoch 21/500\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 0.0960 - accuracy: 1.0000 - val_loss: 2.8267 - val_accuracy: 0.0625\n",
            "Epoch 22/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.0926 - accuracy: 1.0000 - val_loss: 2.8443 - val_accuracy: 0.0469\n",
            "Epoch 23/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.0874 - accuracy: 1.0000 - val_loss: 2.8642 - val_accuracy: 0.0625\n",
            "Epoch 24/500\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.0844 - accuracy: 1.0000 - val_loss: 2.8796 - val_accuracy: 0.0781\n",
            "Epoch 25/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.0777 - accuracy: 1.0000 - val_loss: 2.8903 - val_accuracy: 0.0625\n",
            "Epoch 26/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.0707 - accuracy: 1.0000 - val_loss: 2.9071 - val_accuracy: 0.0625\n",
            "Epoch 27/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.0684 - accuracy: 1.0000 - val_loss: 2.9216 - val_accuracy: 0.0625\n",
            "Epoch 28/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.0636 - accuracy: 1.0000 - val_loss: 2.9356 - val_accuracy: 0.0938\n",
            "Epoch 29/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.0635 - accuracy: 1.0000 - val_loss: 2.9446 - val_accuracy: 0.0625\n",
            "Epoch 30/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.0598 - accuracy: 1.0000 - val_loss: 2.9642 - val_accuracy: 0.0781\n",
            "Epoch 31/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.0594 - accuracy: 1.0000 - val_loss: 2.9816 - val_accuracy: 0.0625\n",
            "Epoch 32/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.0578 - accuracy: 1.0000 - val_loss: 2.9918 - val_accuracy: 0.0625\n",
            "Epoch 33/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.0538 - accuracy: 1.0000 - val_loss: 2.9984 - val_accuracy: 0.0625\n",
            "Epoch 34/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.0531 - accuracy: 1.0000 - val_loss: 3.0150 - val_accuracy: 0.0625\n",
            "Epoch 35/500\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.0487 - accuracy: 1.0000 - val_loss: 3.0286 - val_accuracy: 0.0625\n",
            "Epoch 36/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.0471 - accuracy: 1.0000 - val_loss: 3.0417 - val_accuracy: 0.0625\n",
            "Epoch 37/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.0434 - accuracy: 1.0000 - val_loss: 3.0526 - val_accuracy: 0.0625\n",
            "Epoch 38/500\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.0443 - accuracy: 1.0000 - val_loss: 3.0591 - val_accuracy: 0.0781\n",
            "Epoch 39/500\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 0.0437 - accuracy: 1.0000 - val_loss: 3.0697 - val_accuracy: 0.0781\n",
            "Epoch 40/500\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.0415 - accuracy: 1.0000 - val_loss: 3.0851 - val_accuracy: 0.0781\n",
            "Epoch 41/500\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 0.0436 - accuracy: 1.0000 - val_loss: 3.0865 - val_accuracy: 0.0781\n",
            "Epoch 42/500\n",
            "5/5 [==============================] - 0s 32ms/step - loss: 0.0384 - accuracy: 1.0000 - val_loss: 3.1015 - val_accuracy: 0.0781\n",
            "Epoch 43/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.0371 - accuracy: 1.0000 - val_loss: 3.1104 - val_accuracy: 0.0781\n",
            "Epoch 44/500\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 0.0371 - accuracy: 1.0000 - val_loss: 3.1194 - val_accuracy: 0.0938\n",
            "Epoch 45/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.0358 - accuracy: 1.0000 - val_loss: 3.1315 - val_accuracy: 0.0938\n",
            "Epoch 46/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.0345 - accuracy: 1.0000 - val_loss: 3.1430 - val_accuracy: 0.0938\n",
            "Epoch 47/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.0343 - accuracy: 1.0000 - val_loss: 3.1475 - val_accuracy: 0.0938\n",
            "Epoch 48/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.0326 - accuracy: 1.0000 - val_loss: 3.1556 - val_accuracy: 0.0938\n",
            "Epoch 49/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.0325 - accuracy: 1.0000 - val_loss: 3.1618 - val_accuracy: 0.0938\n",
            "Epoch 50/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.0314 - accuracy: 1.0000 - val_loss: 3.1645 - val_accuracy: 0.0938\n",
            "Epoch 51/500\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.0310 - accuracy: 1.0000 - val_loss: 3.1767 - val_accuracy: 0.0938\n",
            "Epoch 52/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.0297 - accuracy: 1.0000 - val_loss: 3.1815 - val_accuracy: 0.0938\n",
            "Epoch 53/500\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.0287 - accuracy: 1.0000 - val_loss: 3.1888 - val_accuracy: 0.0938\n",
            "Epoch 54/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.0288 - accuracy: 1.0000 - val_loss: 3.1888 - val_accuracy: 0.1094\n",
            "Epoch 55/500\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.0278 - accuracy: 1.0000 - val_loss: 3.1863 - val_accuracy: 0.0938\n",
            "Epoch 56/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.0268 - accuracy: 1.0000 - val_loss: 3.1875 - val_accuracy: 0.0938\n",
            "Epoch 57/500\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 0.0267 - accuracy: 1.0000 - val_loss: 3.1871 - val_accuracy: 0.0938\n",
            "Epoch 58/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.0261 - accuracy: 1.0000 - val_loss: 3.1844 - val_accuracy: 0.0938\n",
            "Epoch 59/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.0292 - accuracy: 1.0000 - val_loss: 3.1837 - val_accuracy: 0.0938\n",
            "Epoch 60/500\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.0250 - accuracy: 1.0000 - val_loss: 3.1782 - val_accuracy: 0.0938\n",
            "Epoch 61/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.0267 - accuracy: 1.0000 - val_loss: 3.1750 - val_accuracy: 0.0938\n",
            "Epoch 62/500\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.0252 - accuracy: 1.0000 - val_loss: 3.1687 - val_accuracy: 0.0781\n",
            "Epoch 63/500\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 0.0244 - accuracy: 1.0000 - val_loss: 3.1687 - val_accuracy: 0.0781\n",
            "Epoch 64/500\n",
            "5/5 [==============================] - 0s 32ms/step - loss: 0.0248 - accuracy: 1.0000 - val_loss: 3.1662 - val_accuracy: 0.0938\n",
            "Epoch 65/500\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.0232 - accuracy: 1.0000 - val_loss: 3.1631 - val_accuracy: 0.1094\n",
            "Epoch 66/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.0224 - accuracy: 1.0000 - val_loss: 3.1572 - val_accuracy: 0.1250\n",
            "Epoch 67/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.0221 - accuracy: 1.0000 - val_loss: 3.1524 - val_accuracy: 0.1562\n",
            "Epoch 68/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.0221 - accuracy: 1.0000 - val_loss: 3.1432 - val_accuracy: 0.1562\n",
            "Epoch 69/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.0214 - accuracy: 1.0000 - val_loss: 3.1340 - val_accuracy: 0.1562\n",
            "Epoch 70/500\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.0228 - accuracy: 1.0000 - val_loss: 3.1182 - val_accuracy: 0.1562\n",
            "Epoch 71/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.0208 - accuracy: 1.0000 - val_loss: 3.1054 - val_accuracy: 0.1719\n",
            "Epoch 72/500\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.0207 - accuracy: 1.0000 - val_loss: 3.0952 - val_accuracy: 0.1719\n",
            "Epoch 73/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.0197 - accuracy: 1.0000 - val_loss: 3.0891 - val_accuracy: 0.1719\n",
            "Epoch 74/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.0196 - accuracy: 1.0000 - val_loss: 3.0780 - val_accuracy: 0.1719\n",
            "Epoch 75/500\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.0190 - accuracy: 1.0000 - val_loss: 3.0626 - val_accuracy: 0.1875\n",
            "Epoch 76/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.0201 - accuracy: 1.0000 - val_loss: 3.0468 - val_accuracy: 0.1875\n",
            "Epoch 77/500\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 0.0189 - accuracy: 1.0000 - val_loss: 3.0322 - val_accuracy: 0.1875\n",
            "Epoch 78/500\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.0190 - accuracy: 1.0000 - val_loss: 3.0250 - val_accuracy: 0.1875\n",
            "Epoch 79/500\n",
            "5/5 [==============================] - 0s 32ms/step - loss: 0.0178 - accuracy: 1.0000 - val_loss: 3.0028 - val_accuracy: 0.1875\n",
            "Epoch 80/500\n",
            "5/5 [==============================] - 0s 32ms/step - loss: 0.0173 - accuracy: 1.0000 - val_loss: 2.9873 - val_accuracy: 0.1875\n",
            "Epoch 81/500\n",
            "5/5 [==============================] - 0s 32ms/step - loss: 0.0172 - accuracy: 1.0000 - val_loss: 2.9759 - val_accuracy: 0.1875\n",
            "Epoch 82/500\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.0168 - accuracy: 1.0000 - val_loss: 2.9616 - val_accuracy: 0.1875\n",
            "Epoch 83/500\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.0175 - accuracy: 1.0000 - val_loss: 2.9397 - val_accuracy: 0.2031\n",
            "Epoch 84/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.0168 - accuracy: 1.0000 - val_loss: 2.9202 - val_accuracy: 0.2031\n",
            "Epoch 85/500\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 0.0174 - accuracy: 1.0000 - val_loss: 2.9115 - val_accuracy: 0.1875\n",
            "Epoch 86/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.0162 - accuracy: 1.0000 - val_loss: 2.8841 - val_accuracy: 0.1875\n",
            "Epoch 87/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.0162 - accuracy: 1.0000 - val_loss: 2.8661 - val_accuracy: 0.1875\n",
            "Epoch 88/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.0164 - accuracy: 1.0000 - val_loss: 2.8432 - val_accuracy: 0.2031\n",
            "Epoch 89/500\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.0161 - accuracy: 1.0000 - val_loss: 2.8320 - val_accuracy: 0.2031\n",
            "Epoch 90/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.0153 - accuracy: 1.0000 - val_loss: 2.8096 - val_accuracy: 0.2188\n",
            "Epoch 91/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.0153 - accuracy: 1.0000 - val_loss: 2.7902 - val_accuracy: 0.2188\n",
            "Epoch 92/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.0157 - accuracy: 1.0000 - val_loss: 2.7597 - val_accuracy: 0.2031\n",
            "Epoch 93/500\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.0151 - accuracy: 1.0000 - val_loss: 2.7406 - val_accuracy: 0.2188\n",
            "Epoch 94/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.0149 - accuracy: 1.0000 - val_loss: 2.7191 - val_accuracy: 0.2188\n",
            "Epoch 95/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.0146 - accuracy: 1.0000 - val_loss: 2.6870 - val_accuracy: 0.2500\n",
            "Epoch 96/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.0144 - accuracy: 1.0000 - val_loss: 2.6720 - val_accuracy: 0.2344\n",
            "Epoch 97/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.0144 - accuracy: 1.0000 - val_loss: 2.6518 - val_accuracy: 0.2344\n",
            "Epoch 98/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.0143 - accuracy: 1.0000 - val_loss: 2.6252 - val_accuracy: 0.2344\n",
            "Epoch 99/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.0146 - accuracy: 1.0000 - val_loss: 2.6138 - val_accuracy: 0.2344\n",
            "Epoch 100/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.0142 - accuracy: 1.0000 - val_loss: 2.5954 - val_accuracy: 0.2344\n",
            "Epoch 101/500\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0139 - accuracy: 1.0000\n",
            " pruning [ = = = = ]\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 0.0139 - accuracy: 1.0000 - val_loss: 2.5705 - val_accuracy: 0.2344\n",
            "Epoch 102/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 2.2949 - accuracy: 0.2566 - val_loss: 2.7672 - val_accuracy: 0.0938\n",
            "Epoch 103/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 1.9131 - accuracy: 0.4735 - val_loss: 2.7417 - val_accuracy: 0.0781\n",
            "Epoch 104/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 1.6531 - accuracy: 0.6460 - val_loss: 2.7184 - val_accuracy: 0.1094\n",
            "Epoch 105/500\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 1.4477 - accuracy: 0.7301 - val_loss: 2.7545 - val_accuracy: 0.1094\n",
            "Epoch 106/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 1.3040 - accuracy: 0.8186 - val_loss: 2.7817 - val_accuracy: 0.0938\n",
            "Epoch 107/500\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 1.1675 - accuracy: 0.8850 - val_loss: 2.7111 - val_accuracy: 0.1250\n",
            "Epoch 108/500\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 1.0311 - accuracy: 0.9336 - val_loss: 2.7377 - val_accuracy: 0.0781\n",
            "Epoch 109/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.9564 - accuracy: 0.9248 - val_loss: 2.7008 - val_accuracy: 0.1250\n",
            "Epoch 110/500\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.8572 - accuracy: 0.9469 - val_loss: 2.6284 - val_accuracy: 0.1562\n",
            "Epoch 111/500\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.7551 - accuracy: 0.9735\n",
            " pruning [ = = = = ]\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.7551 - accuracy: 0.9735 - val_loss: 2.7386 - val_accuracy: 0.1250\n",
            "Epoch 112/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 1.1871 - accuracy: 0.8938 - val_loss: 2.6772 - val_accuracy: 0.1250\n",
            "Epoch 113/500\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.9861 - accuracy: 0.9115 - val_loss: 2.7111 - val_accuracy: 0.1562\n",
            "Epoch 114/500\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.8447 - accuracy: 0.9690 - val_loss: 2.6501 - val_accuracy: 0.1875\n",
            "Epoch 115/500\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 0.7550 - accuracy: 0.9779 - val_loss: 2.6091 - val_accuracy: 0.2344\n",
            "Epoch 116/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.6891 - accuracy: 0.9779 - val_loss: 2.6763 - val_accuracy: 0.1719\n",
            "Epoch 117/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.6259 - accuracy: 0.9823 - val_loss: 2.6018 - val_accuracy: 0.1875\n",
            "Epoch 118/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.6028 - accuracy: 0.9912 - val_loss: 2.5671 - val_accuracy: 0.1719\n",
            "Epoch 119/500\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.5149 - accuracy: 1.0000 - val_loss: 2.5860 - val_accuracy: 0.1719\n",
            "Epoch 120/500\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.4735 - accuracy: 1.0000 - val_loss: 2.5520 - val_accuracy: 0.2031\n",
            "Epoch 121/500\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.4307 - accuracy: 0.9956\n",
            " pruning [ = = = = ]\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 0.4307 - accuracy: 0.9956 - val_loss: 2.5792 - val_accuracy: 0.1875\n",
            "Epoch 122/500\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.7050 - accuracy: 0.9867 - val_loss: 2.5909 - val_accuracy: 0.1562\n",
            "Epoch 123/500\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 0.6050 - accuracy: 0.9823 - val_loss: 2.5698 - val_accuracy: 0.2188\n",
            "Epoch 124/500\n",
            "5/5 [==============================] - 0s 32ms/step - loss: 0.5363 - accuracy: 1.0000 - val_loss: 2.6021 - val_accuracy: 0.1875\n",
            "Epoch 125/500\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.4851 - accuracy: 0.9956 - val_loss: 2.5395 - val_accuracy: 0.2344\n",
            "Epoch 126/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.4039 - accuracy: 1.0000 - val_loss: 2.4969 - val_accuracy: 0.2656\n",
            "Epoch 127/500\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 0.3879 - accuracy: 0.9956 - val_loss: 2.4646 - val_accuracy: 0.2344\n",
            "Epoch 128/500\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.3412 - accuracy: 1.0000 - val_loss: 2.4625 - val_accuracy: 0.2031\n",
            "Epoch 129/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.3149 - accuracy: 0.9956 - val_loss: 2.4411 - val_accuracy: 0.2344\n",
            "Epoch 130/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.2981 - accuracy: 1.0000 - val_loss: 2.4134 - val_accuracy: 0.2188\n",
            "Epoch 131/500\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.2736 - accuracy: 1.0000\n",
            " pruning [ = = = = ]\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.2736 - accuracy: 1.0000 - val_loss: 2.4685 - val_accuracy: 0.2188\n",
            "Epoch 132/500\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.7610 - accuracy: 0.9912 - val_loss: 2.5006 - val_accuracy: 0.1094\n",
            "Epoch 133/500\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.6679 - accuracy: 0.9735 - val_loss: 2.4146 - val_accuracy: 0.2344\n",
            "Epoch 134/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.5113 - accuracy: 1.0000 - val_loss: 2.4264 - val_accuracy: 0.1875\n",
            "Epoch 135/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.4620 - accuracy: 0.9956 - val_loss: 2.4966 - val_accuracy: 0.2344\n",
            "Epoch 136/500\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.4041 - accuracy: 1.0000 - val_loss: 2.4288 - val_accuracy: 0.1875\n",
            "Epoch 137/500\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.3521 - accuracy: 1.0000 - val_loss: 2.4297 - val_accuracy: 0.2031\n",
            "Epoch 138/500\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.3192 - accuracy: 1.0000 - val_loss: 2.3557 - val_accuracy: 0.2031\n",
            "Epoch 139/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.2982 - accuracy: 1.0000 - val_loss: 2.3407 - val_accuracy: 0.2188\n",
            "Epoch 140/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.2678 - accuracy: 1.0000 - val_loss: 2.3597 - val_accuracy: 0.2188\n",
            "Epoch 141/500\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.2584 - accuracy: 1.0000\n",
            " pruning [ = = = = ]\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.2584 - accuracy: 1.0000 - val_loss: 2.3526 - val_accuracy: 0.2188\n",
            "Epoch 142/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.6195 - accuracy: 1.0000 - val_loss: 2.3537 - val_accuracy: 0.2344\n",
            "Epoch 143/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.5258 - accuracy: 0.9956 - val_loss: 2.3264 - val_accuracy: 0.2969\n",
            "Epoch 144/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.4449 - accuracy: 1.0000 - val_loss: 2.5046 - val_accuracy: 0.1875\n",
            "Epoch 145/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.4040 - accuracy: 1.0000 - val_loss: 2.3674 - val_accuracy: 0.2500\n",
            "Epoch 146/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.3456 - accuracy: 1.0000 - val_loss: 2.3342 - val_accuracy: 0.2812\n",
            "Epoch 147/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.3080 - accuracy: 1.0000 - val_loss: 2.3466 - val_accuracy: 0.2500\n",
            "Epoch 148/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.2861 - accuracy: 1.0000 - val_loss: 2.2963 - val_accuracy: 0.2656\n",
            "Epoch 149/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.2553 - accuracy: 1.0000 - val_loss: 2.2868 - val_accuracy: 0.2812\n",
            "Epoch 150/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.2381 - accuracy: 1.0000 - val_loss: 2.3193 - val_accuracy: 0.2031\n",
            "Epoch 151/500\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.2362 - accuracy: 1.0000\n",
            " pruning [ = = = = ]\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 0.2362 - accuracy: 1.0000 - val_loss: 2.2474 - val_accuracy: 0.2969\n",
            "Epoch 152/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.7244 - accuracy: 0.9867 - val_loss: 2.4079 - val_accuracy: 0.2031\n",
            "Epoch 153/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.5528 - accuracy: 1.0000 - val_loss: 2.5356 - val_accuracy: 0.1719\n",
            "Epoch 154/500\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 0.4581 - accuracy: 1.0000 - val_loss: 2.3578 - val_accuracy: 0.2188\n",
            "Epoch 155/500\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 0.4291 - accuracy: 1.0000 - val_loss: 2.4465 - val_accuracy: 0.1875\n",
            "Epoch 156/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.3518 - accuracy: 1.0000 - val_loss: 2.3805 - val_accuracy: 0.2344\n",
            "Epoch 157/500\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.3051 - accuracy: 1.0000 - val_loss: 2.2709 - val_accuracy: 0.2812\n",
            "Epoch 158/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.2695 - accuracy: 1.0000 - val_loss: 2.2161 - val_accuracy: 0.2656\n",
            "Epoch 159/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.2608 - accuracy: 1.0000 - val_loss: 2.3002 - val_accuracy: 0.2500\n",
            "Epoch 160/500\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.2327 - accuracy: 1.0000 - val_loss: 2.1886 - val_accuracy: 0.2812\n",
            "Epoch 161/500\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 0.2158 - accuracy: 1.0000\n",
            " pruning [ = = = = ]\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.2132 - accuracy: 1.0000 - val_loss: 2.2373 - val_accuracy: 0.2812\n",
            "Epoch 162/500\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.5633 - accuracy: 1.0000 - val_loss: 2.3873 - val_accuracy: 0.2812\n",
            "Epoch 163/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.4280 - accuracy: 1.0000 - val_loss: 2.2687 - val_accuracy: 0.2969\n",
            "Epoch 164/500\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.3923 - accuracy: 1.0000 - val_loss: 2.3642 - val_accuracy: 0.2500\n",
            "Epoch 165/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.3564 - accuracy: 1.0000 - val_loss: 2.3229 - val_accuracy: 0.2500\n",
            "Epoch 166/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.3040 - accuracy: 1.0000 - val_loss: 2.2767 - val_accuracy: 0.2500\n",
            "Epoch 167/500\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.2652 - accuracy: 1.0000 - val_loss: 2.3055 - val_accuracy: 0.2656\n",
            "Epoch 168/500\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.2632 - accuracy: 1.0000 - val_loss: 2.3126 - val_accuracy: 0.2500\n",
            "Epoch 169/500\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.2338 - accuracy: 1.0000 - val_loss: 2.3159 - val_accuracy: 0.2344\n",
            "Epoch 170/500\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.2261 - accuracy: 1.0000 - val_loss: 2.3421 - val_accuracy: 0.2500\n",
            "Epoch 171/500\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.2051 - accuracy: 1.0000\n",
            " pruning [ = = = = ]\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.2051 - accuracy: 1.0000 - val_loss: 2.3208 - val_accuracy: 0.2500\n",
            "Epoch 172/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.7616 - accuracy: 0.9690 - val_loss: 2.3660 - val_accuracy: 0.2656\n",
            "Epoch 173/500\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.6075 - accuracy: 0.9867 - val_loss: 2.7430 - val_accuracy: 0.1250\n",
            "Epoch 174/500\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 0.5377 - accuracy: 0.9956 - val_loss: 2.3281 - val_accuracy: 0.2031\n",
            "Epoch 175/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.4192 - accuracy: 1.0000 - val_loss: 2.4223 - val_accuracy: 0.2344\n",
            "Epoch 176/500\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.3522 - accuracy: 1.0000 - val_loss: 2.3021 - val_accuracy: 0.2656\n",
            "Epoch 177/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.3178 - accuracy: 1.0000 - val_loss: 2.4376 - val_accuracy: 0.2344\n",
            "Epoch 178/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.2772 - accuracy: 1.0000 - val_loss: 2.3600 - val_accuracy: 0.2812\n",
            "Epoch 179/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.2478 - accuracy: 1.0000 - val_loss: 2.3077 - val_accuracy: 0.2812\n",
            "Epoch 180/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.2408 - accuracy: 1.0000 - val_loss: 2.3235 - val_accuracy: 0.2656\n",
            "Epoch 181/500\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.2141 - accuracy: 1.0000\n",
            " pruning [ = = = = ]\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.2141 - accuracy: 1.0000 - val_loss: 2.2824 - val_accuracy: 0.2656\n",
            "Epoch 182/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.6041 - accuracy: 0.9956 - val_loss: 2.3490 - val_accuracy: 0.2344\n",
            "Epoch 183/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.4491 - accuracy: 1.0000 - val_loss: 2.3673 - val_accuracy: 0.2969\n",
            "Epoch 184/500\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 0.3955 - accuracy: 1.0000 - val_loss: 2.3080 - val_accuracy: 0.2500\n",
            "Epoch 185/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.3392 - accuracy: 1.0000 - val_loss: 2.3536 - val_accuracy: 0.2500\n",
            "Epoch 186/500\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.3116 - accuracy: 1.0000 - val_loss: 2.4896 - val_accuracy: 0.2188\n",
            "Epoch 187/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.2898 - accuracy: 1.0000 - val_loss: 2.4396 - val_accuracy: 0.2188\n",
            "Epoch 188/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.2583 - accuracy: 1.0000 - val_loss: 2.3442 - val_accuracy: 0.2969\n",
            "Epoch 189/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.2489 - accuracy: 1.0000 - val_loss: 2.2634 - val_accuracy: 0.2812\n",
            "Epoch 190/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.2123 - accuracy: 1.0000 - val_loss: 2.2829 - val_accuracy: 0.2500\n",
            "Epoch 191/500\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.1969 - accuracy: 1.0000\n",
            " pruning [ = = = = ]\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.1969 - accuracy: 1.0000 - val_loss: 2.2857 - val_accuracy: 0.3125\n",
            "Epoch 192/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.5017 - accuracy: 1.0000 - val_loss: 2.3749 - val_accuracy: 0.2656\n",
            "Epoch 193/500\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 0.4261 - accuracy: 1.0000 - val_loss: 2.3813 - val_accuracy: 0.2656\n",
            "Epoch 194/500\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 0.3440 - accuracy: 1.0000 - val_loss: 2.3510 - val_accuracy: 0.2812\n",
            "Epoch 195/500\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 0.3221 - accuracy: 1.0000 - val_loss: 2.3570 - val_accuracy: 0.2656\n",
            "Epoch 196/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.2671 - accuracy: 1.0000 - val_loss: 2.2869 - val_accuracy: 0.2656\n",
            "Epoch 197/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.2313 - accuracy: 1.0000 - val_loss: 2.2723 - val_accuracy: 0.3125\n",
            "Epoch 198/500\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.2188 - accuracy: 1.0000 - val_loss: 2.2423 - val_accuracy: 0.3438\n",
            "Epoch 199/500\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.1917 - accuracy: 1.0000 - val_loss: 2.2661 - val_accuracy: 0.3125\n",
            "Epoch 200/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.1831 - accuracy: 1.0000 - val_loss: 2.2721 - val_accuracy: 0.2344\n",
            "Epoch 201/500\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.1837 - accuracy: 1.0000\n",
            " pruning [ = = = = ]\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.1837 - accuracy: 1.0000 - val_loss: 2.2364 - val_accuracy: 0.2812\n",
            "Epoch 202/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.6646 - accuracy: 0.9912 - val_loss: 2.5054 - val_accuracy: 0.2188\n",
            "Epoch 203/500\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.5177 - accuracy: 0.9912 - val_loss: 2.3143 - val_accuracy: 0.2969\n",
            "Epoch 204/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.3855 - accuracy: 1.0000 - val_loss: 2.2617 - val_accuracy: 0.2656\n",
            "Epoch 205/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.3854 - accuracy: 1.0000 - val_loss: 2.3174 - val_accuracy: 0.2969\n",
            "Epoch 206/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.3156 - accuracy: 1.0000 - val_loss: 2.2941 - val_accuracy: 0.2656\n",
            "Epoch 207/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.2904 - accuracy: 1.0000 - val_loss: 2.2362 - val_accuracy: 0.2969\n",
            "Epoch 208/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.2605 - accuracy: 1.0000 - val_loss: 2.2826 - val_accuracy: 0.3281\n",
            "Epoch 209/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.2467 - accuracy: 1.0000 - val_loss: 2.2108 - val_accuracy: 0.3281\n",
            "Epoch 210/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.2174 - accuracy: 1.0000 - val_loss: 2.2015 - val_accuracy: 0.2500\n",
            "Epoch 211/500\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.2063 - accuracy: 1.0000\n",
            " pruning [ = = = = ]\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 0.2063 - accuracy: 1.0000 - val_loss: 2.2535 - val_accuracy: 0.2656\n",
            "Epoch 212/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.8875 - accuracy: 0.9336 - val_loss: 2.2332 - val_accuracy: 0.2812\n",
            "Epoch 213/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.6470 - accuracy: 0.9956 - val_loss: 2.3411 - val_accuracy: 0.2344\n",
            "Epoch 214/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.5867 - accuracy: 0.9823 - val_loss: 2.3012 - val_accuracy: 0.2812\n",
            "Epoch 215/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.4396 - accuracy: 0.9912 - val_loss: 2.2386 - val_accuracy: 0.2500\n",
            "Epoch 216/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.4111 - accuracy: 0.9956 - val_loss: 2.2686 - val_accuracy: 0.2969\n",
            "Epoch 217/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.3474 - accuracy: 1.0000 - val_loss: 2.3740 - val_accuracy: 0.2188\n",
            "Epoch 218/500\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.3118 - accuracy: 1.0000 - val_loss: 2.2852 - val_accuracy: 0.3281\n",
            "Epoch 219/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.2909 - accuracy: 1.0000 - val_loss: 2.2288 - val_accuracy: 0.3438\n",
            "Epoch 220/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.2598 - accuracy: 1.0000 - val_loss: 2.1808 - val_accuracy: 0.2500\n",
            "Epoch 221/500\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.2430 - accuracy: 1.0000\n",
            " pruning [ = = = = ]\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.2430 - accuracy: 1.0000 - val_loss: 2.1877 - val_accuracy: 0.3125\n",
            "Epoch 222/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.7384 - accuracy: 0.9912 - val_loss: 2.3671 - val_accuracy: 0.2031\n",
            "Epoch 223/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.5942 - accuracy: 0.9823 - val_loss: 2.3007 - val_accuracy: 0.2812\n",
            "Epoch 224/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.5427 - accuracy: 0.9912 - val_loss: 2.5162 - val_accuracy: 0.2031\n",
            "Epoch 225/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.5180 - accuracy: 1.0000 - val_loss: 2.3220 - val_accuracy: 0.2500\n",
            "Epoch 226/500\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.4546 - accuracy: 0.9912 - val_loss: 2.5700 - val_accuracy: 0.1406\n",
            "Epoch 227/500\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.3737 - accuracy: 1.0000 - val_loss: 2.3107 - val_accuracy: 0.2969\n",
            "Epoch 228/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.3361 - accuracy: 1.0000 - val_loss: 2.2391 - val_accuracy: 0.2344\n",
            "Epoch 229/500\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.3146 - accuracy: 1.0000 - val_loss: 2.2319 - val_accuracy: 0.2812\n",
            "Epoch 230/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.2823 - accuracy: 1.0000 - val_loss: 2.3214 - val_accuracy: 0.2188\n",
            "Epoch 231/500\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.2653 - accuracy: 1.0000\n",
            " pruning [ = = = = ]\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.2653 - accuracy: 1.0000 - val_loss: 2.3016 - val_accuracy: 0.2188\n",
            "Epoch 232/500\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 1.0513 - accuracy: 0.8761 - val_loss: 2.7094 - val_accuracy: 0.1406\n",
            "Epoch 233/500\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 0.8529 - accuracy: 0.9381 - val_loss: 2.4289 - val_accuracy: 0.2656\n",
            "Epoch 234/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.6685 - accuracy: 0.9867 - val_loss: 2.3391 - val_accuracy: 0.2188\n",
            "Epoch 235/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.6292 - accuracy: 0.9779 - val_loss: 2.4505 - val_accuracy: 0.1719\n",
            "Epoch 236/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.5274 - accuracy: 1.0000 - val_loss: 2.3802 - val_accuracy: 0.2500\n",
            "Epoch 237/500\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 0.4653 - accuracy: 0.9956 - val_loss: 2.3266 - val_accuracy: 0.2812\n",
            "Epoch 238/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.4399 - accuracy: 1.0000 - val_loss: 2.3884 - val_accuracy: 0.2344\n",
            "Epoch 239/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.3989 - accuracy: 1.0000 - val_loss: 2.6155 - val_accuracy: 0.1719\n",
            "Epoch 240/500\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.3824 - accuracy: 0.9956 - val_loss: 2.3221 - val_accuracy: 0.2188\n",
            "Epoch 241/500\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.3224 - accuracy: 1.0000\n",
            " pruning [ = = = = ]\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.3224 - accuracy: 1.0000 - val_loss: 2.4185 - val_accuracy: 0.2188\n",
            "Epoch 242/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 1.1626 - accuracy: 0.8230 - val_loss: 2.4961 - val_accuracy: 0.1250\n",
            "Epoch 243/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.9086 - accuracy: 0.9248 - val_loss: 2.4000 - val_accuracy: 0.3125\n",
            "Epoch 244/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.7368 - accuracy: 0.9779 - val_loss: 2.5240 - val_accuracy: 0.2031\n",
            "Epoch 245/500\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.6175 - accuracy: 0.9823 - val_loss: 2.3165 - val_accuracy: 0.2344\n",
            "Epoch 246/500\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.5920 - accuracy: 0.9912 - val_loss: 2.3188 - val_accuracy: 0.2188\n",
            "Epoch 247/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.5186 - accuracy: 0.9912 - val_loss: 2.3679 - val_accuracy: 0.2031\n",
            "Epoch 248/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.4765 - accuracy: 0.9956 - val_loss: 2.3790 - val_accuracy: 0.2500\n",
            "Epoch 249/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.4583 - accuracy: 1.0000 - val_loss: 2.2363 - val_accuracy: 0.2969\n",
            "Epoch 250/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.3818 - accuracy: 1.0000 - val_loss: 2.4289 - val_accuracy: 0.2500\n",
            "Epoch 251/500\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.3504 - accuracy: 1.0000\n",
            " pruning [ = = = = ]\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.3504 - accuracy: 1.0000 - val_loss: 2.3334 - val_accuracy: 0.2031\n",
            "Epoch 252/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 1.3004 - accuracy: 0.7611 - val_loss: 2.4890 - val_accuracy: 0.2500\n",
            "Epoch 253/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 1.1251 - accuracy: 0.8496 - val_loss: 2.4106 - val_accuracy: 0.2500\n",
            "Epoch 254/500\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.9463 - accuracy: 0.9159 - val_loss: 2.4584 - val_accuracy: 0.2344\n",
            "Epoch 255/500\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.8597 - accuracy: 0.9336 - val_loss: 2.6064 - val_accuracy: 0.1875\n",
            "Epoch 256/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.8457 - accuracy: 0.9248 - val_loss: 2.2980 - val_accuracy: 0.2500\n",
            "Epoch 257/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.7430 - accuracy: 0.9646 - val_loss: 2.4309 - val_accuracy: 0.2500\n",
            "Epoch 258/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.6316 - accuracy: 1.0000 - val_loss: 2.3882 - val_accuracy: 0.2344\n",
            "Epoch 259/500\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 0.6052 - accuracy: 1.0000 - val_loss: 2.4375 - val_accuracy: 0.2344\n",
            "Epoch 260/500\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.5551 - accuracy: 0.9956 - val_loss: 2.2730 - val_accuracy: 0.2344\n",
            "Epoch 261/500\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 0.5052 - accuracy: 0.9956 - val_loss: 2.3912 - val_accuracy: 0.1719\n",
            "Epoch 262/500\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.4222 - accuracy: 1.0000 - val_loss: 2.3761 - val_accuracy: 0.2344\n",
            "Epoch 263/500\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.4187 - accuracy: 1.0000 - val_loss: 2.2269 - val_accuracy: 0.2812\n",
            "Epoch 264/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.3699 - accuracy: 1.0000 - val_loss: 2.3469 - val_accuracy: 0.1875\n",
            "Epoch 265/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.3497 - accuracy: 1.0000 - val_loss: 2.2670 - val_accuracy: 0.2188\n",
            "Epoch 266/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.3417 - accuracy: 1.0000 - val_loss: 2.2157 - val_accuracy: 0.3281\n",
            "Epoch 267/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.3036 - accuracy: 1.0000 - val_loss: 2.3123 - val_accuracy: 0.2344\n",
            "Epoch 268/500\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.2763 - accuracy: 1.0000 - val_loss: 2.3462 - val_accuracy: 0.2500\n",
            "Epoch 269/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.2709 - accuracy: 1.0000 - val_loss: 2.2727 - val_accuracy: 0.2344\n",
            "Epoch 270/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.2558 - accuracy: 1.0000 - val_loss: 2.3223 - val_accuracy: 0.2188\n",
            "Epoch 271/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.2294 - accuracy: 1.0000 - val_loss: 2.2834 - val_accuracy: 0.2500\n",
            "Epoch 272/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.2324 - accuracy: 1.0000 - val_loss: 2.3250 - val_accuracy: 0.2344\n",
            "Epoch 273/500\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.2068 - accuracy: 1.0000 - val_loss: 2.2835 - val_accuracy: 0.2344\n",
            "Epoch 274/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.2053 - accuracy: 1.0000 - val_loss: 2.3442 - val_accuracy: 0.2656\n",
            "Epoch 275/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.1970 - accuracy: 1.0000 - val_loss: 2.2594 - val_accuracy: 0.2344\n",
            "Epoch 276/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.1865 - accuracy: 1.0000 - val_loss: 2.2105 - val_accuracy: 0.2031\n",
            "Epoch 277/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.1770 - accuracy: 1.0000 - val_loss: 2.3318 - val_accuracy: 0.2188\n",
            "Epoch 278/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.1636 - accuracy: 1.0000 - val_loss: 2.3340 - val_accuracy: 0.2500\n",
            "Epoch 279/500\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.1688 - accuracy: 1.0000 - val_loss: 2.2862 - val_accuracy: 0.2500\n",
            "Epoch 280/500\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 0.1518 - accuracy: 1.0000 - val_loss: 2.2000 - val_accuracy: 0.2500\n",
            "Epoch 281/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.1487 - accuracy: 1.0000 - val_loss: 2.2610 - val_accuracy: 0.2344\n",
            "Epoch 282/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.1387 - accuracy: 1.0000 - val_loss: 2.1979 - val_accuracy: 0.3281\n",
            "Epoch 283/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.1316 - accuracy: 1.0000 - val_loss: 2.2122 - val_accuracy: 0.2812\n",
            "Epoch 284/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.1273 - accuracy: 1.0000 - val_loss: 2.2438 - val_accuracy: 0.2344\n",
            "Epoch 285/500\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.1268 - accuracy: 1.0000 - val_loss: 2.2327 - val_accuracy: 0.2969\n",
            "Epoch 286/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.1233 - accuracy: 1.0000 - val_loss: 2.2092 - val_accuracy: 0.2656\n",
            "Epoch 287/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.1201 - accuracy: 1.0000 - val_loss: 2.2288 - val_accuracy: 0.2500\n",
            "Epoch 288/500\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.1191 - accuracy: 1.0000 - val_loss: 2.2563 - val_accuracy: 0.2188\n",
            "Epoch 289/500\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.1079 - accuracy: 1.0000 - val_loss: 2.1878 - val_accuracy: 0.2500\n",
            "Epoch 290/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.1041 - accuracy: 1.0000 - val_loss: 2.2081 - val_accuracy: 0.2656\n",
            "Epoch 291/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.1028 - accuracy: 1.0000 - val_loss: 2.2710 - val_accuracy: 0.2812\n",
            "Epoch 292/500\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.0986 - accuracy: 1.0000 - val_loss: 2.2703 - val_accuracy: 0.2656\n",
            "Epoch 293/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.0954 - accuracy: 1.0000 - val_loss: 2.2170 - val_accuracy: 0.2812\n",
            "Epoch 294/500\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.0937 - accuracy: 1.0000 - val_loss: 2.2296 - val_accuracy: 0.2500\n",
            "Epoch 295/500\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.0901 - accuracy: 1.0000 - val_loss: 2.1942 - val_accuracy: 0.2812\n",
            "Epoch 296/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.0882 - accuracy: 1.0000 - val_loss: 2.2272 - val_accuracy: 0.2656\n",
            "Epoch 297/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.0857 - accuracy: 1.0000 - val_loss: 2.2185 - val_accuracy: 0.2500\n",
            "Epoch 298/500\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.0837 - accuracy: 1.0000 - val_loss: 2.2180 - val_accuracy: 0.2656\n",
            "Epoch 299/500\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.0847 - accuracy: 1.0000 - val_loss: 2.2017 - val_accuracy: 0.2656\n",
            "Epoch 300/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.0781 - accuracy: 1.0000 - val_loss: 2.2116 - val_accuracy: 0.3125\n",
            "Epoch 301/500\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.0804 - accuracy: 1.0000 - val_loss: 2.2197 - val_accuracy: 0.2812\n",
            "Epoch 302/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.0817 - accuracy: 1.0000 - val_loss: 2.2249 - val_accuracy: 0.2500\n",
            "Epoch 303/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.0750 - accuracy: 1.0000 - val_loss: 2.1948 - val_accuracy: 0.2969\n",
            "Epoch 304/500\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.0696 - accuracy: 1.0000 - val_loss: 2.2218 - val_accuracy: 0.2656\n",
            "Epoch 305/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.0694 - accuracy: 1.0000 - val_loss: 2.2219 - val_accuracy: 0.2656\n",
            "Epoch 306/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.0688 - accuracy: 1.0000 - val_loss: 2.2006 - val_accuracy: 0.2812\n",
            "Epoch 307/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.0707 - accuracy: 1.0000 - val_loss: 2.2046 - val_accuracy: 0.2500\n",
            "Epoch 308/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.0674 - accuracy: 1.0000 - val_loss: 2.1825 - val_accuracy: 0.2969\n",
            "Epoch 309/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.0665 - accuracy: 1.0000 - val_loss: 2.1967 - val_accuracy: 0.2656\n",
            "Epoch 310/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.0627 - accuracy: 1.0000 - val_loss: 2.1981 - val_accuracy: 0.3125\n",
            "Epoch 311/500\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.0623 - accuracy: 1.0000 - val_loss: 2.2494 - val_accuracy: 0.2500\n",
            "Epoch 312/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.0610 - accuracy: 1.0000 - val_loss: 2.1901 - val_accuracy: 0.2812\n",
            "Epoch 313/500\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 0.0616 - accuracy: 1.0000 - val_loss: 2.2116 - val_accuracy: 0.2656\n",
            "Epoch 314/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.0623 - accuracy: 1.0000 - val_loss: 2.1933 - val_accuracy: 0.3125\n",
            "Epoch 315/500\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.0570 - accuracy: 1.0000 - val_loss: 2.2314 - val_accuracy: 0.2656\n",
            "Epoch 316/500\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.0604 - accuracy: 1.0000 - val_loss: 2.2129 - val_accuracy: 0.2812\n",
            "Epoch 317/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.0585 - accuracy: 1.0000 - val_loss: 2.2292 - val_accuracy: 0.2812\n",
            "Epoch 318/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.0550 - accuracy: 1.0000 - val_loss: 2.2007 - val_accuracy: 0.2969\n",
            "Epoch 319/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.0520 - accuracy: 1.0000 - val_loss: 2.2193 - val_accuracy: 0.2969\n",
            "Epoch 320/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.0543 - accuracy: 1.0000 - val_loss: 2.1846 - val_accuracy: 0.2969\n",
            "Epoch 321/500\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.0528 - accuracy: 1.0000 - val_loss: 2.2237 - val_accuracy: 0.2812\n",
            "Epoch 322/500\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.0512 - accuracy: 1.0000 - val_loss: 2.2297 - val_accuracy: 0.2500\n",
            "Epoch 323/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.0493 - accuracy: 1.0000 - val_loss: 2.2351 - val_accuracy: 0.2656\n",
            "Epoch 324/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.0497 - accuracy: 1.0000 - val_loss: 2.2531 - val_accuracy: 0.2500\n",
            "Epoch 325/500\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.0497 - accuracy: 1.0000 - val_loss: 2.2302 - val_accuracy: 0.2969\n",
            "Epoch 326/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.0510 - accuracy: 1.0000 - val_loss: 2.2605 - val_accuracy: 0.2500\n",
            "Epoch 327/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.0479 - accuracy: 1.0000 - val_loss: 2.2244 - val_accuracy: 0.3281\n",
            "Epoch 328/500\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.0466 - accuracy: 1.0000 - val_loss: 2.2120 - val_accuracy: 0.3125\n",
            "Epoch 329/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.0465 - accuracy: 1.0000 - val_loss: 2.2147 - val_accuracy: 0.3125\n",
            "Epoch 330/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.0468 - accuracy: 1.0000 - val_loss: 2.2355 - val_accuracy: 0.2812\n",
            "Epoch 331/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.0468 - accuracy: 1.0000 - val_loss: 2.2140 - val_accuracy: 0.2812\n",
            "Epoch 332/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.0439 - accuracy: 1.0000 - val_loss: 2.1965 - val_accuracy: 0.3125\n",
            "Epoch 333/500\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.0429 - accuracy: 1.0000 - val_loss: 2.2251 - val_accuracy: 0.2656\n",
            "Epoch 334/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.0433 - accuracy: 1.0000 - val_loss: 2.2330 - val_accuracy: 0.3125\n",
            "Epoch 335/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.0431 - accuracy: 1.0000 - val_loss: 2.1966 - val_accuracy: 0.2969\n",
            "Epoch 336/500\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.0416 - accuracy: 1.0000 - val_loss: 2.2263 - val_accuracy: 0.3281\n",
            "Epoch 337/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.0410 - accuracy: 1.0000 - val_loss: 2.2619 - val_accuracy: 0.3125\n",
            "Epoch 338/500\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 0.0402 - accuracy: 1.0000 - val_loss: 2.2165 - val_accuracy: 0.2656\n",
            "Epoch 339/500\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 0.0391 - accuracy: 1.0000 - val_loss: 2.2467 - val_accuracy: 0.2500\n",
            "Epoch 340/500\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 0.0403 - accuracy: 1.0000 - val_loss: 2.2436 - val_accuracy: 0.2500\n",
            "Epoch 341/500\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 0.0395 - accuracy: 1.0000 - val_loss: 2.2350 - val_accuracy: 0.2969\n",
            "Epoch 342/500\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.0392 - accuracy: 1.0000 - val_loss: 2.2248 - val_accuracy: 0.2344\n",
            "Epoch 343/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.0379 - accuracy: 1.0000 - val_loss: 2.2202 - val_accuracy: 0.2969\n",
            "Epoch 344/500\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.0382 - accuracy: 1.0000 - val_loss: 2.2323 - val_accuracy: 0.2656\n",
            "Epoch 345/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.0369 - accuracy: 1.0000 - val_loss: 2.2283 - val_accuracy: 0.2969\n",
            "Epoch 346/500\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 0.0374 - accuracy: 1.0000 - val_loss: 2.2367 - val_accuracy: 0.2969\n",
            "Epoch 347/500\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.0361 - accuracy: 1.0000 - val_loss: 2.2164 - val_accuracy: 0.2500\n",
            "Epoch 348/500\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.0370 - accuracy: 1.0000 - val_loss: 2.2191 - val_accuracy: 0.2656\n",
            "Epoch 349/500\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.0362 - accuracy: 1.0000 - val_loss: 2.2444 - val_accuracy: 0.2969\n",
            "Epoch 350/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.0349 - accuracy: 1.0000 - val_loss: 2.2385 - val_accuracy: 0.2656\n",
            "Epoch 351/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.0341 - accuracy: 1.0000 - val_loss: 2.2460 - val_accuracy: 0.2969\n",
            "Epoch 352/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.0336 - accuracy: 1.0000 - val_loss: 2.2111 - val_accuracy: 0.3125\n",
            "Epoch 353/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.0343 - accuracy: 1.0000 - val_loss: 2.2265 - val_accuracy: 0.2812\n",
            "Epoch 354/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.0328 - accuracy: 1.0000 - val_loss: 2.2541 - val_accuracy: 0.2188\n",
            "Epoch 355/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.0347 - accuracy: 1.0000 - val_loss: 2.2330 - val_accuracy: 0.2969\n",
            "Epoch 356/500\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.0334 - accuracy: 1.0000 - val_loss: 2.2354 - val_accuracy: 0.3281\n",
            "Epoch 357/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.0317 - accuracy: 1.0000 - val_loss: 2.2251 - val_accuracy: 0.2969\n",
            "Epoch 358/500\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.0324 - accuracy: 1.0000 - val_loss: 2.2369 - val_accuracy: 0.2969\n",
            "Epoch 359/500\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.0310 - accuracy: 1.0000 - val_loss: 2.2245 - val_accuracy: 0.2969\n",
            "Epoch 360/500\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 0.0322 - accuracy: 1.0000 - val_loss: 2.2461 - val_accuracy: 0.2812\n",
            "Epoch 361/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.0321 - accuracy: 1.0000 - val_loss: 2.2280 - val_accuracy: 0.3281\n",
            "Epoch 362/500\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 0.0311 - accuracy: 1.0000 - val_loss: 2.2286 - val_accuracy: 0.2812\n",
            "Epoch 363/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.0296 - accuracy: 1.0000 - val_loss: 2.2469 - val_accuracy: 0.2812\n",
            "Epoch 364/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.0299 - accuracy: 1.0000 - val_loss: 2.2474 - val_accuracy: 0.2969\n",
            "Epoch 365/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.0287 - accuracy: 1.0000 - val_loss: 2.2348 - val_accuracy: 0.3125\n",
            "Epoch 366/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.0293 - accuracy: 1.0000 - val_loss: 2.2329 - val_accuracy: 0.3125\n",
            "Epoch 367/500\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.0288 - accuracy: 1.0000 - val_loss: 2.2400 - val_accuracy: 0.2969\n",
            "Epoch 368/500\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 0.0281 - accuracy: 1.0000 - val_loss: 2.2360 - val_accuracy: 0.2969\n",
            "Epoch 369/500\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 0.0290 - accuracy: 1.0000 - val_loss: 2.2537 - val_accuracy: 0.2812\n",
            "Epoch 370/500\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.0273 - accuracy: 1.0000 - val_loss: 2.2384 - val_accuracy: 0.2969\n",
            "Epoch 371/500\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.0280 - accuracy: 1.0000 - val_loss: 2.2350 - val_accuracy: 0.2812\n",
            "Epoch 372/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.0271 - accuracy: 1.0000 - val_loss: 2.2653 - val_accuracy: 0.2812\n",
            "Epoch 373/500\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.0282 - accuracy: 1.0000 - val_loss: 2.2507 - val_accuracy: 0.3125\n",
            "Epoch 374/500\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.0270 - accuracy: 1.0000 - val_loss: 2.2495 - val_accuracy: 0.2969\n",
            "Epoch 375/500\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.0274 - accuracy: 1.0000 - val_loss: 2.2485 - val_accuracy: 0.2812\n",
            "Epoch 376/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.0276 - accuracy: 1.0000 - val_loss: 2.2393 - val_accuracy: 0.2812\n",
            "Epoch 377/500\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.0263 - accuracy: 1.0000 - val_loss: 2.2286 - val_accuracy: 0.3281\n",
            "Epoch 378/500\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.0259 - accuracy: 1.0000 - val_loss: 2.2372 - val_accuracy: 0.2812\n",
            "Epoch 379/500\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.0258 - accuracy: 1.0000 - val_loss: 2.2617 - val_accuracy: 0.2812\n",
            "Epoch 380/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.0250 - accuracy: 1.0000 - val_loss: 2.2460 - val_accuracy: 0.2812\n",
            "Epoch 381/500\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 0.0263 - accuracy: 1.0000 - val_loss: 2.2447 - val_accuracy: 0.2812\n",
            "Epoch 382/500\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 0.0261 - accuracy: 1.0000 - val_loss: 2.2468 - val_accuracy: 0.2969\n",
            "Epoch 383/500\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.0249 - accuracy: 1.0000 - val_loss: 2.2421 - val_accuracy: 0.2969\n",
            "Epoch 384/500\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 0.0249 - accuracy: 1.0000 - val_loss: 2.2417 - val_accuracy: 0.2969\n",
            "Epoch 385/500\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 0.0245 - accuracy: 1.0000 - val_loss: 2.2300 - val_accuracy: 0.2812\n",
            "Epoch 386/500\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.0242 - accuracy: 1.0000 - val_loss: 2.2456 - val_accuracy: 0.3125\n",
            "Epoch 387/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.0239 - accuracy: 1.0000 - val_loss: 2.2334 - val_accuracy: 0.2969\n",
            "Epoch 388/500\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.0235 - accuracy: 1.0000 - val_loss: 2.2535 - val_accuracy: 0.2812\n",
            "Epoch 389/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.0233 - accuracy: 1.0000 - val_loss: 2.2460 - val_accuracy: 0.2812\n",
            "Epoch 390/500\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.0239 - accuracy: 1.0000 - val_loss: 2.2407 - val_accuracy: 0.2812\n",
            "Epoch 391/500\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.0239 - accuracy: 1.0000 - val_loss: 2.2593 - val_accuracy: 0.2812\n",
            "Epoch 392/500\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 0.0241 - accuracy: 1.0000 - val_loss: 2.2494 - val_accuracy: 0.2812\n",
            "Epoch 393/500\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.0226 - accuracy: 1.0000 - val_loss: 2.2353 - val_accuracy: 0.2812\n",
            "Epoch 394/500\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 0.0227 - accuracy: 1.0000 - val_loss: 2.2435 - val_accuracy: 0.2969\n",
            "Epoch 395/500\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.0222 - accuracy: 1.0000 - val_loss: 2.2399 - val_accuracy: 0.3125\n",
            "Epoch 396/500\n",
            "5/5 [==============================] - 0s 46ms/step - loss: 0.0222 - accuracy: 1.0000 - val_loss: 2.2702 - val_accuracy: 0.2812\n",
            "Epoch 397/500\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.0224 - accuracy: 1.0000 - val_loss: 2.2506 - val_accuracy: 0.2969\n",
            "Epoch 398/500\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.0225 - accuracy: 1.0000 - val_loss: 2.2421 - val_accuracy: 0.2812\n",
            "Epoch 399/500\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.0228 - accuracy: 1.0000 - val_loss: 2.2271 - val_accuracy: 0.3125\n",
            "Epoch 400/500\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.0225 - accuracy: 1.0000 - val_loss: 2.2412 - val_accuracy: 0.2969\n",
            "Epoch 401/500\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 0.0218 - accuracy: 1.0000 - val_loss: 2.2431 - val_accuracy: 0.3125\n",
            "Epoch 402/500\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 0.0207 - accuracy: 1.0000 - val_loss: 2.2402 - val_accuracy: 0.2969\n",
            "Epoch 403/500\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.0209 - accuracy: 1.0000 - val_loss: 2.2300 - val_accuracy: 0.3125\n",
            "Epoch 404/500\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.0206 - accuracy: 1.0000 - val_loss: 2.2406 - val_accuracy: 0.2812\n",
            "Epoch 405/500\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.0216 - accuracy: 1.0000 - val_loss: 2.2478 - val_accuracy: 0.2812\n",
            "Epoch 406/500\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.0207 - accuracy: 1.0000 - val_loss: 2.2421 - val_accuracy: 0.2812\n",
            "Epoch 407/500\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 0.0211 - accuracy: 1.0000 - val_loss: 2.2422 - val_accuracy: 0.3125\n",
            "Epoch 408/500\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.0207 - accuracy: 1.0000 - val_loss: 2.2454 - val_accuracy: 0.3125\n",
            "Epoch 409/500\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 0.0210 - accuracy: 1.0000 - val_loss: 2.2670 - val_accuracy: 0.2812\n",
            "Epoch 410/500\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.0200 - accuracy: 1.0000 - val_loss: 2.2510 - val_accuracy: 0.2812\n",
            "Epoch 411/500\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 0.0200 - accuracy: 1.0000 - val_loss: 2.2549 - val_accuracy: 0.2812\n",
            "Epoch 412/500\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 0.0208 - accuracy: 1.0000 - val_loss: 2.2596 - val_accuracy: 0.3125\n",
            "Epoch 413/500\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 0.0195 - accuracy: 1.0000 - val_loss: 2.2353 - val_accuracy: 0.2812\n",
            "Epoch 414/500\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 0.0197 - accuracy: 1.0000 - val_loss: 2.2670 - val_accuracy: 0.2969\n",
            "Epoch 415/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.0195 - accuracy: 1.0000 - val_loss: 2.2349 - val_accuracy: 0.2812\n",
            "Epoch 416/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.0201 - accuracy: 1.0000 - val_loss: 2.2528 - val_accuracy: 0.2969\n",
            "Epoch 417/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.0185 - accuracy: 1.0000 - val_loss: 2.2581 - val_accuracy: 0.2969\n",
            "Epoch 418/500\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 0.0196 - accuracy: 1.0000 - val_loss: 2.2588 - val_accuracy: 0.2969\n",
            "Epoch 419/500\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.0195 - accuracy: 1.0000 - val_loss: 2.2511 - val_accuracy: 0.2812\n",
            "Epoch 420/500\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 0.0185 - accuracy: 1.0000 - val_loss: 2.2785 - val_accuracy: 0.2969\n",
            "Epoch 421/500\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 0.0194 - accuracy: 1.0000 - val_loss: 2.2580 - val_accuracy: 0.2969\n",
            "Epoch 422/500\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.0193 - accuracy: 1.0000 - val_loss: 2.2362 - val_accuracy: 0.2969\n",
            "Epoch 423/500\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.0195 - accuracy: 1.0000 - val_loss: 2.2391 - val_accuracy: 0.2812\n",
            "Epoch 424/500\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.0177 - accuracy: 1.0000 - val_loss: 2.2451 - val_accuracy: 0.2969\n",
            "Epoch 425/500\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 0.0186 - accuracy: 1.0000 - val_loss: 2.2575 - val_accuracy: 0.2969\n",
            "Epoch 426/500\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.0178 - accuracy: 1.0000 - val_loss: 2.2480 - val_accuracy: 0.2812\n",
            "Epoch 427/500\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.0188 - accuracy: 1.0000 - val_loss: 2.2645 - val_accuracy: 0.2812\n",
            "Epoch 428/500\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.0184 - accuracy: 1.0000 - val_loss: 2.2588 - val_accuracy: 0.2812\n",
            "Epoch 429/500\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.0176 - accuracy: 1.0000 - val_loss: 2.2485 - val_accuracy: 0.2969\n",
            "Epoch 430/500\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 0.0177 - accuracy: 1.0000 - val_loss: 2.2508 - val_accuracy: 0.2969\n",
            "Epoch 431/500\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 0.0174 - accuracy: 1.0000 - val_loss: 2.2459 - val_accuracy: 0.3125\n",
            "Epoch 432/500\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.0177 - accuracy: 1.0000 - val_loss: 2.2446 - val_accuracy: 0.2969\n",
            "Epoch 433/500\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 0.0170 - accuracy: 1.0000 - val_loss: 2.2451 - val_accuracy: 0.2969\n",
            "Epoch 434/500\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 0.0164 - accuracy: 1.0000 - val_loss: 2.2578 - val_accuracy: 0.2812\n",
            "Epoch 435/500\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.0173 - accuracy: 1.0000 - val_loss: 2.2466 - val_accuracy: 0.3125\n",
            "Epoch 436/500\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 0.0165 - accuracy: 1.0000 - val_loss: 2.2510 - val_accuracy: 0.2812\n",
            "Epoch 437/500\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.0167 - accuracy: 1.0000 - val_loss: 2.2475 - val_accuracy: 0.2969\n",
            "Epoch 438/500\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 0.0163 - accuracy: 1.0000 - val_loss: 2.2467 - val_accuracy: 0.2969\n",
            "Epoch 439/500\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.0163 - accuracy: 1.0000 - val_loss: 2.2452 - val_accuracy: 0.2969\n",
            "Epoch 440/500\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.0164 - accuracy: 1.0000 - val_loss: 2.2519 - val_accuracy: 0.2812\n",
            "Epoch 441/500\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.0165 - accuracy: 1.0000 - val_loss: 2.2471 - val_accuracy: 0.2969\n",
            "Epoch 442/500\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.0167 - accuracy: 1.0000 - val_loss: 2.2591 - val_accuracy: 0.2656\n",
            "Epoch 443/500\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.0166 - accuracy: 1.0000 - val_loss: 2.2569 - val_accuracy: 0.2969\n",
            "Epoch 444/500\n",
            "5/5 [==============================] - 0s 45ms/step - loss: 0.0172 - accuracy: 1.0000 - val_loss: 2.2487 - val_accuracy: 0.3125\n",
            "Epoch 445/500\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.0156 - accuracy: 1.0000 - val_loss: 2.2508 - val_accuracy: 0.2969\n",
            "Epoch 446/500\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 0.0163 - accuracy: 1.0000 - val_loss: 2.2619 - val_accuracy: 0.2969\n",
            "Epoch 447/500\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.0166 - accuracy: 1.0000 - val_loss: 2.2676 - val_accuracy: 0.2969\n",
            "Epoch 448/500\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.0159 - accuracy: 1.0000 - val_loss: 2.2443 - val_accuracy: 0.2969\n",
            "Epoch 449/500\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.0158 - accuracy: 1.0000 - val_loss: 2.2593 - val_accuracy: 0.2812\n",
            "Epoch 450/500\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.0156 - accuracy: 1.0000 - val_loss: 2.2747 - val_accuracy: 0.2969\n",
            "Epoch 451/500\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 0.0154 - accuracy: 1.0000 - val_loss: 2.2707 - val_accuracy: 0.2812\n",
            "Epoch 452/500\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.0150 - accuracy: 1.0000 - val_loss: 2.2674 - val_accuracy: 0.2969\n",
            "Epoch 453/500\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.0155 - accuracy: 1.0000 - val_loss: 2.2543 - val_accuracy: 0.2812\n",
            "Epoch 454/500\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 0.0156 - accuracy: 1.0000 - val_loss: 2.2537 - val_accuracy: 0.2969\n",
            "Epoch 455/500\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.0152 - accuracy: 1.0000 - val_loss: 2.2589 - val_accuracy: 0.3281\n",
            "Epoch 456/500\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.0148 - accuracy: 1.0000 - val_loss: 2.2605 - val_accuracy: 0.2812\n",
            "Epoch 457/500\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 0.0148 - accuracy: 1.0000 - val_loss: 2.2608 - val_accuracy: 0.2812\n",
            "Epoch 458/500\n",
            "5/5 [==============================] - 0s 49ms/step - loss: 0.0151 - accuracy: 1.0000 - val_loss: 2.2554 - val_accuracy: 0.2812\n",
            "Epoch 459/500\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.0147 - accuracy: 1.0000 - val_loss: 2.2696 - val_accuracy: 0.2812\n",
            "Epoch 460/500\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 0.0143 - accuracy: 1.0000 - val_loss: 2.2659 - val_accuracy: 0.2812\n",
            "Epoch 461/500\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.0150 - accuracy: 1.0000 - val_loss: 2.2812 - val_accuracy: 0.2812\n",
            "Epoch 462/500\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.0146 - accuracy: 1.0000 - val_loss: 2.2962 - val_accuracy: 0.2656\n",
            "Epoch 463/500\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.0145 - accuracy: 1.0000 - val_loss: 2.2760 - val_accuracy: 0.2812\n",
            "Epoch 464/500\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.0143 - accuracy: 1.0000 - val_loss: 2.2665 - val_accuracy: 0.2812\n",
            "Epoch 465/500\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.0147 - accuracy: 1.0000 - val_loss: 2.2562 - val_accuracy: 0.2812\n",
            "Epoch 466/500\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 0.0141 - accuracy: 1.0000 - val_loss: 2.2662 - val_accuracy: 0.2969\n",
            "Epoch 467/500\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 0.0152 - accuracy: 1.0000 - val_loss: 2.2650 - val_accuracy: 0.2969\n",
            "Epoch 468/500\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 0.0134 - accuracy: 1.0000 - val_loss: 2.2678 - val_accuracy: 0.2812\n",
            "Epoch 469/500\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 0.0148 - accuracy: 1.0000 - val_loss: 2.2922 - val_accuracy: 0.2656\n",
            "Epoch 470/500\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 0.0142 - accuracy: 1.0000 - val_loss: 2.2548 - val_accuracy: 0.3125\n",
            "Epoch 471/500\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 0.0144 - accuracy: 1.0000 - val_loss: 2.2547 - val_accuracy: 0.2969\n",
            "Epoch 472/500\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.0134 - accuracy: 1.0000 - val_loss: 2.2661 - val_accuracy: 0.2969\n",
            "Epoch 473/500\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.0138 - accuracy: 1.0000 - val_loss: 2.2651 - val_accuracy: 0.2812\n",
            "Epoch 474/500\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.0136 - accuracy: 1.0000 - val_loss: 2.2574 - val_accuracy: 0.2812\n",
            "Epoch 475/500\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 0.0142 - accuracy: 1.0000 - val_loss: 2.2669 - val_accuracy: 0.2969\n",
            "Epoch 476/500\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.0141 - accuracy: 1.0000 - val_loss: 2.2699 - val_accuracy: 0.2812\n",
            "Epoch 477/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.0135 - accuracy: 1.0000 - val_loss: 2.2698 - val_accuracy: 0.2812\n",
            "Epoch 478/500\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 0.0138 - accuracy: 1.0000 - val_loss: 2.2868 - val_accuracy: 0.3125\n",
            "Epoch 479/500\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.0136 - accuracy: 1.0000 - val_loss: 2.2782 - val_accuracy: 0.2969\n",
            "Epoch 480/500\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.0134 - accuracy: 1.0000 - val_loss: 2.2701 - val_accuracy: 0.2969\n",
            "Epoch 481/500\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.0127 - accuracy: 1.0000 - val_loss: 2.2709 - val_accuracy: 0.2969\n",
            "Epoch 482/500\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.0136 - accuracy: 1.0000 - val_loss: 2.2691 - val_accuracy: 0.2969\n",
            "Epoch 483/500\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.0137 - accuracy: 1.0000 - val_loss: 2.2587 - val_accuracy: 0.2812\n",
            "Epoch 484/500\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.0144 - accuracy: 1.0000 - val_loss: 2.2577 - val_accuracy: 0.2969\n",
            "Epoch 485/500\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.0130 - accuracy: 1.0000 - val_loss: 2.2605 - val_accuracy: 0.2812\n",
            "Epoch 486/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.0130 - accuracy: 1.0000 - val_loss: 2.2722 - val_accuracy: 0.2969\n",
            "Epoch 487/500\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.0130 - accuracy: 1.0000 - val_loss: 2.2561 - val_accuracy: 0.2969\n",
            "Epoch 488/500\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 0.0127 - accuracy: 1.0000 - val_loss: 2.2705 - val_accuracy: 0.3125\n",
            "Epoch 489/500\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.0128 - accuracy: 1.0000 - val_loss: 2.2794 - val_accuracy: 0.3125\n",
            "Epoch 490/500\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.0127 - accuracy: 1.0000 - val_loss: 2.2666 - val_accuracy: 0.3125\n",
            "Epoch 491/500\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.0123 - accuracy: 1.0000 - val_loss: 2.2699 - val_accuracy: 0.2812\n",
            "Epoch 492/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.0125 - accuracy: 1.0000 - val_loss: 2.2777 - val_accuracy: 0.2656\n",
            "Epoch 493/500\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 0.0122 - accuracy: 1.0000 - val_loss: 2.2788 - val_accuracy: 0.2969\n",
            "Epoch 494/500\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.0127 - accuracy: 1.0000 - val_loss: 2.2727 - val_accuracy: 0.2812\n",
            "Epoch 495/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.0123 - accuracy: 1.0000 - val_loss: 2.2619 - val_accuracy: 0.2812\n",
            "Epoch 496/500\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.0123 - accuracy: 1.0000 - val_loss: 2.2673 - val_accuracy: 0.2969\n",
            "Epoch 497/500\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.0124 - accuracy: 1.0000 - val_loss: 2.2744 - val_accuracy: 0.2969\n",
            "Epoch 498/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.0114 - accuracy: 1.0000 - val_loss: 2.2666 - val_accuracy: 0.2812\n",
            "Epoch 499/500\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.0119 - accuracy: 1.0000 - val_loss: 2.2717 - val_accuracy: 0.2812\n",
            "Epoch 500/500\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.0120 - accuracy: 1.0000 - val_loss: 2.2788 - val_accuracy: 0.2969\n"
          ]
        }
      ],
      "source": [
        "pruningcallback_0=PruningCallback(init_step=100, end_step=250,init_sparsity=0.4, end_sparsity=0.75,pruning_step=10)\n",
        "tf.random.set_seed(1234)\n",
        "hist_p=model_to_prune_0.fit(X_train_50.reshape(-1,dim_50[0],dim_50[0],3), y_train, \n",
        "                     batch_size=50, epochs=500,\n",
        "                     callbacks=[pruningcallback_0],\n",
        "                     validation_data=(X_test_50.reshape(-1,dim_50[0],dim_50[0],3),y_test),verbose=1)\n",
        "\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "This code trains the \"model_to_prune_0\" model using the \"fit\" method.\n",
        "The training data is X_train_50 which is reshaped to the input shape \n",
        "of the model using reshape(-1,dim_50[0],dim_50[0],3) and the labels \n",
        "are y_train. The batch_size is set to 50 and the number of training \n",
        "epochs is set to 500.\n",
        "\n",
        "A pruningcallback_0 is also defined and passed to the \"callbacks\" \n",
        "argument of the fit method. The PruningCallback is a callback \n",
        "function provided by TensorFlow's Model Pruning library, \n",
        "it is used to implement the pruning of the model during the training.\n",
        "The pruning process starts at step 100, ends at step 250, and performs\n",
        "pruning every 10 steps. The initial sparsity is set to 0.4, meaning \n",
        "that 40% of the neurons will be pruned and the final sparsity is\n",
        "set to 0.75, meaning that 75% of the neurons will be pruned.\n",
        "\n",
        "The validation data and labels are set to X_test_50 and y_test, \n",
        "respectively. The verbose argument is set to 1, meaning that the\n",
        "progress of the training will be displayed on the console.\n",
        "\n",
        "The results of the training process, including the final accuracy\n",
        "and loss values, are stored in the hist_p variable.\n",
        "\n",
        "It's important to note that this code requires the TensorFlow Model\n",
        "Pruning library to be installed and imported in order to use the PruningCallback.\n",
        "\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cll-VIU1_adh",
        "outputId": "a677c887-d110-4dbb-83bd-365df6b39f1a",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n",
            "5/5 [==============================] - 1s 87ms/step - loss: 2.8283 - accuracy: 0.1018 - val_loss: 2.6390 - val_accuracy: 0.0625\n",
            "Epoch 2/500\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 2.0313 - accuracy: 0.3584 - val_loss: 2.6431 - val_accuracy: 0.0625\n",
            "Epoch 3/500\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 1.5475 - accuracy: 0.6372 - val_loss: 2.6431 - val_accuracy: 0.0625\n",
            "Epoch 4/500\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 1.2143 - accuracy: 0.7965 - val_loss: 2.6466 - val_accuracy: 0.0781\n",
            "Epoch 5/500\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.9558 - accuracy: 0.8761 - val_loss: 2.6530 - val_accuracy: 0.0781\n",
            "Epoch 6/500\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 0.7996 - accuracy: 0.9292 - val_loss: 2.6615 - val_accuracy: 0.1094\n",
            "Epoch 7/500\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 0.5986 - accuracy: 0.9735 - val_loss: 2.6681 - val_accuracy: 0.0781\n",
            "Epoch 8/500\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.4825 - accuracy: 0.9823 - val_loss: 2.6778 - val_accuracy: 0.0625\n",
            "Epoch 9/500\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.4050 - accuracy: 0.9956 - val_loss: 2.6863 - val_accuracy: 0.0625\n",
            "Epoch 10/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.3420 - accuracy: 0.9956 - val_loss: 2.6971 - val_accuracy: 0.0938\n",
            "Epoch 11/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.2833 - accuracy: 1.0000 - val_loss: 2.7087 - val_accuracy: 0.0938\n",
            "Epoch 12/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.2436 - accuracy: 1.0000 - val_loss: 2.7138 - val_accuracy: 0.0938\n",
            "Epoch 13/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.2085 - accuracy: 1.0000 - val_loss: 2.7274 - val_accuracy: 0.0625\n",
            "Epoch 14/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.1899 - accuracy: 1.0000 - val_loss: 2.7365 - val_accuracy: 0.0938\n",
            "Epoch 15/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.1690 - accuracy: 1.0000 - val_loss: 2.7506 - val_accuracy: 0.0938\n",
            "Epoch 16/500\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.1486 - accuracy: 1.0000 - val_loss: 2.7638 - val_accuracy: 0.0781\n",
            "Epoch 17/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.1386 - accuracy: 1.0000 - val_loss: 2.7773 - val_accuracy: 0.0781\n",
            "Epoch 18/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.1266 - accuracy: 1.0000 - val_loss: 2.7887 - val_accuracy: 0.0781\n",
            "Epoch 19/500\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.1187 - accuracy: 1.0000 - val_loss: 2.7969 - val_accuracy: 0.0469\n",
            "Epoch 20/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.1043 - accuracy: 1.0000 - val_loss: 2.8129 - val_accuracy: 0.0469\n",
            "Epoch 21/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.0953 - accuracy: 1.0000 - val_loss: 2.8278 - val_accuracy: 0.0625\n",
            "Epoch 22/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.0924 - accuracy: 1.0000 - val_loss: 2.8442 - val_accuracy: 0.0625\n",
            "Epoch 23/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.0874 - accuracy: 1.0000 - val_loss: 2.8645 - val_accuracy: 0.0625\n",
            "Epoch 24/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.0840 - accuracy: 1.0000 - val_loss: 2.8785 - val_accuracy: 0.0625\n",
            "Epoch 25/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.0774 - accuracy: 1.0000 - val_loss: 2.8882 - val_accuracy: 0.0625\n",
            "Epoch 26/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.0700 - accuracy: 1.0000 - val_loss: 2.9060 - val_accuracy: 0.0625\n",
            "Epoch 27/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.0680 - accuracy: 1.0000 - val_loss: 2.9209 - val_accuracy: 0.0781\n",
            "Epoch 28/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.0638 - accuracy: 1.0000 - val_loss: 2.9346 - val_accuracy: 0.0781\n",
            "Epoch 29/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.0631 - accuracy: 1.0000 - val_loss: 2.9447 - val_accuracy: 0.0781\n",
            "Epoch 30/500\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.0597 - accuracy: 1.0000 - val_loss: 2.9630 - val_accuracy: 0.0781\n",
            "Epoch 31/500\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.0590 - accuracy: 1.0000 - val_loss: 2.9803 - val_accuracy: 0.0781\n",
            "Epoch 32/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.0579 - accuracy: 1.0000 - val_loss: 2.9886 - val_accuracy: 0.0625\n",
            "Epoch 33/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.0534 - accuracy: 1.0000 - val_loss: 2.9953 - val_accuracy: 0.0625\n",
            "Epoch 34/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.0530 - accuracy: 1.0000 - val_loss: 3.0110 - val_accuracy: 0.0625\n",
            "Epoch 35/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.0485 - accuracy: 1.0000 - val_loss: 3.0246 - val_accuracy: 0.0625\n",
            "Epoch 36/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.0466 - accuracy: 1.0000 - val_loss: 3.0377 - val_accuracy: 0.0625\n",
            "Epoch 37/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.0433 - accuracy: 1.0000 - val_loss: 3.0476 - val_accuracy: 0.0625\n",
            "Epoch 38/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.0441 - accuracy: 1.0000 - val_loss: 3.0538 - val_accuracy: 0.0625\n",
            "Epoch 39/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.0436 - accuracy: 1.0000 - val_loss: 3.0658 - val_accuracy: 0.0625\n",
            "Epoch 40/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.0412 - accuracy: 1.0000 - val_loss: 3.0814 - val_accuracy: 0.0625\n",
            "Epoch 41/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.0433 - accuracy: 1.0000 - val_loss: 3.0850 - val_accuracy: 0.0625\n",
            "Epoch 42/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.0383 - accuracy: 1.0000 - val_loss: 3.0994 - val_accuracy: 0.0625\n",
            "Epoch 43/500\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.0369 - accuracy: 1.0000 - val_loss: 3.1098 - val_accuracy: 0.0625\n",
            "Epoch 44/500\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.0370 - accuracy: 1.0000 - val_loss: 3.1163 - val_accuracy: 0.0781\n",
            "Epoch 45/500\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.0356 - accuracy: 1.0000 - val_loss: 3.1309 - val_accuracy: 0.0938\n",
            "Epoch 46/500\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.0345 - accuracy: 1.0000 - val_loss: 3.1418 - val_accuracy: 0.0625\n",
            "Epoch 47/500\n",
            "5/5 [==============================] - 0s 32ms/step - loss: 0.0341 - accuracy: 1.0000 - val_loss: 3.1472 - val_accuracy: 0.0938\n",
            "Epoch 48/500\n",
            "5/5 [==============================] - 0s 32ms/step - loss: 0.0325 - accuracy: 1.0000 - val_loss: 3.1577 - val_accuracy: 0.0938\n",
            "Epoch 49/500\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.0323 - accuracy: 1.0000 - val_loss: 3.1631 - val_accuracy: 0.0938\n",
            "Epoch 50/500\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 0.0313 - accuracy: 1.0000 - val_loss: 3.1666 - val_accuracy: 0.0938\n",
            "Epoch 51/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.0309 - accuracy: 1.0000 - val_loss: 3.1817 - val_accuracy: 0.0938\n",
            "Epoch 52/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.0295 - accuracy: 1.0000 - val_loss: 3.1839 - val_accuracy: 0.0938\n",
            "Epoch 53/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.0285 - accuracy: 1.0000 - val_loss: 3.1939 - val_accuracy: 0.0938\n",
            "Epoch 54/500\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.0287 - accuracy: 1.0000 - val_loss: 3.1934 - val_accuracy: 0.0938\n",
            "Epoch 55/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.0278 - accuracy: 1.0000 - val_loss: 3.1929 - val_accuracy: 0.0938\n",
            "Epoch 56/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.0267 - accuracy: 1.0000 - val_loss: 3.1948 - val_accuracy: 0.0938\n",
            "Epoch 57/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.0267 - accuracy: 1.0000 - val_loss: 3.1944 - val_accuracy: 0.0938\n",
            "Epoch 58/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.0260 - accuracy: 1.0000 - val_loss: 3.1974 - val_accuracy: 0.0938\n",
            "Epoch 59/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.0289 - accuracy: 1.0000 - val_loss: 3.1970 - val_accuracy: 0.0938\n",
            "Epoch 60/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.0250 - accuracy: 1.0000 - val_loss: 3.1944 - val_accuracy: 0.0938\n",
            "Epoch 61/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.0266 - accuracy: 1.0000 - val_loss: 3.1894 - val_accuracy: 0.1094\n",
            "Epoch 62/500\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.0251 - accuracy: 1.0000 - val_loss: 3.1844 - val_accuracy: 0.0938\n",
            "Epoch 63/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.0242 - accuracy: 1.0000 - val_loss: 3.1827 - val_accuracy: 0.0938\n",
            "Epoch 64/500\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.0246 - accuracy: 1.0000 - val_loss: 3.1814 - val_accuracy: 0.0938\n",
            "Epoch 65/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.0231 - accuracy: 1.0000 - val_loss: 3.1794 - val_accuracy: 0.0938\n",
            "Epoch 66/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.0223 - accuracy: 1.0000 - val_loss: 3.1723 - val_accuracy: 0.1406\n",
            "Epoch 67/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.0220 - accuracy: 1.0000 - val_loss: 3.1688 - val_accuracy: 0.1406\n",
            "Epoch 68/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.0221 - accuracy: 1.0000 - val_loss: 3.1571 - val_accuracy: 0.1406\n",
            "Epoch 69/500\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.0214 - accuracy: 1.0000 - val_loss: 3.1506 - val_accuracy: 0.1406\n",
            "Epoch 70/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.0228 - accuracy: 1.0000 - val_loss: 3.1376 - val_accuracy: 0.1406\n",
            "Epoch 71/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.0207 - accuracy: 1.0000 - val_loss: 3.1283 - val_accuracy: 0.1406\n",
            "Epoch 72/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.0205 - accuracy: 1.0000 - val_loss: 3.1164 - val_accuracy: 0.1406\n",
            "Epoch 73/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.0196 - accuracy: 1.0000 - val_loss: 3.1138 - val_accuracy: 0.1406\n",
            "Epoch 74/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.0196 - accuracy: 1.0000 - val_loss: 3.1023 - val_accuracy: 0.1406\n",
            "Epoch 75/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.0189 - accuracy: 1.0000 - val_loss: 3.0895 - val_accuracy: 0.1875\n",
            "Epoch 76/500\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.0200 - accuracy: 1.0000 - val_loss: 3.0763 - val_accuracy: 0.1875\n",
            "Epoch 77/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.0189 - accuracy: 1.0000 - val_loss: 3.0589 - val_accuracy: 0.1875\n",
            "Epoch 78/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.0189 - accuracy: 1.0000 - val_loss: 3.0520 - val_accuracy: 0.1719\n",
            "Epoch 79/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.0176 - accuracy: 1.0000 - val_loss: 3.0313 - val_accuracy: 0.1875\n",
            "Epoch 80/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.0173 - accuracy: 1.0000 - val_loss: 3.0126 - val_accuracy: 0.1875\n",
            "Epoch 81/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.0171 - accuracy: 1.0000 - val_loss: 2.9984 - val_accuracy: 0.1875\n",
            "Epoch 82/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.0167 - accuracy: 1.0000 - val_loss: 2.9836 - val_accuracy: 0.1875\n",
            "Epoch 83/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.0175 - accuracy: 1.0000 - val_loss: 2.9661 - val_accuracy: 0.1875\n",
            "Epoch 84/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.0167 - accuracy: 1.0000 - val_loss: 2.9463 - val_accuracy: 0.2031\n",
            "Epoch 85/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.0174 - accuracy: 1.0000 - val_loss: 2.9352 - val_accuracy: 0.2188\n",
            "Epoch 86/500\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.0162 - accuracy: 1.0000 - val_loss: 2.9111 - val_accuracy: 0.2188\n",
            "Epoch 87/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.0161 - accuracy: 1.0000 - val_loss: 2.8938 - val_accuracy: 0.2031\n",
            "Epoch 88/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.0163 - accuracy: 1.0000 - val_loss: 2.8719 - val_accuracy: 0.2031\n",
            "Epoch 89/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.0160 - accuracy: 1.0000 - val_loss: 2.8591 - val_accuracy: 0.2031\n",
            "Epoch 90/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.0153 - accuracy: 1.0000 - val_loss: 2.8365 - val_accuracy: 0.2031\n",
            "Epoch 91/500\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.0154 - accuracy: 1.0000 - val_loss: 2.8211 - val_accuracy: 0.1875\n",
            "Epoch 92/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.0156 - accuracy: 1.0000 - val_loss: 2.7869 - val_accuracy: 0.2031\n",
            "Epoch 93/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.0150 - accuracy: 1.0000 - val_loss: 2.7691 - val_accuracy: 0.2188\n",
            "Epoch 94/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.0148 - accuracy: 1.0000 - val_loss: 2.7525 - val_accuracy: 0.2188\n",
            "Epoch 95/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.0146 - accuracy: 1.0000 - val_loss: 2.7191 - val_accuracy: 0.2188\n",
            "Epoch 96/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.0143 - accuracy: 1.0000 - val_loss: 2.7016 - val_accuracy: 0.2344\n",
            "Epoch 97/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.0143 - accuracy: 1.0000 - val_loss: 2.6798 - val_accuracy: 0.2344\n",
            "Epoch 98/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.0142 - accuracy: 1.0000 - val_loss: 2.6560 - val_accuracy: 0.2344\n",
            "Epoch 99/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.0146 - accuracy: 1.0000 - val_loss: 2.6394 - val_accuracy: 0.2344\n",
            "Epoch 100/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.0141 - accuracy: 1.0000 - val_loss: 2.6230 - val_accuracy: 0.2344\n",
            "Epoch 101/500\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0138 - accuracy: 1.0000\n",
            " pruning [ = = = = ]\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.0138 - accuracy: 1.0000 - val_loss: 2.5996 - val_accuracy: 0.2344\n",
            "Epoch 102/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 2.3245 - accuracy: 0.2522 - val_loss: 2.7650 - val_accuracy: 0.0781\n",
            "Epoch 103/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 1.9469 - accuracy: 0.4336 - val_loss: 2.7485 - val_accuracy: 0.0938\n",
            "Epoch 104/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 1.6924 - accuracy: 0.5841 - val_loss: 2.7688 - val_accuracy: 0.1250\n",
            "Epoch 105/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 1.4964 - accuracy: 0.7345 - val_loss: 2.7723 - val_accuracy: 0.1719\n",
            "Epoch 106/500\n",
            "5/5 [==============================] - ETA: 0s - loss: 1.3436 - accuracy: 0.7788\n",
            " pruning [ = = = = ]\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 1.3436 - accuracy: 0.7788 - val_loss: 2.7828 - val_accuracy: 0.1250\n",
            "Epoch 107/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 1.3460 - accuracy: 0.8053 - val_loss: 2.7245 - val_accuracy: 0.1719\n",
            "Epoch 108/500\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 1.1839 - accuracy: 0.8761 - val_loss: 2.7083 - val_accuracy: 0.1562\n",
            "Epoch 109/500\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 1.0676 - accuracy: 0.9204 - val_loss: 2.6853 - val_accuracy: 0.1406\n",
            "Epoch 110/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.9695 - accuracy: 0.9469 - val_loss: 2.6534 - val_accuracy: 0.1562\n",
            "Epoch 111/500\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.8685 - accuracy: 0.9646\n",
            " pruning [ = = = = ]\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.8685 - accuracy: 0.9646 - val_loss: 2.6585 - val_accuracy: 0.1406\n",
            "Epoch 112/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 1.0629 - accuracy: 0.9248 - val_loss: 2.6094 - val_accuracy: 0.1562\n",
            "Epoch 113/500\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 0.9234 - accuracy: 0.9513 - val_loss: 2.6982 - val_accuracy: 0.1562\n",
            "Epoch 114/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.8070 - accuracy: 0.9690 - val_loss: 2.6376 - val_accuracy: 0.1719\n",
            "Epoch 115/500\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.7234 - accuracy: 0.9867 - val_loss: 2.5812 - val_accuracy: 0.1562\n",
            "Epoch 116/500\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.6700 - accuracy: 0.9690\n",
            " pruning [ = = = = ]\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.6700 - accuracy: 0.9690 - val_loss: 2.5802 - val_accuracy: 0.1562\n",
            "Epoch 117/500\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.9029 - accuracy: 0.9425 - val_loss: 2.6186 - val_accuracy: 0.1562\n",
            "Epoch 118/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.8273 - accuracy: 0.9469 - val_loss: 2.5594 - val_accuracy: 0.2031\n",
            "Epoch 119/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.6623 - accuracy: 0.9867 - val_loss: 2.5866 - val_accuracy: 0.2344\n",
            "Epoch 120/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.5931 - accuracy: 0.9912 - val_loss: 2.5314 - val_accuracy: 0.1562\n",
            "Epoch 121/500\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 0.5319 - accuracy: 0.9900\n",
            " pruning [ = = = = ]\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.5359 - accuracy: 0.9912 - val_loss: 2.5745 - val_accuracy: 0.2031\n",
            "Epoch 122/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.7652 - accuracy: 0.9602 - val_loss: 2.6141 - val_accuracy: 0.2656\n",
            "Epoch 123/500\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.6505 - accuracy: 0.9912 - val_loss: 2.6286 - val_accuracy: 0.2344\n",
            "Epoch 124/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.5917 - accuracy: 0.9912 - val_loss: 2.5471 - val_accuracy: 0.2031\n",
            "Epoch 125/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.5190 - accuracy: 0.9912 - val_loss: 2.6048 - val_accuracy: 0.1719\n",
            "Epoch 126/500\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.4439 - accuracy: 0.9956\n",
            " pruning [ = = = = ]\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.4439 - accuracy: 0.9956 - val_loss: 2.4755 - val_accuracy: 0.2188\n",
            "Epoch 127/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.5307 - accuracy: 0.9956 - val_loss: 2.5156 - val_accuracy: 0.1875\n",
            "Epoch 128/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.4573 - accuracy: 1.0000 - val_loss: 2.4912 - val_accuracy: 0.2812\n",
            "Epoch 129/500\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.4437 - accuracy: 0.9956 - val_loss: 2.5353 - val_accuracy: 0.1719\n",
            "Epoch 130/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.3849 - accuracy: 1.0000 - val_loss: 2.3875 - val_accuracy: 0.3125\n",
            "Epoch 131/500\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.3481 - accuracy: 1.0000\n",
            " pruning [ = = = = ]\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.3481 - accuracy: 1.0000 - val_loss: 2.4721 - val_accuracy: 0.2500\n",
            "Epoch 132/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.4691 - accuracy: 1.0000 - val_loss: 2.4910 - val_accuracy: 0.2031\n",
            "Epoch 133/500\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.4432 - accuracy: 1.0000 - val_loss: 2.4463 - val_accuracy: 0.2500\n",
            "Epoch 134/500\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.3794 - accuracy: 1.0000 - val_loss: 2.4080 - val_accuracy: 0.1875\n",
            "Epoch 135/500\n",
            "5/5 [==============================] - 0s 32ms/step - loss: 0.3618 - accuracy: 1.0000 - val_loss: 2.4361 - val_accuracy: 0.2500\n",
            "Epoch 136/500\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.3102 - accuracy: 1.0000\n",
            " pruning [ = = = = ]\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 0.3102 - accuracy: 1.0000 - val_loss: 2.4400 - val_accuracy: 0.1875\n",
            "Epoch 137/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.5919 - accuracy: 0.9956 - val_loss: 2.3883 - val_accuracy: 0.2344\n",
            "Epoch 138/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.4998 - accuracy: 1.0000 - val_loss: 2.3965 - val_accuracy: 0.2188\n",
            "Epoch 139/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.4215 - accuracy: 1.0000 - val_loss: 2.3930 - val_accuracy: 0.2344\n",
            "Epoch 140/500\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.3733 - accuracy: 1.0000 - val_loss: 2.4254 - val_accuracy: 0.2031\n",
            "Epoch 141/500\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.3474 - accuracy: 1.0000\n",
            " pruning [ = = = = ]\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.3474 - accuracy: 1.0000 - val_loss: 2.3400 - val_accuracy: 0.2656\n",
            "Epoch 142/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.5984 - accuracy: 1.0000 - val_loss: 2.3763 - val_accuracy: 0.1406\n",
            "Epoch 143/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.4748 - accuracy: 1.0000 - val_loss: 2.2918 - val_accuracy: 0.2500\n",
            "Epoch 144/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.4028 - accuracy: 1.0000 - val_loss: 2.3702 - val_accuracy: 0.2500\n",
            "Epoch 145/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.3529 - accuracy: 1.0000 - val_loss: 2.4674 - val_accuracy: 0.1406\n",
            "Epoch 146/500\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.3328 - accuracy: 1.0000\n",
            " pruning [ = = = = ]\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 0.3328 - accuracy: 1.0000 - val_loss: 2.2972 - val_accuracy: 0.2969\n",
            "Epoch 147/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.5641 - accuracy: 0.9956 - val_loss: 2.3893 - val_accuracy: 0.2344\n",
            "Epoch 148/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.4465 - accuracy: 1.0000 - val_loss: 2.3151 - val_accuracy: 0.2656\n",
            "Epoch 149/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.3974 - accuracy: 1.0000 - val_loss: 2.3236 - val_accuracy: 0.2344\n",
            "Epoch 150/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.3645 - accuracy: 1.0000 - val_loss: 2.2877 - val_accuracy: 0.2656\n",
            "Epoch 151/500\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.3509 - accuracy: 1.0000\n",
            " pruning [ = = = = ]\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.3509 - accuracy: 1.0000 - val_loss: 2.2178 - val_accuracy: 0.2969\n",
            "Epoch 152/500\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.5444 - accuracy: 1.0000 - val_loss: 2.3275 - val_accuracy: 0.3281\n",
            "Epoch 153/500\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 0.4448 - accuracy: 0.9956 - val_loss: 2.3613 - val_accuracy: 0.2188\n",
            "Epoch 154/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.4174 - accuracy: 1.0000 - val_loss: 2.3586 - val_accuracy: 0.2500\n",
            "Epoch 155/500\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 0.3601 - accuracy: 1.0000 - val_loss: 2.3992 - val_accuracy: 0.2500\n",
            "Epoch 156/500\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.3278 - accuracy: 1.0000\n",
            " pruning [ = = = = ]\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 0.3278 - accuracy: 1.0000 - val_loss: 2.2545 - val_accuracy: 0.2969\n",
            "Epoch 157/500\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.4140 - accuracy: 1.0000 - val_loss: 2.1673 - val_accuracy: 0.2812\n",
            "Epoch 158/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.3455 - accuracy: 1.0000 - val_loss: 2.1749 - val_accuracy: 0.2812\n",
            "Epoch 159/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.3257 - accuracy: 1.0000 - val_loss: 2.2373 - val_accuracy: 0.2812\n",
            "Epoch 160/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.3071 - accuracy: 1.0000 - val_loss: 2.2487 - val_accuracy: 0.2500\n",
            "Epoch 161/500\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.3212 - accuracy: 1.0000\n",
            " pruning [ = = = = ]\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.3212 - accuracy: 1.0000 - val_loss: 2.2419 - val_accuracy: 0.2812\n",
            "Epoch 162/500\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.5115 - accuracy: 0.9956 - val_loss: 2.3352 - val_accuracy: 0.2500\n",
            "Epoch 163/500\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 0.4207 - accuracy: 1.0000 - val_loss: 2.1824 - val_accuracy: 0.3750\n",
            "Epoch 164/500\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.3633 - accuracy: 1.0000 - val_loss: 2.2803 - val_accuracy: 0.2188\n",
            "Epoch 165/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.3252 - accuracy: 1.0000 - val_loss: 2.2436 - val_accuracy: 0.2969\n",
            "Epoch 166/500\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.2836 - accuracy: 1.0000\n",
            " pruning [ = = = = ]\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.2836 - accuracy: 1.0000 - val_loss: 2.2254 - val_accuracy: 0.2500\n",
            "Epoch 167/500\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.5650 - accuracy: 0.9779 - val_loss: 2.3837 - val_accuracy: 0.2500\n",
            "Epoch 168/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.4418 - accuracy: 0.9956 - val_loss: 2.2355 - val_accuracy: 0.3438\n",
            "Epoch 169/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.3925 - accuracy: 1.0000 - val_loss: 2.2404 - val_accuracy: 0.3125\n",
            "Epoch 170/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.3626 - accuracy: 0.9956 - val_loss: 2.3175 - val_accuracy: 0.2812\n",
            "Epoch 171/500\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.3125 - accuracy: 1.0000\n",
            " pruning [ = = = = ]\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.3125 - accuracy: 1.0000 - val_loss: 2.2494 - val_accuracy: 0.2656\n",
            "Epoch 172/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.4621 - accuracy: 1.0000 - val_loss: 2.2593 - val_accuracy: 0.3281\n",
            "Epoch 173/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.4432 - accuracy: 0.9956 - val_loss: 2.2544 - val_accuracy: 0.2344\n",
            "Epoch 174/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.3908 - accuracy: 1.0000 - val_loss: 2.2095 - val_accuracy: 0.3125\n",
            "Epoch 175/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.3391 - accuracy: 0.9956 - val_loss: 2.1795 - val_accuracy: 0.2969\n",
            "Epoch 176/500\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.2969 - accuracy: 1.0000\n",
            " pruning [ = = = = ]\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.2969 - accuracy: 1.0000 - val_loss: 2.1441 - val_accuracy: 0.2969\n",
            "Epoch 177/500\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.5351 - accuracy: 0.9956 - val_loss: 2.3420 - val_accuracy: 0.2500\n",
            "Epoch 178/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.4236 - accuracy: 0.9956 - val_loss: 2.2514 - val_accuracy: 0.3281\n",
            "Epoch 179/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.3842 - accuracy: 0.9956 - val_loss: 2.2613 - val_accuracy: 0.2656\n",
            "Epoch 180/500\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.3579 - accuracy: 1.0000 - val_loss: 2.1967 - val_accuracy: 0.3125\n",
            "Epoch 181/500\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 0.2819 - accuracy: 1.0000\n",
            " pruning [ = = = = ]\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.2849 - accuracy: 1.0000 - val_loss: 2.1835 - val_accuracy: 0.2969\n",
            "Epoch 182/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.6573 - accuracy: 0.9867 - val_loss: 2.2708 - val_accuracy: 0.2656\n",
            "Epoch 183/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.5318 - accuracy: 1.0000 - val_loss: 2.3128 - val_accuracy: 0.2656\n",
            "Epoch 184/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.4797 - accuracy: 1.0000 - val_loss: 2.2750 - val_accuracy: 0.2500\n",
            "Epoch 185/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.4124 - accuracy: 1.0000 - val_loss: 2.2550 - val_accuracy: 0.2500\n",
            "Epoch 186/500\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.3971 - accuracy: 0.9956\n",
            " pruning [ = = = = ]\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.3971 - accuracy: 0.9956 - val_loss: 2.3743 - val_accuracy: 0.2656\n",
            "Epoch 187/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.7873 - accuracy: 0.9425 - val_loss: 2.4384 - val_accuracy: 0.2500\n",
            "Epoch 188/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.5748 - accuracy: 0.9912 - val_loss: 2.3189 - val_accuracy: 0.2812\n",
            "Epoch 189/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.5183 - accuracy: 1.0000 - val_loss: 2.3043 - val_accuracy: 0.2188\n",
            "Epoch 190/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.4497 - accuracy: 1.0000 - val_loss: 2.3577 - val_accuracy: 0.3281\n",
            "Epoch 191/500\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.4118 - accuracy: 0.9956\n",
            " pruning [ = = = = ]\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.4118 - accuracy: 0.9956 - val_loss: 2.1577 - val_accuracy: 0.3125\n",
            "Epoch 192/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.5376 - accuracy: 0.9956 - val_loss: 2.2343 - val_accuracy: 0.3750\n",
            "Epoch 193/500\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.4915 - accuracy: 1.0000 - val_loss: 2.3094 - val_accuracy: 0.2344\n",
            "Epoch 194/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.4330 - accuracy: 1.0000 - val_loss: 2.2510 - val_accuracy: 0.3281\n",
            "Epoch 195/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.4106 - accuracy: 1.0000 - val_loss: 2.3053 - val_accuracy: 0.2344\n",
            "Epoch 196/500\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.3574 - accuracy: 1.0000\n",
            " pruning [ = = = = ]\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.3574 - accuracy: 1.0000 - val_loss: 2.1827 - val_accuracy: 0.2500\n",
            "Epoch 197/500\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 0.7226 - accuracy: 0.9867 - val_loss: 2.2640 - val_accuracy: 0.2812\n",
            "Epoch 198/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.7081 - accuracy: 0.9602 - val_loss: 2.2211 - val_accuracy: 0.2969\n",
            "Epoch 199/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.5156 - accuracy: 1.0000 - val_loss: 2.2248 - val_accuracy: 0.2969\n",
            "Epoch 200/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.4580 - accuracy: 1.0000 - val_loss: 2.3160 - val_accuracy: 0.2188\n",
            "Epoch 201/500\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.4717 - accuracy: 1.0000\n",
            " pruning [ = = = = ]\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.4717 - accuracy: 1.0000 - val_loss: 2.1713 - val_accuracy: 0.3594\n",
            "Epoch 202/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.8465 - accuracy: 0.9735 - val_loss: 2.3457 - val_accuracy: 0.3438\n",
            "Epoch 203/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.7051 - accuracy: 0.9867 - val_loss: 2.3351 - val_accuracy: 0.2656\n",
            "Epoch 204/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.5897 - accuracy: 0.9956 - val_loss: 2.3136 - val_accuracy: 0.3281\n",
            "Epoch 205/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.5574 - accuracy: 0.9956 - val_loss: 2.3373 - val_accuracy: 0.2656\n",
            "Epoch 206/500\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.5175 - accuracy: 1.0000\n",
            " pruning [ = = = = ]\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 0.5175 - accuracy: 1.0000 - val_loss: 2.3601 - val_accuracy: 0.2031\n",
            "Epoch 207/500\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.8587 - accuracy: 0.9425 - val_loss: 2.3398 - val_accuracy: 0.2812\n",
            "Epoch 208/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.6941 - accuracy: 0.9956 - val_loss: 2.4293 - val_accuracy: 0.2344\n",
            "Epoch 209/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.6472 - accuracy: 0.9823 - val_loss: 2.2925 - val_accuracy: 0.2500\n",
            "Epoch 210/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.5744 - accuracy: 0.9912 - val_loss: 2.3916 - val_accuracy: 0.1875\n",
            "Epoch 211/500\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.4949 - accuracy: 1.0000\n",
            " pruning [ = = = = ]\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 0.4949 - accuracy: 1.0000 - val_loss: 2.3560 - val_accuracy: 0.2500\n",
            "Epoch 212/500\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 0.7529 - accuracy: 0.9867 - val_loss: 2.3156 - val_accuracy: 0.3594\n",
            "Epoch 213/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.6671 - accuracy: 0.9823 - val_loss: 2.3140 - val_accuracy: 0.2969\n",
            "Epoch 214/500\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.5881 - accuracy: 0.9912 - val_loss: 2.4119 - val_accuracy: 0.2031\n",
            "Epoch 215/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.5438 - accuracy: 0.9823 - val_loss: 2.4048 - val_accuracy: 0.2969\n",
            "Epoch 216/500\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.4748 - accuracy: 1.0000\n",
            " pruning [ = = = = ]\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.4748 - accuracy: 1.0000 - val_loss: 2.3643 - val_accuracy: 0.2500\n",
            "Epoch 217/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.8700 - accuracy: 0.9469 - val_loss: 2.4028 - val_accuracy: 0.2812\n",
            "Epoch 218/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.7058 - accuracy: 0.9779 - val_loss: 2.3659 - val_accuracy: 0.2344\n",
            "Epoch 219/500\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.6057 - accuracy: 0.9956 - val_loss: 2.5537 - val_accuracy: 0.1875\n",
            "Epoch 220/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.5672 - accuracy: 0.9956 - val_loss: 2.3221 - val_accuracy: 0.2812\n",
            "Epoch 221/500\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.4873 - accuracy: 1.0000\n",
            " pruning [ = = = = ]\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.4873 - accuracy: 1.0000 - val_loss: 2.3051 - val_accuracy: 0.2656\n",
            "Epoch 222/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 1.0738 - accuracy: 0.9027 - val_loss: 2.4982 - val_accuracy: 0.2500\n",
            "Epoch 223/500\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 0.8758 - accuracy: 0.9779 - val_loss: 2.4412 - val_accuracy: 0.2031\n",
            "Epoch 224/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.7328 - accuracy: 0.9912 - val_loss: 2.3364 - val_accuracy: 0.2969\n",
            "Epoch 225/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.6612 - accuracy: 1.0000 - val_loss: 2.3101 - val_accuracy: 0.2344\n",
            "Epoch 226/500\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.7007 - accuracy: 0.9735\n",
            " pruning [ = = = = ]\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.7007 - accuracy: 0.9735 - val_loss: 2.3052 - val_accuracy: 0.2344\n",
            "Epoch 227/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.8152 - accuracy: 0.9779 - val_loss: 2.4115 - val_accuracy: 0.2031\n",
            "Epoch 228/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.7787 - accuracy: 0.9912 - val_loss: 2.3592 - val_accuracy: 0.3125\n",
            "Epoch 229/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.6652 - accuracy: 0.9956 - val_loss: 2.2716 - val_accuracy: 0.2969\n",
            "Epoch 230/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.6140 - accuracy: 0.9912 - val_loss: 2.3661 - val_accuracy: 0.2969\n",
            "Epoch 231/500\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.5698 - accuracy: 0.9912\n",
            " pruning [ = = = = ]\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.5698 - accuracy: 0.9912 - val_loss: 2.3138 - val_accuracy: 0.3750\n",
            "Epoch 232/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 1.1802 - accuracy: 0.8717 - val_loss: 2.5428 - val_accuracy: 0.1719\n",
            "Epoch 233/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.8904 - accuracy: 0.9558 - val_loss: 2.4468 - val_accuracy: 0.2656\n",
            "Epoch 234/500\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.8037 - accuracy: 0.9823 - val_loss: 2.4190 - val_accuracy: 0.2188\n",
            "Epoch 235/500\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.7692 - accuracy: 0.9823 - val_loss: 2.4386 - val_accuracy: 0.2344\n",
            "Epoch 236/500\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.7122 - accuracy: 0.9735\n",
            " pruning [ = = = = ]\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.7122 - accuracy: 0.9735 - val_loss: 2.5512 - val_accuracy: 0.2188\n",
            "Epoch 237/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 1.3635 - accuracy: 0.7743 - val_loss: 2.5551 - val_accuracy: 0.1719\n",
            "Epoch 238/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 1.0379 - accuracy: 0.9071 - val_loss: 2.5772 - val_accuracy: 0.1719\n",
            "Epoch 239/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.9873 - accuracy: 0.9425 - val_loss: 2.4809 - val_accuracy: 0.2188\n",
            "Epoch 240/500\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.8673 - accuracy: 0.9602 - val_loss: 2.5828 - val_accuracy: 0.1875\n",
            "Epoch 241/500\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.7999 - accuracy: 0.9646\n",
            " pruning [ = = = = ]\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 0.7999 - accuracy: 0.9646 - val_loss: 2.4497 - val_accuracy: 0.3281\n",
            "Epoch 242/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 1.1096 - accuracy: 0.9115 - val_loss: 2.4508 - val_accuracy: 0.2344\n",
            "Epoch 243/500\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 1.0007 - accuracy: 0.9381 - val_loss: 2.4847 - val_accuracy: 0.1875\n",
            "Epoch 244/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.9001 - accuracy: 0.9425 - val_loss: 2.5060 - val_accuracy: 0.2188\n",
            "Epoch 245/500\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.8272 - accuracy: 0.9779 - val_loss: 2.4344 - val_accuracy: 0.1719\n",
            "Epoch 246/500\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 0.7590 - accuracy: 0.9750\n",
            " pruning [ = = = = ]\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 0.7630 - accuracy: 0.9779 - val_loss: 2.4061 - val_accuracy: 0.2656\n",
            "Epoch 247/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 1.3027 - accuracy: 0.8142 - val_loss: 2.5418 - val_accuracy: 0.2344\n",
            "Epoch 248/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 1.0912 - accuracy: 0.9159 - val_loss: 2.4808 - val_accuracy: 0.2031\n",
            "Epoch 249/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 1.0295 - accuracy: 0.9248 - val_loss: 2.5059 - val_accuracy: 0.1719\n",
            "Epoch 250/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.9128 - accuracy: 0.9513 - val_loss: 2.4585 - val_accuracy: 0.2500\n",
            "Epoch 251/500\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.8645 - accuracy: 0.9735\n",
            " pruning [ = = = = ]\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.8645 - accuracy: 0.9735 - val_loss: 2.5121 - val_accuracy: 0.2344\n",
            "Epoch 252/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 1.1116 - accuracy: 0.9292 - val_loss: 2.5078 - val_accuracy: 0.2188\n",
            "Epoch 253/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 1.1040 - accuracy: 0.8938 - val_loss: 2.5193 - val_accuracy: 0.2188\n",
            "Epoch 254/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.9870 - accuracy: 0.9469 - val_loss: 2.4759 - val_accuracy: 0.2344\n",
            "Epoch 255/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.9233 - accuracy: 0.9425 - val_loss: 2.5277 - val_accuracy: 0.1406\n",
            "Epoch 256/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.9285 - accuracy: 0.9336 - val_loss: 2.5587 - val_accuracy: 0.1250\n",
            "Epoch 257/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.8245 - accuracy: 0.9558 - val_loss: 2.4911 - val_accuracy: 0.1875\n",
            "Epoch 258/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.7186 - accuracy: 0.9690 - val_loss: 2.5564 - val_accuracy: 0.1250\n",
            "Epoch 259/500\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 0.6771 - accuracy: 0.9956 - val_loss: 2.5913 - val_accuracy: 0.1719\n",
            "Epoch 260/500\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.7693 - accuracy: 0.9690 - val_loss: 2.4232 - val_accuracy: 0.1875\n",
            "Epoch 261/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.6407 - accuracy: 0.9912 - val_loss: 2.5681 - val_accuracy: 0.1562\n",
            "Epoch 262/500\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 0.5798 - accuracy: 0.9912 - val_loss: 2.4754 - val_accuracy: 0.2031\n",
            "Epoch 263/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.5228 - accuracy: 1.0000 - val_loss: 2.5229 - val_accuracy: 0.2031\n",
            "Epoch 264/500\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.5418 - accuracy: 0.9956 - val_loss: 2.4978 - val_accuracy: 0.1875\n",
            "Epoch 265/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.5032 - accuracy: 0.9912 - val_loss: 2.4809 - val_accuracy: 0.1875\n",
            "Epoch 266/500\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.4757 - accuracy: 1.0000 - val_loss: 2.4289 - val_accuracy: 0.2031\n",
            "Epoch 267/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.4238 - accuracy: 1.0000 - val_loss: 2.5328 - val_accuracy: 0.1719\n",
            "Epoch 268/500\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.4204 - accuracy: 1.0000 - val_loss: 2.4982 - val_accuracy: 0.1719\n",
            "Epoch 269/500\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.4090 - accuracy: 0.9956 - val_loss: 2.4784 - val_accuracy: 0.1562\n",
            "Epoch 270/500\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.3813 - accuracy: 0.9956 - val_loss: 2.5549 - val_accuracy: 0.1875\n",
            "Epoch 271/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.3658 - accuracy: 0.9956 - val_loss: 2.5380 - val_accuracy: 0.1875\n",
            "Epoch 272/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.3341 - accuracy: 1.0000 - val_loss: 2.5184 - val_accuracy: 0.2031\n",
            "Epoch 273/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.3443 - accuracy: 1.0000 - val_loss: 2.5159 - val_accuracy: 0.1562\n",
            "Epoch 274/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.3148 - accuracy: 1.0000 - val_loss: 2.5265 - val_accuracy: 0.2344\n",
            "Epoch 275/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.2780 - accuracy: 1.0000 - val_loss: 2.4725 - val_accuracy: 0.1562\n",
            "Epoch 276/500\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.2793 - accuracy: 1.0000 - val_loss: 2.4991 - val_accuracy: 0.1406\n",
            "Epoch 277/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.2615 - accuracy: 1.0000 - val_loss: 2.4794 - val_accuracy: 0.1719\n",
            "Epoch 278/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.2471 - accuracy: 1.0000 - val_loss: 2.5433 - val_accuracy: 0.1562\n",
            "Epoch 279/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.2681 - accuracy: 1.0000 - val_loss: 2.5192 - val_accuracy: 0.2031\n",
            "Epoch 280/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.2289 - accuracy: 1.0000 - val_loss: 2.4454 - val_accuracy: 0.2500\n",
            "Epoch 281/500\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.2249 - accuracy: 1.0000 - val_loss: 2.5616 - val_accuracy: 0.1562\n",
            "Epoch 282/500\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.2194 - accuracy: 1.0000 - val_loss: 2.4940 - val_accuracy: 0.2031\n",
            "Epoch 283/500\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.1922 - accuracy: 1.0000 - val_loss: 2.5247 - val_accuracy: 0.2031\n",
            "Epoch 284/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.1871 - accuracy: 1.0000 - val_loss: 2.5052 - val_accuracy: 0.2031\n",
            "Epoch 285/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.1835 - accuracy: 1.0000 - val_loss: 2.4942 - val_accuracy: 0.1719\n",
            "Epoch 286/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.1894 - accuracy: 1.0000 - val_loss: 2.4839 - val_accuracy: 0.2344\n",
            "Epoch 287/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.1819 - accuracy: 1.0000 - val_loss: 2.4827 - val_accuracy: 0.1719\n",
            "Epoch 288/500\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 0.1718 - accuracy: 1.0000 - val_loss: 2.5549 - val_accuracy: 0.1406\n",
            "Epoch 289/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.1607 - accuracy: 1.0000 - val_loss: 2.4891 - val_accuracy: 0.1875\n",
            "Epoch 290/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.1482 - accuracy: 1.0000 - val_loss: 2.4960 - val_accuracy: 0.1875\n",
            "Epoch 291/500\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.1452 - accuracy: 1.0000 - val_loss: 2.5118 - val_accuracy: 0.1875\n",
            "Epoch 292/500\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.1435 - accuracy: 1.0000 - val_loss: 2.5271 - val_accuracy: 0.2031\n",
            "Epoch 293/500\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.1385 - accuracy: 1.0000 - val_loss: 2.5080 - val_accuracy: 0.1875\n",
            "Epoch 294/500\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.1385 - accuracy: 1.0000 - val_loss: 2.5186 - val_accuracy: 0.2188\n",
            "Epoch 295/500\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.1298 - accuracy: 1.0000 - val_loss: 2.4838 - val_accuracy: 0.2031\n",
            "Epoch 296/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.1229 - accuracy: 1.0000 - val_loss: 2.4950 - val_accuracy: 0.1875\n",
            "Epoch 297/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.1244 - accuracy: 1.0000 - val_loss: 2.5196 - val_accuracy: 0.2031\n",
            "Epoch 298/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.1183 - accuracy: 1.0000 - val_loss: 2.5039 - val_accuracy: 0.2344\n",
            "Epoch 299/500\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.1187 - accuracy: 1.0000 - val_loss: 2.4922 - val_accuracy: 0.2031\n",
            "Epoch 300/500\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.1097 - accuracy: 1.0000 - val_loss: 2.4942 - val_accuracy: 0.1719\n",
            "Epoch 301/500\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.1133 - accuracy: 1.0000 - val_loss: 2.4954 - val_accuracy: 0.1875\n",
            "Epoch 302/500\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 0.1151 - accuracy: 1.0000 - val_loss: 2.5191 - val_accuracy: 0.2031\n",
            "Epoch 303/500\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 0.1067 - accuracy: 1.0000 - val_loss: 2.5237 - val_accuracy: 0.2344\n",
            "Epoch 304/500\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 0.0965 - accuracy: 1.0000 - val_loss: 2.5148 - val_accuracy: 0.2188\n",
            "Epoch 305/500\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 0.0971 - accuracy: 1.0000 - val_loss: 2.5292 - val_accuracy: 0.1719\n",
            "Epoch 306/500\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.0960 - accuracy: 1.0000 - val_loss: 2.4827 - val_accuracy: 0.2031\n",
            "Epoch 307/500\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.1005 - accuracy: 1.0000 - val_loss: 2.4950 - val_accuracy: 0.2188\n",
            "Epoch 308/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.0928 - accuracy: 1.0000 - val_loss: 2.5205 - val_accuracy: 0.2344\n",
            "Epoch 309/500\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.0901 - accuracy: 1.0000 - val_loss: 2.4902 - val_accuracy: 0.2500\n",
            "Epoch 310/500\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.0866 - accuracy: 1.0000 - val_loss: 2.5208 - val_accuracy: 0.2031\n",
            "Epoch 311/500\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.0859 - accuracy: 1.0000 - val_loss: 2.5269 - val_accuracy: 0.2031\n",
            "Epoch 312/500\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 0.0819 - accuracy: 1.0000 - val_loss: 2.4961 - val_accuracy: 0.2188\n",
            "Epoch 313/500\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.0819 - accuracy: 1.0000 - val_loss: 2.5351 - val_accuracy: 0.2188\n",
            "Epoch 314/500\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.0828 - accuracy: 1.0000 - val_loss: 2.5111 - val_accuracy: 0.2031\n",
            "Epoch 315/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.0774 - accuracy: 1.0000 - val_loss: 2.5450 - val_accuracy: 0.2188\n",
            "Epoch 316/500\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.0791 - accuracy: 1.0000 - val_loss: 2.5223 - val_accuracy: 0.2031\n",
            "Epoch 317/500\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.0792 - accuracy: 1.0000 - val_loss: 2.5165 - val_accuracy: 0.1875\n",
            "Epoch 318/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.0740 - accuracy: 1.0000 - val_loss: 2.5044 - val_accuracy: 0.2188\n",
            "Epoch 319/500\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.0693 - accuracy: 1.0000 - val_loss: 2.5380 - val_accuracy: 0.2188\n",
            "Epoch 320/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.0716 - accuracy: 1.0000 - val_loss: 2.5054 - val_accuracy: 0.2031\n",
            "Epoch 321/500\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.0703 - accuracy: 1.0000 - val_loss: 2.5274 - val_accuracy: 0.2344\n",
            "Epoch 322/500\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 0.0691 - accuracy: 1.0000 - val_loss: 2.5419 - val_accuracy: 0.2031\n",
            "Epoch 323/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.0667 - accuracy: 1.0000 - val_loss: 2.5637 - val_accuracy: 0.1562\n",
            "Epoch 324/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.0667 - accuracy: 1.0000 - val_loss: 2.5742 - val_accuracy: 0.2188\n",
            "Epoch 325/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.0686 - accuracy: 1.0000 - val_loss: 2.5145 - val_accuracy: 0.2344\n",
            "Epoch 326/500\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.0672 - accuracy: 1.0000 - val_loss: 2.5411 - val_accuracy: 0.1562\n",
            "Epoch 327/500\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.0642 - accuracy: 1.0000 - val_loss: 2.5659 - val_accuracy: 0.1719\n",
            "Epoch 328/500\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.0629 - accuracy: 1.0000 - val_loss: 2.5272 - val_accuracy: 0.2031\n",
            "Epoch 329/500\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.0605 - accuracy: 1.0000 - val_loss: 2.5352 - val_accuracy: 0.2188\n",
            "Epoch 330/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.0608 - accuracy: 1.0000 - val_loss: 2.5295 - val_accuracy: 0.2031\n",
            "Epoch 331/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.0612 - accuracy: 1.0000 - val_loss: 2.5218 - val_accuracy: 0.2188\n",
            "Epoch 332/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.0587 - accuracy: 1.0000 - val_loss: 2.5415 - val_accuracy: 0.2031\n",
            "Epoch 333/500\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.0557 - accuracy: 1.0000 - val_loss: 2.5617 - val_accuracy: 0.2344\n",
            "Epoch 334/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.0561 - accuracy: 1.0000 - val_loss: 2.5644 - val_accuracy: 0.2188\n",
            "Epoch 335/500\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.0561 - accuracy: 1.0000 - val_loss: 2.5432 - val_accuracy: 0.2031\n",
            "Epoch 336/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.0549 - accuracy: 1.0000 - val_loss: 2.5421 - val_accuracy: 0.1875\n",
            "Epoch 337/500\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 0.0526 - accuracy: 1.0000 - val_loss: 2.5597 - val_accuracy: 0.1875\n",
            "Epoch 338/500\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.0530 - accuracy: 1.0000 - val_loss: 2.5485 - val_accuracy: 0.2031\n",
            "Epoch 339/500\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.0501 - accuracy: 1.0000 - val_loss: 2.5466 - val_accuracy: 0.1875\n",
            "Epoch 340/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.0517 - accuracy: 1.0000 - val_loss: 2.5490 - val_accuracy: 0.2031\n",
            "Epoch 341/500\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 0.0528 - accuracy: 1.0000 - val_loss: 2.5569 - val_accuracy: 0.1719\n",
            "Epoch 342/500\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 0.0504 - accuracy: 1.0000 - val_loss: 2.5475 - val_accuracy: 0.2188\n",
            "Epoch 343/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.0495 - accuracy: 1.0000 - val_loss: 2.5491 - val_accuracy: 0.2031\n",
            "Epoch 344/500\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.0501 - accuracy: 1.0000 - val_loss: 2.5585 - val_accuracy: 0.2031\n",
            "Epoch 345/500\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.0476 - accuracy: 1.0000 - val_loss: 2.5298 - val_accuracy: 0.1875\n",
            "Epoch 346/500\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.0463 - accuracy: 1.0000 - val_loss: 2.5720 - val_accuracy: 0.2031\n",
            "Epoch 347/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.0473 - accuracy: 1.0000 - val_loss: 2.5425 - val_accuracy: 0.2031\n",
            "Epoch 348/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.0466 - accuracy: 1.0000 - val_loss: 2.5469 - val_accuracy: 0.1875\n",
            "Epoch 349/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.0455 - accuracy: 1.0000 - val_loss: 2.5583 - val_accuracy: 0.1719\n",
            "Epoch 350/500\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.0446 - accuracy: 1.0000 - val_loss: 2.5749 - val_accuracy: 0.1719\n",
            "Epoch 351/500\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.0436 - accuracy: 1.0000 - val_loss: 2.5522 - val_accuracy: 0.2031\n",
            "Epoch 352/500\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 0.0424 - accuracy: 1.0000 - val_loss: 2.5798 - val_accuracy: 0.2031\n",
            "Epoch 353/500\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.0435 - accuracy: 1.0000 - val_loss: 2.5783 - val_accuracy: 0.1719\n",
            "Epoch 354/500\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.0410 - accuracy: 1.0000 - val_loss: 2.5621 - val_accuracy: 0.1719\n",
            "Epoch 355/500\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 0.0455 - accuracy: 1.0000 - val_loss: 2.5590 - val_accuracy: 0.1875\n",
            "Epoch 356/500\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.0413 - accuracy: 1.0000 - val_loss: 2.5706 - val_accuracy: 0.1875\n",
            "Epoch 357/500\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.0402 - accuracy: 1.0000 - val_loss: 2.5423 - val_accuracy: 0.1875\n",
            "Epoch 358/500\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.0419 - accuracy: 1.0000 - val_loss: 2.5694 - val_accuracy: 0.2031\n",
            "Epoch 359/500\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 0.0397 - accuracy: 1.0000 - val_loss: 2.5575 - val_accuracy: 0.1719\n",
            "Epoch 360/500\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.0410 - accuracy: 1.0000 - val_loss: 2.5778 - val_accuracy: 0.2188\n",
            "Epoch 361/500\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.0410 - accuracy: 1.0000 - val_loss: 2.5855 - val_accuracy: 0.2188\n",
            "Epoch 362/500\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 0.0399 - accuracy: 1.0000 - val_loss: 2.5489 - val_accuracy: 0.2031\n",
            "Epoch 363/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.0378 - accuracy: 1.0000 - val_loss: 2.5914 - val_accuracy: 0.1719\n",
            "Epoch 364/500\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 0.0378 - accuracy: 1.0000 - val_loss: 2.5833 - val_accuracy: 0.1875\n",
            "Epoch 365/500\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 0.0359 - accuracy: 1.0000 - val_loss: 2.5794 - val_accuracy: 0.1719\n",
            "Epoch 366/500\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 0.0361 - accuracy: 1.0000 - val_loss: 2.5645 - val_accuracy: 0.2031\n",
            "Epoch 367/500\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 0.0365 - accuracy: 1.0000 - val_loss: 2.5793 - val_accuracy: 0.1875\n",
            "Epoch 368/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.0349 - accuracy: 1.0000 - val_loss: 2.5773 - val_accuracy: 0.1875\n",
            "Epoch 369/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.0369 - accuracy: 1.0000 - val_loss: 2.5653 - val_accuracy: 0.1875\n",
            "Epoch 370/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.0345 - accuracy: 1.0000 - val_loss: 2.5663 - val_accuracy: 0.2031\n",
            "Epoch 371/500\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.0341 - accuracy: 1.0000 - val_loss: 2.5867 - val_accuracy: 0.2188\n",
            "Epoch 372/500\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.0339 - accuracy: 1.0000 - val_loss: 2.5967 - val_accuracy: 0.1719\n",
            "Epoch 373/500\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.0367 - accuracy: 1.0000 - val_loss: 2.5898 - val_accuracy: 0.2031\n",
            "Epoch 374/500\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 0.0332 - accuracy: 1.0000 - val_loss: 2.5950 - val_accuracy: 0.1719\n",
            "Epoch 375/500\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.0345 - accuracy: 1.0000 - val_loss: 2.5971 - val_accuracy: 0.1875\n",
            "Epoch 376/500\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.0338 - accuracy: 1.0000 - val_loss: 2.5738 - val_accuracy: 0.1875\n",
            "Epoch 377/500\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.0334 - accuracy: 1.0000 - val_loss: 2.5917 - val_accuracy: 0.2188\n",
            "Epoch 378/500\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.0323 - accuracy: 1.0000 - val_loss: 2.5780 - val_accuracy: 0.1875\n",
            "Epoch 379/500\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 0.0323 - accuracy: 1.0000 - val_loss: 2.6156 - val_accuracy: 0.1719\n",
            "Epoch 380/500\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 0.0311 - accuracy: 1.0000 - val_loss: 2.5775 - val_accuracy: 0.1875\n",
            "Epoch 381/500\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.0319 - accuracy: 1.0000 - val_loss: 2.5938 - val_accuracy: 0.2031\n",
            "Epoch 382/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.0328 - accuracy: 1.0000 - val_loss: 2.6082 - val_accuracy: 0.1875\n",
            "Epoch 383/500\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.0311 - accuracy: 1.0000 - val_loss: 2.5947 - val_accuracy: 0.1875\n",
            "Epoch 384/500\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.0311 - accuracy: 1.0000 - val_loss: 2.5741 - val_accuracy: 0.1719\n",
            "Epoch 385/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.0297 - accuracy: 1.0000 - val_loss: 2.5721 - val_accuracy: 0.2031\n",
            "Epoch 386/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.0305 - accuracy: 1.0000 - val_loss: 2.5986 - val_accuracy: 0.1875\n",
            "Epoch 387/500\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.0290 - accuracy: 1.0000 - val_loss: 2.5915 - val_accuracy: 0.1875\n",
            "Epoch 388/500\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.0292 - accuracy: 1.0000 - val_loss: 2.5893 - val_accuracy: 0.1875\n",
            "Epoch 389/500\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 0.0282 - accuracy: 1.0000 - val_loss: 2.5999 - val_accuracy: 0.1875\n",
            "Epoch 390/500\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 0.0296 - accuracy: 1.0000 - val_loss: 2.5799 - val_accuracy: 0.1719\n",
            "Epoch 391/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.0287 - accuracy: 1.0000 - val_loss: 2.5810 - val_accuracy: 0.1719\n",
            "Epoch 392/500\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 0.0298 - accuracy: 1.0000 - val_loss: 2.5877 - val_accuracy: 0.1719\n",
            "Epoch 393/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.0278 - accuracy: 1.0000 - val_loss: 2.6073 - val_accuracy: 0.2188\n",
            "Epoch 394/500\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 0.0277 - accuracy: 1.0000 - val_loss: 2.5774 - val_accuracy: 0.1719\n",
            "Epoch 395/500\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.0275 - accuracy: 1.0000 - val_loss: 2.5976 - val_accuracy: 0.1875\n",
            "Epoch 396/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.0272 - accuracy: 1.0000 - val_loss: 2.6057 - val_accuracy: 0.1719\n",
            "Epoch 397/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.0282 - accuracy: 1.0000 - val_loss: 2.5870 - val_accuracy: 0.2188\n",
            "Epoch 398/500\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 0.0270 - accuracy: 1.0000 - val_loss: 2.5918 - val_accuracy: 0.2188\n",
            "Epoch 399/500\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 0.0276 - accuracy: 1.0000 - val_loss: 2.5885 - val_accuracy: 0.2188\n",
            "Epoch 400/500\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.0273 - accuracy: 1.0000 - val_loss: 2.6064 - val_accuracy: 0.2031\n",
            "Epoch 401/500\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.0266 - accuracy: 1.0000 - val_loss: 2.5915 - val_accuracy: 0.1719\n",
            "Epoch 402/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.0258 - accuracy: 1.0000 - val_loss: 2.5948 - val_accuracy: 0.1875\n",
            "Epoch 403/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.0254 - accuracy: 1.0000 - val_loss: 2.5905 - val_accuracy: 0.2188\n",
            "Epoch 404/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.0253 - accuracy: 1.0000 - val_loss: 2.5906 - val_accuracy: 0.2188\n",
            "Epoch 405/500\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.0263 - accuracy: 1.0000 - val_loss: 2.6004 - val_accuracy: 0.2031\n",
            "Epoch 406/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.0255 - accuracy: 1.0000 - val_loss: 2.6077 - val_accuracy: 0.2031\n",
            "Epoch 407/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.0267 - accuracy: 1.0000 - val_loss: 2.5762 - val_accuracy: 0.2031\n",
            "Epoch 408/500\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.0251 - accuracy: 1.0000 - val_loss: 2.6131 - val_accuracy: 0.1875\n",
            "Epoch 409/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.0257 - accuracy: 1.0000 - val_loss: 2.6298 - val_accuracy: 0.1875\n",
            "Epoch 410/500\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.0241 - accuracy: 1.0000 - val_loss: 2.6036 - val_accuracy: 0.1875\n",
            "Epoch 411/500\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.0237 - accuracy: 1.0000 - val_loss: 2.5972 - val_accuracy: 0.1719\n",
            "Epoch 412/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.0248 - accuracy: 1.0000 - val_loss: 2.6238 - val_accuracy: 0.1719\n",
            "Epoch 413/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.0239 - accuracy: 1.0000 - val_loss: 2.5911 - val_accuracy: 0.1875\n",
            "Epoch 414/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.0238 - accuracy: 1.0000 - val_loss: 2.6318 - val_accuracy: 0.1719\n",
            "Epoch 415/500\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.0237 - accuracy: 1.0000 - val_loss: 2.6050 - val_accuracy: 0.2031\n",
            "Epoch 416/500\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.0247 - accuracy: 1.0000 - val_loss: 2.6257 - val_accuracy: 0.2031\n",
            "Epoch 417/500\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 0.0223 - accuracy: 1.0000 - val_loss: 2.6028 - val_accuracy: 0.1719\n",
            "Epoch 418/500\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 0.0243 - accuracy: 1.0000 - val_loss: 2.6112 - val_accuracy: 0.1719\n",
            "Epoch 419/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.0229 - accuracy: 1.0000 - val_loss: 2.6072 - val_accuracy: 0.1562\n",
            "Epoch 420/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.0223 - accuracy: 1.0000 - val_loss: 2.6243 - val_accuracy: 0.1719\n",
            "Epoch 421/500\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 0.0234 - accuracy: 1.0000 - val_loss: 2.6096 - val_accuracy: 0.1719\n",
            "Epoch 422/500\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.0234 - accuracy: 1.0000 - val_loss: 2.5814 - val_accuracy: 0.1719\n",
            "Epoch 423/500\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.0230 - accuracy: 1.0000 - val_loss: 2.6114 - val_accuracy: 0.2188\n",
            "Epoch 424/500\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 0.0217 - accuracy: 1.0000 - val_loss: 2.6260 - val_accuracy: 0.2031\n",
            "Epoch 425/500\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.0225 - accuracy: 1.0000 - val_loss: 2.6010 - val_accuracy: 0.1719\n",
            "Epoch 426/500\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 0.0216 - accuracy: 1.0000 - val_loss: 2.6027 - val_accuracy: 0.1719\n",
            "Epoch 427/500\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.0225 - accuracy: 1.0000 - val_loss: 2.6251 - val_accuracy: 0.1719\n",
            "Epoch 428/500\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.0224 - accuracy: 1.0000 - val_loss: 2.6055 - val_accuracy: 0.1875\n",
            "Epoch 429/500\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 0.0216 - accuracy: 1.0000 - val_loss: 2.6054 - val_accuracy: 0.2031\n",
            "Epoch 430/500\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.0214 - accuracy: 1.0000 - val_loss: 2.6046 - val_accuracy: 0.1875\n",
            "Epoch 431/500\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 0.0203 - accuracy: 1.0000 - val_loss: 2.6046 - val_accuracy: 0.2031\n",
            "Epoch 432/500\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.0209 - accuracy: 1.0000 - val_loss: 2.6061 - val_accuracy: 0.2188\n",
            "Epoch 433/500\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.0200 - accuracy: 1.0000 - val_loss: 2.5996 - val_accuracy: 0.2031\n",
            "Epoch 434/500\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 0.0200 - accuracy: 1.0000 - val_loss: 2.6134 - val_accuracy: 0.1719\n",
            "Epoch 435/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.0211 - accuracy: 1.0000 - val_loss: 2.5992 - val_accuracy: 0.1719\n",
            "Epoch 436/500\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.0198 - accuracy: 1.0000 - val_loss: 2.6008 - val_accuracy: 0.2031\n",
            "Epoch 437/500\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.0205 - accuracy: 1.0000 - val_loss: 2.6078 - val_accuracy: 0.2031\n",
            "Epoch 438/500\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 0.0194 - accuracy: 1.0000 - val_loss: 2.6145 - val_accuracy: 0.2031\n",
            "Epoch 439/500\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 0.0198 - accuracy: 1.0000 - val_loss: 2.6096 - val_accuracy: 0.1875\n",
            "Epoch 440/500\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.0194 - accuracy: 1.0000 - val_loss: 2.6110 - val_accuracy: 0.1562\n",
            "Epoch 441/500\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.0192 - accuracy: 1.0000 - val_loss: 2.6114 - val_accuracy: 0.2031\n",
            "Epoch 442/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.0196 - accuracy: 1.0000 - val_loss: 2.6290 - val_accuracy: 0.1719\n",
            "Epoch 443/500\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.0200 - accuracy: 1.0000 - val_loss: 2.6253 - val_accuracy: 0.1719\n",
            "Epoch 444/500\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.0199 - accuracy: 1.0000 - val_loss: 2.6284 - val_accuracy: 0.2031\n",
            "Epoch 445/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.0184 - accuracy: 1.0000 - val_loss: 2.6081 - val_accuracy: 0.2031\n",
            "Epoch 446/500\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.0190 - accuracy: 1.0000 - val_loss: 2.6158 - val_accuracy: 0.1719\n",
            "Epoch 447/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.0198 - accuracy: 1.0000 - val_loss: 2.6173 - val_accuracy: 0.1719\n",
            "Epoch 448/500\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.0185 - accuracy: 1.0000 - val_loss: 2.6112 - val_accuracy: 0.1875\n",
            "Epoch 449/500\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.0187 - accuracy: 1.0000 - val_loss: 2.6319 - val_accuracy: 0.1719\n",
            "Epoch 450/500\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 0.0185 - accuracy: 1.0000 - val_loss: 2.6246 - val_accuracy: 0.1875\n",
            "Epoch 451/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.0180 - accuracy: 1.0000 - val_loss: 2.6327 - val_accuracy: 0.1875\n",
            "Epoch 452/500\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.0181 - accuracy: 1.0000 - val_loss: 2.6203 - val_accuracy: 0.2031\n",
            "Epoch 453/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.0189 - accuracy: 1.0000 - val_loss: 2.6111 - val_accuracy: 0.1719\n",
            "Epoch 454/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.0182 - accuracy: 1.0000 - val_loss: 2.6215 - val_accuracy: 0.2031\n",
            "Epoch 455/500\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.0187 - accuracy: 1.0000 - val_loss: 2.6086 - val_accuracy: 0.1875\n",
            "Epoch 456/500\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 0.0178 - accuracy: 1.0000 - val_loss: 2.6238 - val_accuracy: 0.2031\n",
            "Epoch 457/500\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 0.0179 - accuracy: 1.0000 - val_loss: 2.6203 - val_accuracy: 0.2031\n",
            "Epoch 458/500\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.0176 - accuracy: 1.0000 - val_loss: 2.6219 - val_accuracy: 0.2031\n",
            "Epoch 459/500\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 0.0179 - accuracy: 1.0000 - val_loss: 2.6213 - val_accuracy: 0.2188\n",
            "Epoch 460/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.0169 - accuracy: 1.0000 - val_loss: 2.6201 - val_accuracy: 0.1875\n",
            "Epoch 461/500\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.0175 - accuracy: 1.0000 - val_loss: 2.6447 - val_accuracy: 0.1719\n",
            "Epoch 462/500\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.0174 - accuracy: 1.0000 - val_loss: 2.6444 - val_accuracy: 0.2031\n",
            "Epoch 463/500\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 0.0174 - accuracy: 1.0000 - val_loss: 2.6459 - val_accuracy: 0.2031\n",
            "Epoch 464/500\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.0164 - accuracy: 1.0000 - val_loss: 2.6364 - val_accuracy: 0.1719\n",
            "Epoch 465/500\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 0.0175 - accuracy: 1.0000 - val_loss: 2.6291 - val_accuracy: 0.1875\n",
            "Epoch 466/500\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.0167 - accuracy: 1.0000 - val_loss: 2.6405 - val_accuracy: 0.2031\n",
            "Epoch 467/500\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.0168 - accuracy: 1.0000 - val_loss: 2.6329 - val_accuracy: 0.2031\n",
            "Epoch 468/500\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.0160 - accuracy: 1.0000 - val_loss: 2.6285 - val_accuracy: 0.1875\n",
            "Epoch 469/500\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 0.0173 - accuracy: 1.0000 - val_loss: 2.6541 - val_accuracy: 0.1875\n",
            "Epoch 470/500\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 0.0170 - accuracy: 1.0000 - val_loss: 2.6179 - val_accuracy: 0.1875\n",
            "Epoch 471/500\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.0178 - accuracy: 1.0000 - val_loss: 2.5951 - val_accuracy: 0.2031\n",
            "Epoch 472/500\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 0.0160 - accuracy: 1.0000 - val_loss: 2.6298 - val_accuracy: 0.2188\n",
            "Epoch 473/500\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 0.0163 - accuracy: 1.0000 - val_loss: 2.6251 - val_accuracy: 0.1875\n",
            "Epoch 474/500\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.0162 - accuracy: 1.0000 - val_loss: 2.6204 - val_accuracy: 0.1875\n",
            "Epoch 475/500\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 0.0165 - accuracy: 1.0000 - val_loss: 2.6210 - val_accuracy: 0.1719\n",
            "Epoch 476/500\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.0167 - accuracy: 1.0000 - val_loss: 2.6386 - val_accuracy: 0.2188\n",
            "Epoch 477/500\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.0159 - accuracy: 1.0000 - val_loss: 2.6461 - val_accuracy: 0.1719\n",
            "Epoch 478/500\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.0158 - accuracy: 1.0000 - val_loss: 2.6373 - val_accuracy: 0.1875\n",
            "Epoch 479/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.0162 - accuracy: 1.0000 - val_loss: 2.6314 - val_accuracy: 0.1875\n",
            "Epoch 480/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.0154 - accuracy: 1.0000 - val_loss: 2.6447 - val_accuracy: 0.1719\n",
            "Epoch 481/500\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 0.0152 - accuracy: 1.0000 - val_loss: 2.6402 - val_accuracy: 0.1875\n",
            "Epoch 482/500\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 0.0158 - accuracy: 1.0000 - val_loss: 2.6454 - val_accuracy: 0.1875\n",
            "Epoch 483/500\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.0160 - accuracy: 1.0000 - val_loss: 2.6307 - val_accuracy: 0.1875\n",
            "Epoch 484/500\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.0167 - accuracy: 1.0000 - val_loss: 2.6519 - val_accuracy: 0.2031\n",
            "Epoch 485/500\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 0.0147 - accuracy: 1.0000 - val_loss: 2.6359 - val_accuracy: 0.1875\n",
            "Epoch 486/500\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.0155 - accuracy: 1.0000 - val_loss: 2.6373 - val_accuracy: 0.1719\n",
            "Epoch 487/500\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.0154 - accuracy: 1.0000 - val_loss: 2.6317 - val_accuracy: 0.1875\n",
            "Epoch 488/500\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 0.0151 - accuracy: 1.0000 - val_loss: 2.6518 - val_accuracy: 0.2031\n",
            "Epoch 489/500\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.0149 - accuracy: 1.0000 - val_loss: 2.6356 - val_accuracy: 0.1719\n",
            "Epoch 490/500\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.0154 - accuracy: 1.0000 - val_loss: 2.6178 - val_accuracy: 0.1719\n",
            "Epoch 491/500\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.0147 - accuracy: 1.0000 - val_loss: 2.6323 - val_accuracy: 0.2031\n",
            "Epoch 492/500\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.0143 - accuracy: 1.0000 - val_loss: 2.6510 - val_accuracy: 0.1719\n",
            "Epoch 493/500\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 0.0145 - accuracy: 1.0000 - val_loss: 2.6414 - val_accuracy: 0.1719\n",
            "Epoch 494/500\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.0148 - accuracy: 1.0000 - val_loss: 2.6397 - val_accuracy: 0.1719\n",
            "Epoch 495/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.0146 - accuracy: 1.0000 - val_loss: 2.6585 - val_accuracy: 0.2031\n",
            "Epoch 496/500\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 0.0143 - accuracy: 1.0000 - val_loss: 2.6481 - val_accuracy: 0.1875\n",
            "Epoch 497/500\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.0149 - accuracy: 1.0000 - val_loss: 2.6596 - val_accuracy: 0.1875\n",
            "Epoch 498/500\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 0.0135 - accuracy: 1.0000 - val_loss: 2.6510 - val_accuracy: 0.1875\n",
            "Epoch 499/500\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 0.0137 - accuracy: 1.0000 - val_loss: 2.6511 - val_accuracy: 0.2031\n",
            "Epoch 500/500\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 0.0140 - accuracy: 1.0000 - val_loss: 2.6439 - val_accuracy: 0.1719\n"
          ]
        }
      ],
      "source": [
        "pruningcallback_1=PruningCallback(init_step=100, end_step=250,\n",
        "                                init_sparsity=0.4, end_sparsity=0.8,pruning_step=5)\n",
        "tf.random.set_seed(1234)\n",
        "hist_p_1=model_to_prune_1.fit(X_train_50.reshape(-1,dim_50[0],dim_50[0],3), y_train, \n",
        "                     batch_size=50, epochs=500,\n",
        "                     callbacks=[pruningcallback_1],\n",
        "                     validation_data=(X_test_50.reshape(-1,dim_50[0],dim_50[0],3),y_test),verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BV-Btru0000d",
        "outputId": "474a2878-2413-41c0-90c5-95f5201c6192",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n",
            "5/5 [==============================] - 1s 84ms/step - loss: 2.8260 - accuracy: 0.1018 - val_loss: 2.6390 - val_accuracy: 0.0781\n",
            "Epoch 2/500\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 2.0653 - accuracy: 0.3097 - val_loss: 2.6435 - val_accuracy: 0.0625\n",
            "Epoch 3/500\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 1.5417 - accuracy: 0.6195 - val_loss: 2.6434 - val_accuracy: 0.0625\n",
            "Epoch 4/500\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 1.2358 - accuracy: 0.7699 - val_loss: 2.6465 - val_accuracy: 0.0781\n",
            "Epoch 5/500\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 0.9626 - accuracy: 0.8805 - val_loss: 2.6514 - val_accuracy: 0.0938\n",
            "Epoch 6/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.7781 - accuracy: 0.9292 - val_loss: 2.6594 - val_accuracy: 0.1094\n",
            "Epoch 7/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.5934 - accuracy: 0.9735 - val_loss: 2.6664 - val_accuracy: 0.0938\n",
            "Epoch 8/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.4877 - accuracy: 0.9823 - val_loss: 2.6751 - val_accuracy: 0.0625\n",
            "Epoch 9/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.4052 - accuracy: 0.9956 - val_loss: 2.6829 - val_accuracy: 0.0781\n",
            "Epoch 10/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.3486 - accuracy: 0.9912 - val_loss: 2.6944 - val_accuracy: 0.0938\n",
            "Epoch 11/500\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.2859 - accuracy: 0.9956 - val_loss: 2.7043 - val_accuracy: 0.0938\n",
            "Epoch 12/500\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.2464 - accuracy: 1.0000 - val_loss: 2.7091 - val_accuracy: 0.1250\n",
            "Epoch 13/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.2084 - accuracy: 1.0000 - val_loss: 2.7222 - val_accuracy: 0.0781\n",
            "Epoch 14/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.1896 - accuracy: 1.0000 - val_loss: 2.7309 - val_accuracy: 0.0625\n",
            "Epoch 15/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.1672 - accuracy: 1.0000 - val_loss: 2.7450 - val_accuracy: 0.0469\n",
            "Epoch 16/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.1481 - accuracy: 1.0000 - val_loss: 2.7575 - val_accuracy: 0.1094\n",
            "Epoch 17/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.1382 - accuracy: 1.0000 - val_loss: 2.7702 - val_accuracy: 0.0781\n",
            "Epoch 18/500\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.1265 - accuracy: 1.0000 - val_loss: 2.7813 - val_accuracy: 0.0781\n",
            "Epoch 19/500\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.1191 - accuracy: 1.0000 - val_loss: 2.7893 - val_accuracy: 0.0781\n",
            "Epoch 20/500\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 0.1048 - accuracy: 1.0000 - val_loss: 2.8039 - val_accuracy: 0.0625\n",
            "Epoch 21/500\n",
            "5/5 [==============================] - 0s 32ms/step - loss: 0.0955 - accuracy: 1.0000 - val_loss: 2.8170 - val_accuracy: 0.0625\n",
            "Epoch 22/500\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.0924 - accuracy: 1.0000 - val_loss: 2.8334 - val_accuracy: 0.0469\n",
            "Epoch 23/500\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 0.0869 - accuracy: 1.0000 - val_loss: 2.8519 - val_accuracy: 0.0625\n",
            "Epoch 24/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.0840 - accuracy: 1.0000 - val_loss: 2.8668 - val_accuracy: 0.0625\n",
            "Epoch 25/500\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.0775 - accuracy: 1.0000 - val_loss: 2.8754 - val_accuracy: 0.0625\n",
            "Epoch 26/500\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.0700 - accuracy: 1.0000 - val_loss: 2.8917 - val_accuracy: 0.0625\n",
            "Epoch 27/500\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.0681 - accuracy: 1.0000 - val_loss: 2.9053 - val_accuracy: 0.0625\n",
            "Epoch 28/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.0641 - accuracy: 1.0000 - val_loss: 2.9187 - val_accuracy: 0.0938\n",
            "Epoch 29/500\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.0635 - accuracy: 1.0000 - val_loss: 2.9281 - val_accuracy: 0.0625\n",
            "Epoch 30/500\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 0.0596 - accuracy: 1.0000 - val_loss: 2.9457 - val_accuracy: 0.0625\n",
            "Epoch 31/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.0591 - accuracy: 1.0000 - val_loss: 2.9628 - val_accuracy: 0.0625\n",
            "Epoch 32/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.0577 - accuracy: 1.0000 - val_loss: 2.9712 - val_accuracy: 0.0625\n",
            "Epoch 33/500\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 0.0537 - accuracy: 1.0000 - val_loss: 2.9775 - val_accuracy: 0.0625\n",
            "Epoch 34/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.0530 - accuracy: 1.0000 - val_loss: 2.9932 - val_accuracy: 0.0625\n",
            "Epoch 35/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.0485 - accuracy: 1.0000 - val_loss: 3.0075 - val_accuracy: 0.0625\n",
            "Epoch 36/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.0469 - accuracy: 1.0000 - val_loss: 3.0206 - val_accuracy: 0.0781\n",
            "Epoch 37/500\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.0435 - accuracy: 1.0000 - val_loss: 3.0295 - val_accuracy: 0.0781\n",
            "Epoch 38/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.0444 - accuracy: 1.0000 - val_loss: 3.0356 - val_accuracy: 0.0938\n",
            "Epoch 39/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.0437 - accuracy: 1.0000 - val_loss: 3.0455 - val_accuracy: 0.0938\n",
            "Epoch 40/500\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.0414 - accuracy: 1.0000 - val_loss: 3.0609 - val_accuracy: 0.0781\n",
            "Epoch 41/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.0434 - accuracy: 1.0000 - val_loss: 3.0639 - val_accuracy: 0.0938\n",
            "Epoch 42/500\n",
            "5/5 [==============================] - 0s 32ms/step - loss: 0.0382 - accuracy: 1.0000 - val_loss: 3.0787 - val_accuracy: 0.0938\n",
            "Epoch 43/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.0369 - accuracy: 1.0000 - val_loss: 3.0863 - val_accuracy: 0.0938\n",
            "Epoch 44/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.0370 - accuracy: 1.0000 - val_loss: 3.0951 - val_accuracy: 0.0938\n",
            "Epoch 45/500\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.0358 - accuracy: 1.0000 - val_loss: 3.1091 - val_accuracy: 0.0938\n",
            "Epoch 46/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.0346 - accuracy: 1.0000 - val_loss: 3.1203 - val_accuracy: 0.0938\n",
            "Epoch 47/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.0342 - accuracy: 1.0000 - val_loss: 3.1235 - val_accuracy: 0.0938\n",
            "Epoch 48/500\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.0327 - accuracy: 1.0000 - val_loss: 3.1330 - val_accuracy: 0.0938\n",
            "Epoch 49/500\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.0324 - accuracy: 1.0000 - val_loss: 3.1405 - val_accuracy: 0.0781\n",
            "Epoch 50/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.0313 - accuracy: 1.0000 - val_loss: 3.1432 - val_accuracy: 0.0781\n",
            "Epoch 51/500\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.0310 - accuracy: 1.0000 - val_loss: 3.1569 - val_accuracy: 0.0781\n",
            "Epoch 52/500\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.0297 - accuracy: 1.0000 - val_loss: 3.1586 - val_accuracy: 0.0781\n",
            "Epoch 53/500\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.0286 - accuracy: 1.0000 - val_loss: 3.1694 - val_accuracy: 0.0781\n",
            "Epoch 54/500\n",
            "5/5 [==============================] - 0s 32ms/step - loss: 0.0289 - accuracy: 1.0000 - val_loss: 3.1686 - val_accuracy: 0.0781\n",
            "Epoch 55/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.0277 - accuracy: 1.0000 - val_loss: 3.1668 - val_accuracy: 0.0781\n",
            "Epoch 56/500\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.0268 - accuracy: 1.0000 - val_loss: 3.1690 - val_accuracy: 0.0781\n",
            "Epoch 57/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.0267 - accuracy: 1.0000 - val_loss: 3.1699 - val_accuracy: 0.0781\n",
            "Epoch 58/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.0260 - accuracy: 1.0000 - val_loss: 3.1725 - val_accuracy: 0.0781\n",
            "Epoch 59/500\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 0.0291 - accuracy: 1.0000 - val_loss: 3.1687 - val_accuracy: 0.0781\n",
            "Epoch 60/500\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.0250 - accuracy: 1.0000 - val_loss: 3.1680 - val_accuracy: 0.0781\n",
            "Epoch 61/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.0266 - accuracy: 1.0000 - val_loss: 3.1636 - val_accuracy: 0.0781\n",
            "Epoch 62/500\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.0253 - accuracy: 1.0000 - val_loss: 3.1572 - val_accuracy: 0.0781\n",
            "Epoch 63/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.0244 - accuracy: 1.0000 - val_loss: 3.1590 - val_accuracy: 0.0781\n",
            "Epoch 64/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.0249 - accuracy: 1.0000 - val_loss: 3.1612 - val_accuracy: 0.0781\n",
            "Epoch 65/500\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.0232 - accuracy: 1.0000 - val_loss: 3.1584 - val_accuracy: 0.0781\n",
            "Epoch 66/500\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.0225 - accuracy: 1.0000 - val_loss: 3.1557 - val_accuracy: 0.0781\n",
            "Epoch 67/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.0222 - accuracy: 1.0000 - val_loss: 3.1470 - val_accuracy: 0.0938\n",
            "Epoch 68/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.0223 - accuracy: 1.0000 - val_loss: 3.1381 - val_accuracy: 0.1094\n",
            "Epoch 69/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.0214 - accuracy: 1.0000 - val_loss: 3.1289 - val_accuracy: 0.1250\n",
            "Epoch 70/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.0228 - accuracy: 1.0000 - val_loss: 3.1155 - val_accuracy: 0.1250\n",
            "Epoch 71/500\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 0.0207 - accuracy: 1.0000 - val_loss: 3.1081 - val_accuracy: 0.1250\n",
            "Epoch 72/500\n",
            "5/5 [==============================] - 0s 32ms/step - loss: 0.0206 - accuracy: 1.0000 - val_loss: 3.0980 - val_accuracy: 0.1406\n",
            "Epoch 73/500\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 0.0196 - accuracy: 1.0000 - val_loss: 3.0958 - val_accuracy: 0.1406\n",
            "Epoch 74/500\n",
            "5/5 [==============================] - 0s 32ms/step - loss: 0.0196 - accuracy: 1.0000 - val_loss: 3.0857 - val_accuracy: 0.1406\n",
            "Epoch 75/500\n",
            "5/5 [==============================] - 0s 32ms/step - loss: 0.0189 - accuracy: 1.0000 - val_loss: 3.0704 - val_accuracy: 0.1406\n",
            "Epoch 76/500\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 0.0201 - accuracy: 1.0000 - val_loss: 3.0535 - val_accuracy: 0.1406\n",
            "Epoch 77/500\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.0189 - accuracy: 1.0000 - val_loss: 3.0403 - val_accuracy: 0.1406\n",
            "Epoch 78/500\n",
            "5/5 [==============================] - 0s 32ms/step - loss: 0.0190 - accuracy: 1.0000 - val_loss: 3.0328 - val_accuracy: 0.1719\n",
            "Epoch 79/500\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 0.0178 - accuracy: 1.0000 - val_loss: 3.0132 - val_accuracy: 0.1719\n",
            "Epoch 80/500\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 0.0173 - accuracy: 1.0000 - val_loss: 2.9987 - val_accuracy: 0.1875\n",
            "Epoch 81/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.0171 - accuracy: 1.0000 - val_loss: 2.9851 - val_accuracy: 0.1719\n",
            "Epoch 82/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.0168 - accuracy: 1.0000 - val_loss: 2.9711 - val_accuracy: 0.1719\n",
            "Epoch 83/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.0175 - accuracy: 1.0000 - val_loss: 2.9502 - val_accuracy: 0.1875\n",
            "Epoch 84/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.0168 - accuracy: 1.0000 - val_loss: 2.9357 - val_accuracy: 0.1719\n",
            "Epoch 85/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.0174 - accuracy: 1.0000 - val_loss: 2.9240 - val_accuracy: 0.1719\n",
            "Epoch 86/500\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.0162 - accuracy: 1.0000 - val_loss: 2.8996 - val_accuracy: 0.1875\n",
            "Epoch 87/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.0161 - accuracy: 1.0000 - val_loss: 2.8800 - val_accuracy: 0.1875\n",
            "Epoch 88/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.0164 - accuracy: 1.0000 - val_loss: 2.8624 - val_accuracy: 0.2031\n",
            "Epoch 89/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.0161 - accuracy: 1.0000 - val_loss: 2.8499 - val_accuracy: 0.2031\n",
            "Epoch 90/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.0154 - accuracy: 1.0000 - val_loss: 2.8276 - val_accuracy: 0.2031\n",
            "Epoch 91/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.0153 - accuracy: 1.0000 - val_loss: 2.8120 - val_accuracy: 0.2031\n",
            "Epoch 92/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.0157 - accuracy: 1.0000 - val_loss: 2.7750 - val_accuracy: 0.1875\n",
            "Epoch 93/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.0151 - accuracy: 1.0000 - val_loss: 2.7590 - val_accuracy: 0.1875\n",
            "Epoch 94/500\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.0148 - accuracy: 1.0000 - val_loss: 2.7405 - val_accuracy: 0.1875\n",
            "Epoch 95/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.0147 - accuracy: 1.0000 - val_loss: 2.7117 - val_accuracy: 0.2031\n",
            "Epoch 96/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.0144 - accuracy: 1.0000 - val_loss: 2.6937 - val_accuracy: 0.2188\n",
            "Epoch 97/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.0144 - accuracy: 1.0000 - val_loss: 2.6738 - val_accuracy: 0.2188\n",
            "Epoch 98/500\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.0143 - accuracy: 1.0000 - val_loss: 2.6498 - val_accuracy: 0.2188\n",
            "Epoch 99/500\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 0.0147 - accuracy: 1.0000 - val_loss: 2.6285 - val_accuracy: 0.2344\n",
            "Epoch 100/500\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 0.0141 - accuracy: 1.0000 - val_loss: 2.6155 - val_accuracy: 0.2188\n",
            "Epoch 101/500\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0140 - accuracy: 1.0000\n",
            " pruning [ = = = = ]\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.0140 - accuracy: 1.0000 - val_loss: 2.5886 - val_accuracy: 0.2656\n",
            "Epoch 102/500\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 2.2995 - accuracy: 0.2699 - val_loss: 2.7473 - val_accuracy: 0.1406\n",
            "Epoch 103/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 1.9299 - accuracy: 0.4690 - val_loss: 2.7354 - val_accuracy: 0.1250\n",
            "Epoch 104/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 1.6578 - accuracy: 0.6018 - val_loss: 2.7331 - val_accuracy: 0.1094\n",
            "Epoch 105/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 1.4635 - accuracy: 0.7124 - val_loss: 2.7006 - val_accuracy: 0.1094\n",
            "Epoch 106/500\n",
            "5/5 [==============================] - ETA: 0s - loss: 1.3078 - accuracy: 0.8319\n",
            " pruning [ = = = = ]\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 1.3078 - accuracy: 0.8319 - val_loss: 2.7463 - val_accuracy: 0.1250\n",
            "Epoch 107/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 1.4038 - accuracy: 0.7832 - val_loss: 2.6688 - val_accuracy: 0.1562\n",
            "Epoch 108/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 1.2026 - accuracy: 0.8938 - val_loss: 2.6551 - val_accuracy: 0.1250\n",
            "Epoch 109/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 1.1041 - accuracy: 0.9071 - val_loss: 2.6465 - val_accuracy: 0.1875\n",
            "Epoch 110/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.9950 - accuracy: 0.9248 - val_loss: 2.6514 - val_accuracy: 0.1406\n",
            "Epoch 111/500\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.8806 - accuracy: 0.9646\n",
            " pruning [ = = = = ]\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.8806 - accuracy: 0.9646 - val_loss: 2.6627 - val_accuracy: 0.1562\n",
            "Epoch 112/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 1.0667 - accuracy: 0.9204 - val_loss: 2.6505 - val_accuracy: 0.1094\n",
            "Epoch 113/500\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.9198 - accuracy: 0.9469 - val_loss: 2.6781 - val_accuracy: 0.1250\n",
            "Epoch 114/500\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 0.8326 - accuracy: 0.9690 - val_loss: 2.6441 - val_accuracy: 0.1719\n",
            "Epoch 115/500\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.7230 - accuracy: 0.9823 - val_loss: 2.6286 - val_accuracy: 0.1250\n",
            "Epoch 116/500\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.6834 - accuracy: 0.9779\n",
            " pruning [ = = = = ]\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.6834 - accuracy: 0.9779 - val_loss: 2.6582 - val_accuracy: 0.1094\n",
            "Epoch 117/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.8826 - accuracy: 0.9469 - val_loss: 2.6271 - val_accuracy: 0.1562\n",
            "Epoch 118/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.8021 - accuracy: 0.9602 - val_loss: 2.5866 - val_accuracy: 0.2031\n",
            "Epoch 119/500\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.6577 - accuracy: 0.9867 - val_loss: 2.5736 - val_accuracy: 0.2031\n",
            "Epoch 120/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.6083 - accuracy: 0.9867 - val_loss: 2.6651 - val_accuracy: 0.1562\n",
            "Epoch 121/500\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.5513 - accuracy: 0.9867\n",
            " pruning [ = = = = ]\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.5513 - accuracy: 0.9867 - val_loss: 2.6070 - val_accuracy: 0.1719\n",
            "Epoch 122/500\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 0.6947 - accuracy: 0.9867 - val_loss: 2.5836 - val_accuracy: 0.1719\n",
            "Epoch 123/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.6037 - accuracy: 0.9867 - val_loss: 2.5749 - val_accuracy: 0.2188\n",
            "Epoch 124/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.5463 - accuracy: 0.9912 - val_loss: 2.5702 - val_accuracy: 0.1250\n",
            "Epoch 125/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.4956 - accuracy: 1.0000 - val_loss: 2.5310 - val_accuracy: 0.1406\n",
            "Epoch 126/500\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.4278 - accuracy: 1.0000\n",
            " pruning [ = = = = ]\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.4278 - accuracy: 1.0000 - val_loss: 2.5301 - val_accuracy: 0.1562\n",
            "Epoch 127/500\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.7007 - accuracy: 0.9823 - val_loss: 2.5628 - val_accuracy: 0.1562\n",
            "Epoch 128/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.5810 - accuracy: 0.9867 - val_loss: 2.5727 - val_accuracy: 0.1719\n",
            "Epoch 129/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.5312 - accuracy: 0.9867 - val_loss: 2.4993 - val_accuracy: 0.2188\n",
            "Epoch 130/500\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.4679 - accuracy: 0.9956 - val_loss: 2.5159 - val_accuracy: 0.1250\n",
            "Epoch 131/500\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.4229 - accuracy: 0.9956\n",
            " pruning [ = = = = ]\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.4229 - accuracy: 0.9956 - val_loss: 2.5187 - val_accuracy: 0.2031\n",
            "Epoch 132/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.6639 - accuracy: 0.9823 - val_loss: 2.5184 - val_accuracy: 0.1250\n",
            "Epoch 133/500\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.5688 - accuracy: 0.9912 - val_loss: 2.4860 - val_accuracy: 0.2500\n",
            "Epoch 134/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.5216 - accuracy: 0.9912 - val_loss: 2.4659 - val_accuracy: 0.1562\n",
            "Epoch 135/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.4493 - accuracy: 0.9956 - val_loss: 2.5269 - val_accuracy: 0.2656\n",
            "Epoch 136/500\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.4095 - accuracy: 0.9956\n",
            " pruning [ = = = = ]\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.4095 - accuracy: 0.9956 - val_loss: 2.5122 - val_accuracy: 0.2500\n",
            "Epoch 137/500\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 0.6317 - accuracy: 0.9912 - val_loss: 2.4938 - val_accuracy: 0.2188\n",
            "Epoch 138/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.5454 - accuracy: 0.9912 - val_loss: 2.4734 - val_accuracy: 0.1875\n",
            "Epoch 139/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.4908 - accuracy: 0.9956 - val_loss: 2.4857 - val_accuracy: 0.2031\n",
            "Epoch 140/500\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.4402 - accuracy: 1.0000 - val_loss: 2.4295 - val_accuracy: 0.2344\n",
            "Epoch 141/500\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.4097 - accuracy: 0.9956\n",
            " pruning [ = = = = ]\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.4097 - accuracy: 0.9956 - val_loss: 2.3828 - val_accuracy: 0.2188\n",
            "Epoch 142/500\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 0.6574 - accuracy: 0.9912 - val_loss: 2.4070 - val_accuracy: 0.1719\n",
            "Epoch 143/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.5302 - accuracy: 0.9956 - val_loss: 2.4640 - val_accuracy: 0.1875\n",
            "Epoch 144/500\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.4639 - accuracy: 0.9956 - val_loss: 2.4279 - val_accuracy: 0.2344\n",
            "Epoch 145/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.4097 - accuracy: 1.0000 - val_loss: 2.4192 - val_accuracy: 0.2188\n",
            "Epoch 146/500\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.3741 - accuracy: 1.0000\n",
            " pruning [ = = = = ]\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 0.3741 - accuracy: 1.0000 - val_loss: 2.4263 - val_accuracy: 0.1875\n",
            "Epoch 147/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.6108 - accuracy: 0.9956 - val_loss: 2.4639 - val_accuracy: 0.2188\n",
            "Epoch 148/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.4937 - accuracy: 0.9956 - val_loss: 2.4092 - val_accuracy: 0.2500\n",
            "Epoch 149/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.4422 - accuracy: 1.0000 - val_loss: 2.3874 - val_accuracy: 0.2500\n",
            "Epoch 150/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.3892 - accuracy: 1.0000 - val_loss: 2.3861 - val_accuracy: 0.2344\n",
            "Epoch 151/500\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.3473 - accuracy: 1.0000\n",
            " pruning [ = = = = ]\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.3473 - accuracy: 1.0000 - val_loss: 2.3734 - val_accuracy: 0.2031\n",
            "Epoch 152/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.6315 - accuracy: 1.0000 - val_loss: 2.4090 - val_accuracy: 0.2812\n",
            "Epoch 153/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.5383 - accuracy: 0.9956 - val_loss: 2.3376 - val_accuracy: 0.2656\n",
            "Epoch 154/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.4528 - accuracy: 1.0000 - val_loss: 2.2872 - val_accuracy: 0.2344\n",
            "Epoch 155/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.4447 - accuracy: 1.0000 - val_loss: 2.4074 - val_accuracy: 0.2812\n",
            "Epoch 156/500\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.4269 - accuracy: 0.9956\n",
            " pruning [ = = = = ]\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.4269 - accuracy: 0.9956 - val_loss: 2.3245 - val_accuracy: 0.2656\n",
            "Epoch 157/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.5066 - accuracy: 0.9956 - val_loss: 2.2198 - val_accuracy: 0.2656\n",
            "Epoch 158/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.4688 - accuracy: 1.0000 - val_loss: 2.2128 - val_accuracy: 0.2031\n",
            "Epoch 159/500\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.4119 - accuracy: 1.0000 - val_loss: 2.2808 - val_accuracy: 0.2812\n",
            "Epoch 160/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.3570 - accuracy: 1.0000 - val_loss: 2.2031 - val_accuracy: 0.3281\n",
            "Epoch 161/500\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.3377 - accuracy: 1.0000\n",
            " pruning [ = = = = ]\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 0.3377 - accuracy: 1.0000 - val_loss: 2.3112 - val_accuracy: 0.2344\n",
            "Epoch 162/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.6563 - accuracy: 0.9823 - val_loss: 2.3326 - val_accuracy: 0.2656\n",
            "Epoch 163/500\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.4866 - accuracy: 1.0000 - val_loss: 2.3049 - val_accuracy: 0.2344\n",
            "Epoch 164/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.4288 - accuracy: 1.0000 - val_loss: 2.2632 - val_accuracy: 0.2344\n",
            "Epoch 165/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.4146 - accuracy: 0.9956 - val_loss: 2.3148 - val_accuracy: 0.2031\n",
            "Epoch 166/500\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.3419 - accuracy: 1.0000\n",
            " pruning [ = = = = ]\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 0.3419 - accuracy: 1.0000 - val_loss: 2.2529 - val_accuracy: 0.2812\n",
            "Epoch 167/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.6837 - accuracy: 0.9956 - val_loss: 2.3878 - val_accuracy: 0.2969\n",
            "Epoch 168/500\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.5484 - accuracy: 0.9912 - val_loss: 2.2982 - val_accuracy: 0.3125\n",
            "Epoch 169/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.4918 - accuracy: 0.9956 - val_loss: 2.2471 - val_accuracy: 0.2656\n",
            "Epoch 170/500\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.4310 - accuracy: 1.0000 - val_loss: 2.3791 - val_accuracy: 0.3438\n",
            "Epoch 171/500\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.3899 - accuracy: 0.9956\n",
            " pruning [ = = = = ]\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.3899 - accuracy: 0.9956 - val_loss: 2.3200 - val_accuracy: 0.3125\n",
            "Epoch 172/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.6761 - accuracy: 0.9735 - val_loss: 2.3287 - val_accuracy: 0.2969\n",
            "Epoch 173/500\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.5548 - accuracy: 0.9867 - val_loss: 2.4357 - val_accuracy: 0.2188\n",
            "Epoch 174/500\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 0.5337 - accuracy: 0.9956 - val_loss: 2.2826 - val_accuracy: 0.2656\n",
            "Epoch 175/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.4439 - accuracy: 1.0000 - val_loss: 2.2810 - val_accuracy: 0.3281\n",
            "Epoch 176/500\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.3828 - accuracy: 1.0000\n",
            " pruning [ = = = = ]\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.3828 - accuracy: 1.0000 - val_loss: 2.2772 - val_accuracy: 0.2969\n",
            "Epoch 177/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.7407 - accuracy: 0.9690 - val_loss: 2.7223 - val_accuracy: 0.1406\n",
            "Epoch 178/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.6145 - accuracy: 0.9867 - val_loss: 2.3248 - val_accuracy: 0.2500\n",
            "Epoch 179/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.5103 - accuracy: 1.0000 - val_loss: 2.3148 - val_accuracy: 0.2344\n",
            "Epoch 180/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.5088 - accuracy: 0.9956 - val_loss: 2.3230 - val_accuracy: 0.2656\n",
            "Epoch 181/500\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.4013 - accuracy: 1.0000\n",
            " pruning [ = = = = ]\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.4013 - accuracy: 1.0000 - val_loss: 2.2518 - val_accuracy: 0.2344\n",
            "Epoch 182/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.5061 - accuracy: 0.9956 - val_loss: 2.4203 - val_accuracy: 0.2344\n",
            "Epoch 183/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.4541 - accuracy: 1.0000 - val_loss: 2.4044 - val_accuracy: 0.2344\n",
            "Epoch 184/500\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.4109 - accuracy: 1.0000 - val_loss: 2.3134 - val_accuracy: 0.2812\n",
            "Epoch 185/500\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.3548 - accuracy: 1.0000 - val_loss: 2.3937 - val_accuracy: 0.2031\n",
            "Epoch 186/500\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.3421 - accuracy: 1.0000\n",
            " pruning [ = = = = ]\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.3421 - accuracy: 1.0000 - val_loss: 2.3239 - val_accuracy: 0.2656\n",
            "Epoch 187/500\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 0.8490 - accuracy: 0.9735 - val_loss: 2.4343 - val_accuracy: 0.2656\n",
            "Epoch 188/500\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 0.6578 - accuracy: 1.0000 - val_loss: 2.5447 - val_accuracy: 0.2031\n",
            "Epoch 189/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.6089 - accuracy: 0.9912 - val_loss: 2.2945 - val_accuracy: 0.2500\n",
            "Epoch 190/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.5241 - accuracy: 1.0000 - val_loss: 2.3371 - val_accuracy: 0.2344\n",
            "Epoch 191/500\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.4800 - accuracy: 1.0000\n",
            " pruning [ = = = = ]\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.4800 - accuracy: 1.0000 - val_loss: 2.3080 - val_accuracy: 0.2656\n",
            "Epoch 192/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.9470 - accuracy: 0.9513 - val_loss: 2.3183 - val_accuracy: 0.2656\n",
            "Epoch 193/500\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.7462 - accuracy: 0.9867 - val_loss: 2.4368 - val_accuracy: 0.2031\n",
            "Epoch 194/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.6447 - accuracy: 1.0000 - val_loss: 2.3688 - val_accuracy: 0.2656\n",
            "Epoch 195/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.5852 - accuracy: 1.0000 - val_loss: 2.4298 - val_accuracy: 0.2344\n",
            "Epoch 196/500\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.5357 - accuracy: 1.0000\n",
            " pruning [ = = = = ]\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.5357 - accuracy: 1.0000 - val_loss: 2.3570 - val_accuracy: 0.2344\n",
            "Epoch 197/500\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 1.0792 - accuracy: 0.9425 - val_loss: 2.3340 - val_accuracy: 0.2344\n",
            "Epoch 198/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.8579 - accuracy: 0.9823 - val_loss: 2.4141 - val_accuracy: 0.1406\n",
            "Epoch 199/500\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 0.7266 - accuracy: 0.9956 - val_loss: 2.4105 - val_accuracy: 0.1562\n",
            "Epoch 200/500\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.7016 - accuracy: 0.9867 - val_loss: 2.3418 - val_accuracy: 0.2031\n",
            "Epoch 201/500\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 0.6331 - accuracy: 1.0000\n",
            " pruning [ = = = = ]\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 0.6230 - accuracy: 1.0000 - val_loss: 2.4297 - val_accuracy: 0.2344\n",
            "Epoch 202/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 1.1055 - accuracy: 0.9115 - val_loss: 2.5088 - val_accuracy: 0.2344\n",
            "Epoch 203/500\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.9261 - accuracy: 0.9469 - val_loss: 2.3030 - val_accuracy: 0.2656\n",
            "Epoch 204/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.7868 - accuracy: 0.9779 - val_loss: 2.2818 - val_accuracy: 0.2969\n",
            "Epoch 205/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.7930 - accuracy: 0.9867 - val_loss: 2.3653 - val_accuracy: 0.2188\n",
            "Epoch 206/500\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 0.7305 - accuracy: 0.9800\n",
            " pruning [ = = = = ]\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.7246 - accuracy: 0.9823 - val_loss: 2.4041 - val_accuracy: 0.2344\n",
            "Epoch 207/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 1.0998 - accuracy: 0.8938 - val_loss: 2.4180 - val_accuracy: 0.2656\n",
            "Epoch 208/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.8866 - accuracy: 0.9735 - val_loss: 2.3894 - val_accuracy: 0.2188\n",
            "Epoch 209/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.8277 - accuracy: 0.9558 - val_loss: 2.3240 - val_accuracy: 0.2344\n",
            "Epoch 210/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.7683 - accuracy: 0.9823 - val_loss: 2.2995 - val_accuracy: 0.2500\n",
            "Epoch 211/500\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.7265 - accuracy: 0.9735\n",
            " pruning [ = = = = ]\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.7265 - accuracy: 0.9735 - val_loss: 2.3027 - val_accuracy: 0.2188\n",
            "Epoch 212/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.8559 - accuracy: 0.9690 - val_loss: 2.3357 - val_accuracy: 0.2500\n",
            "Epoch 213/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.7528 - accuracy: 0.9912 - val_loss: 2.3778 - val_accuracy: 0.2500\n",
            "Epoch 214/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.7084 - accuracy: 0.9867 - val_loss: 2.3536 - val_accuracy: 0.2188\n",
            "Epoch 215/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.6335 - accuracy: 0.9912 - val_loss: 2.3770 - val_accuracy: 0.2812\n",
            "Epoch 216/500\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.5859 - accuracy: 1.0000\n",
            " pruning [ = = = = ]\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.5859 - accuracy: 1.0000 - val_loss: 2.3329 - val_accuracy: 0.2812\n",
            "Epoch 217/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 1.1050 - accuracy: 0.9027 - val_loss: 2.4744 - val_accuracy: 0.2656\n",
            "Epoch 218/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.9246 - accuracy: 0.9336 - val_loss: 2.4595 - val_accuracy: 0.1875\n",
            "Epoch 219/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.8967 - accuracy: 0.9513 - val_loss: 2.5200 - val_accuracy: 0.2188\n",
            "Epoch 220/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.7544 - accuracy: 0.9912 - val_loss: 2.3421 - val_accuracy: 0.3125\n",
            "Epoch 221/500\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.6772 - accuracy: 0.9823\n",
            " pruning [ = = = = ]\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.6772 - accuracy: 0.9823 - val_loss: 2.2374 - val_accuracy: 0.2812\n",
            "Epoch 222/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 1.0649 - accuracy: 0.9248 - val_loss: 2.4381 - val_accuracy: 0.2344\n",
            "Epoch 223/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.9278 - accuracy: 0.9735 - val_loss: 2.3757 - val_accuracy: 0.2500\n",
            "Epoch 224/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.8043 - accuracy: 0.9735 - val_loss: 2.3418 - val_accuracy: 0.2812\n",
            "Epoch 225/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.7617 - accuracy: 0.9912 - val_loss: 2.2814 - val_accuracy: 0.2969\n",
            "Epoch 226/500\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.6801 - accuracy: 0.9867\n",
            " pruning [ = = = = ]\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.6801 - accuracy: 0.9867 - val_loss: 2.3157 - val_accuracy: 0.2344\n",
            "Epoch 227/500\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 1.2054 - accuracy: 0.8894 - val_loss: 2.5083 - val_accuracy: 0.2031\n",
            "Epoch 228/500\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 1.1261 - accuracy: 0.9204 - val_loss: 2.4389 - val_accuracy: 0.1562\n",
            "Epoch 229/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 1.0156 - accuracy: 0.9248 - val_loss: 2.3440 - val_accuracy: 0.2500\n",
            "Epoch 230/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.9551 - accuracy: 0.9602 - val_loss: 2.4027 - val_accuracy: 0.1719\n",
            "Epoch 231/500\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.8531 - accuracy: 0.9867\n",
            " pruning [ = = = = ]\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 0.8531 - accuracy: 0.9867 - val_loss: 2.4070 - val_accuracy: 0.2031\n",
            "Epoch 232/500\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 1.3517 - accuracy: 0.8230 - val_loss: 2.6883 - val_accuracy: 0.1562\n",
            "Epoch 233/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 1.2927 - accuracy: 0.8407 - val_loss: 2.6757 - val_accuracy: 0.1562\n",
            "Epoch 234/500\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 1.0869 - accuracy: 0.9336 - val_loss: 2.4803 - val_accuracy: 0.2031\n",
            "Epoch 235/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 1.0248 - accuracy: 0.9513 - val_loss: 2.4181 - val_accuracy: 0.2344\n",
            "Epoch 236/500\n",
            "5/5 [==============================] - ETA: 0s - loss: 1.0502 - accuracy: 0.9248\n",
            " pruning [ = = = = ]\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 1.0502 - accuracy: 0.9248 - val_loss: 2.5175 - val_accuracy: 0.2500\n",
            "Epoch 237/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 1.3746 - accuracy: 0.8363 - val_loss: 2.5865 - val_accuracy: 0.2031\n",
            "Epoch 238/500\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 1.2756 - accuracy: 0.8850 - val_loss: 2.6566 - val_accuracy: 0.1875\n",
            "Epoch 239/500\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 1.2641 - accuracy: 0.8673 - val_loss: 2.6470 - val_accuracy: 0.1406\n",
            "Epoch 240/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 1.1828 - accuracy: 0.8938 - val_loss: 2.3909 - val_accuracy: 0.2500\n",
            "Epoch 241/500\n",
            "5/5 [==============================] - ETA: 0s - loss: 1.1525 - accuracy: 0.9204\n",
            " pruning [ = = = = ]\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 1.1525 - accuracy: 0.9204 - val_loss: 2.5986 - val_accuracy: 0.1562\n",
            "Epoch 242/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 1.4620 - accuracy: 0.7876 - val_loss: 2.4313 - val_accuracy: 0.2344\n",
            "Epoch 243/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 1.3306 - accuracy: 0.8717 - val_loss: 2.6610 - val_accuracy: 0.1719\n",
            "Epoch 244/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 1.2940 - accuracy: 0.8451 - val_loss: 2.4557 - val_accuracy: 0.2656\n",
            "Epoch 245/500\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 1.1735 - accuracy: 0.9027 - val_loss: 2.4703 - val_accuracy: 0.2344\n",
            "Epoch 246/500\n",
            "5/5 [==============================] - ETA: 0s - loss: 1.1893 - accuracy: 0.9071\n",
            " pruning [ = = = = ]\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 1.1893 - accuracy: 0.9071 - val_loss: 2.4823 - val_accuracy: 0.2344\n",
            "Epoch 247/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 1.7320 - accuracy: 0.6283 - val_loss: 2.4280 - val_accuracy: 0.1562\n",
            "Epoch 248/500\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 1.5807 - accuracy: 0.6991 - val_loss: 2.5458 - val_accuracy: 0.2031\n",
            "Epoch 249/500\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 1.5173 - accuracy: 0.6770 - val_loss: 2.6668 - val_accuracy: 0.1406\n",
            "Epoch 250/500\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 1.4028 - accuracy: 0.8097 - val_loss: 2.4443 - val_accuracy: 0.1719\n",
            "Epoch 251/500\n",
            "5/5 [==============================] - ETA: 0s - loss: 1.3706 - accuracy: 0.8009\n",
            " pruning [ = = = = ]\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 1.3706 - accuracy: 0.8009 - val_loss: 2.4943 - val_accuracy: 0.2188\n",
            "Epoch 252/500\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 1.8480 - accuracy: 0.5088 - val_loss: 2.7229 - val_accuracy: 0.1562\n",
            "Epoch 253/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 1.7095 - accuracy: 0.5575 - val_loss: 2.4962 - val_accuracy: 0.1562\n",
            "Epoch 254/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 1.5235 - accuracy: 0.7080 - val_loss: 2.5818 - val_accuracy: 0.1875\n",
            "Epoch 255/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 1.4658 - accuracy: 0.7389 - val_loss: 2.6491 - val_accuracy: 0.1719\n",
            "Epoch 256/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 1.4414 - accuracy: 0.7876 - val_loss: 2.5577 - val_accuracy: 0.2188\n",
            "Epoch 257/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 1.3437 - accuracy: 0.8097 - val_loss: 2.6007 - val_accuracy: 0.2031\n",
            "Epoch 258/500\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 1.2982 - accuracy: 0.8230 - val_loss: 2.4762 - val_accuracy: 0.2188\n",
            "Epoch 259/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 1.2353 - accuracy: 0.8805 - val_loss: 2.5246 - val_accuracy: 0.1875\n",
            "Epoch 260/500\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 1.2276 - accuracy: 0.8540 - val_loss: 2.4542 - val_accuracy: 0.2188\n",
            "Epoch 261/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 1.1242 - accuracy: 0.9159 - val_loss: 2.6288 - val_accuracy: 0.1406\n",
            "Epoch 262/500\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 1.1213 - accuracy: 0.8982 - val_loss: 2.4178 - val_accuracy: 0.2500\n",
            "Epoch 263/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 1.0397 - accuracy: 0.9248 - val_loss: 2.4351 - val_accuracy: 0.2344\n",
            "Epoch 264/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 1.0570 - accuracy: 0.9159 - val_loss: 2.6121 - val_accuracy: 0.0938\n",
            "Epoch 265/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 1.0107 - accuracy: 0.9204 - val_loss: 2.5376 - val_accuracy: 0.1875\n",
            "Epoch 266/500\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.9869 - accuracy: 0.9204 - val_loss: 2.5065 - val_accuracy: 0.1875\n",
            "Epoch 267/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.9782 - accuracy: 0.9248 - val_loss: 2.5200 - val_accuracy: 0.2344\n",
            "Epoch 268/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.9506 - accuracy: 0.9513 - val_loss: 2.4423 - val_accuracy: 0.2500\n",
            "Epoch 269/500\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.9119 - accuracy: 0.9336 - val_loss: 2.4221 - val_accuracy: 0.1562\n",
            "Epoch 270/500\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.9146 - accuracy: 0.9602 - val_loss: 2.3872 - val_accuracy: 0.2656\n",
            "Epoch 271/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.8171 - accuracy: 0.9690 - val_loss: 2.5069 - val_accuracy: 0.2031\n",
            "Epoch 272/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.7755 - accuracy: 0.9690 - val_loss: 2.4395 - val_accuracy: 0.2188\n",
            "Epoch 273/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.7602 - accuracy: 0.9779 - val_loss: 2.6154 - val_accuracy: 0.2031\n",
            "Epoch 274/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.8706 - accuracy: 0.9336 - val_loss: 2.5377 - val_accuracy: 0.2500\n",
            "Epoch 275/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.8007 - accuracy: 0.9646 - val_loss: 2.3599 - val_accuracy: 0.2656\n",
            "Epoch 276/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.7497 - accuracy: 0.9602 - val_loss: 2.4124 - val_accuracy: 0.2344\n",
            "Epoch 277/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.6585 - accuracy: 0.9690 - val_loss: 2.3477 - val_accuracy: 0.2500\n",
            "Epoch 278/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.7080 - accuracy: 0.9735 - val_loss: 2.5954 - val_accuracy: 0.2344\n",
            "Epoch 279/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.6339 - accuracy: 0.9735 - val_loss: 2.6809 - val_accuracy: 0.1562\n",
            "Epoch 280/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.6200 - accuracy: 0.9912 - val_loss: 2.2723 - val_accuracy: 0.3125\n",
            "Epoch 281/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.6773 - accuracy: 0.9690 - val_loss: 2.3798 - val_accuracy: 0.2969\n",
            "Epoch 282/500\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.5882 - accuracy: 0.9779 - val_loss: 2.4341 - val_accuracy: 0.2656\n",
            "Epoch 283/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.6361 - accuracy: 0.9735 - val_loss: 2.6263 - val_accuracy: 0.1562\n",
            "Epoch 284/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.5163 - accuracy: 0.9912 - val_loss: 2.5608 - val_accuracy: 0.2500\n",
            "Epoch 285/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.5116 - accuracy: 0.9912 - val_loss: 2.4000 - val_accuracy: 0.2344\n",
            "Epoch 286/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.4876 - accuracy: 1.0000 - val_loss: 2.4968 - val_accuracy: 0.1875\n",
            "Epoch 287/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.4944 - accuracy: 0.9867 - val_loss: 2.3722 - val_accuracy: 0.2344\n",
            "Epoch 288/500\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.4554 - accuracy: 0.9823 - val_loss: 2.8260 - val_accuracy: 0.1562\n",
            "Epoch 289/500\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 0.4948 - accuracy: 0.9912 - val_loss: 2.4348 - val_accuracy: 0.2969\n",
            "Epoch 290/500\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.3971 - accuracy: 1.0000 - val_loss: 2.3489 - val_accuracy: 0.2500\n",
            "Epoch 291/500\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.4152 - accuracy: 0.9956 - val_loss: 2.3600 - val_accuracy: 0.2188\n",
            "Epoch 292/500\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.3671 - accuracy: 1.0000 - val_loss: 2.3867 - val_accuracy: 0.2812\n",
            "Epoch 293/500\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.3460 - accuracy: 1.0000 - val_loss: 2.3455 - val_accuracy: 0.2969\n",
            "Epoch 294/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.3330 - accuracy: 1.0000 - val_loss: 2.3927 - val_accuracy: 0.2344\n",
            "Epoch 295/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.3071 - accuracy: 1.0000 - val_loss: 2.4350 - val_accuracy: 0.2188\n",
            "Epoch 296/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.3411 - accuracy: 1.0000 - val_loss: 2.5035 - val_accuracy: 0.2031\n",
            "Epoch 297/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.3286 - accuracy: 1.0000 - val_loss: 2.3546 - val_accuracy: 0.2344\n",
            "Epoch 298/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.2890 - accuracy: 1.0000 - val_loss: 2.3989 - val_accuracy: 0.2500\n",
            "Epoch 299/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.2812 - accuracy: 1.0000 - val_loss: 2.3782 - val_accuracy: 0.2188\n",
            "Epoch 300/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.2693 - accuracy: 1.0000 - val_loss: 2.4118 - val_accuracy: 0.2188\n",
            "Epoch 301/500\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.2658 - accuracy: 1.0000 - val_loss: 2.3946 - val_accuracy: 0.2656\n",
            "Epoch 302/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.2581 - accuracy: 1.0000 - val_loss: 2.4084 - val_accuracy: 0.2188\n",
            "Epoch 303/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.2500 - accuracy: 1.0000 - val_loss: 2.4340 - val_accuracy: 0.2188\n",
            "Epoch 304/500\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.2333 - accuracy: 1.0000 - val_loss: 2.3844 - val_accuracy: 0.2344\n",
            "Epoch 305/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.2310 - accuracy: 1.0000 - val_loss: 2.6028 - val_accuracy: 0.2188\n",
            "Epoch 306/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.2408 - accuracy: 1.0000 - val_loss: 2.3972 - val_accuracy: 0.2188\n",
            "Epoch 307/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.2261 - accuracy: 1.0000 - val_loss: 2.4957 - val_accuracy: 0.2656\n",
            "Epoch 308/500\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.2641 - accuracy: 1.0000 - val_loss: 2.3479 - val_accuracy: 0.2500\n",
            "Epoch 309/500\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.2083 - accuracy: 1.0000 - val_loss: 2.3674 - val_accuracy: 0.2656\n",
            "Epoch 310/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.1867 - accuracy: 1.0000 - val_loss: 2.3372 - val_accuracy: 0.2344\n",
            "Epoch 311/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.1968 - accuracy: 0.9956 - val_loss: 2.3794 - val_accuracy: 0.2188\n",
            "Epoch 312/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.1812 - accuracy: 1.0000 - val_loss: 2.3381 - val_accuracy: 0.3281\n",
            "Epoch 313/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.1828 - accuracy: 1.0000 - val_loss: 2.3799 - val_accuracy: 0.2500\n",
            "Epoch 314/500\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.1700 - accuracy: 1.0000 - val_loss: 2.3805 - val_accuracy: 0.2500\n",
            "Epoch 315/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.1654 - accuracy: 1.0000 - val_loss: 2.4957 - val_accuracy: 0.2188\n",
            "Epoch 316/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.1605 - accuracy: 1.0000 - val_loss: 2.4259 - val_accuracy: 0.2031\n",
            "Epoch 317/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.1616 - accuracy: 1.0000 - val_loss: 2.4800 - val_accuracy: 0.2031\n",
            "Epoch 318/500\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.1544 - accuracy: 1.0000 - val_loss: 2.4114 - val_accuracy: 0.2188\n",
            "Epoch 319/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.1462 - accuracy: 1.0000 - val_loss: 2.4004 - val_accuracy: 0.2031\n",
            "Epoch 320/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.1532 - accuracy: 1.0000 - val_loss: 2.3740 - val_accuracy: 0.2500\n",
            "Epoch 321/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.1461 - accuracy: 1.0000 - val_loss: 2.4272 - val_accuracy: 0.2031\n",
            "Epoch 322/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.1341 - accuracy: 1.0000 - val_loss: 2.4034 - val_accuracy: 0.2812\n",
            "Epoch 323/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.1338 - accuracy: 1.0000 - val_loss: 2.4455 - val_accuracy: 0.2188\n",
            "Epoch 324/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.1315 - accuracy: 1.0000 - val_loss: 2.5261 - val_accuracy: 0.2031\n",
            "Epoch 325/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.1343 - accuracy: 1.0000 - val_loss: 2.3710 - val_accuracy: 0.2656\n",
            "Epoch 326/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.1242 - accuracy: 1.0000 - val_loss: 2.5373 - val_accuracy: 0.2031\n",
            "Epoch 327/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.1295 - accuracy: 1.0000 - val_loss: 2.4815 - val_accuracy: 0.2031\n",
            "Epoch 328/500\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 0.1215 - accuracy: 1.0000 - val_loss: 2.4410 - val_accuracy: 0.2031\n",
            "Epoch 329/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.1214 - accuracy: 1.0000 - val_loss: 2.4341 - val_accuracy: 0.2188\n",
            "Epoch 330/500\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.1162 - accuracy: 1.0000 - val_loss: 2.4075 - val_accuracy: 0.1875\n",
            "Epoch 331/500\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.1110 - accuracy: 1.0000 - val_loss: 2.4456 - val_accuracy: 0.2344\n",
            "Epoch 332/500\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.1082 - accuracy: 1.0000 - val_loss: 2.4177 - val_accuracy: 0.2500\n",
            "Epoch 333/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.1065 - accuracy: 1.0000 - val_loss: 2.4505 - val_accuracy: 0.2656\n",
            "Epoch 334/500\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 0.1030 - accuracy: 1.0000 - val_loss: 2.4452 - val_accuracy: 0.2500\n",
            "Epoch 335/500\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.1008 - accuracy: 1.0000 - val_loss: 2.4583 - val_accuracy: 0.2188\n",
            "Epoch 336/500\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 0.1010 - accuracy: 1.0000 - val_loss: 2.4245 - val_accuracy: 0.2969\n",
            "Epoch 337/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.0943 - accuracy: 1.0000 - val_loss: 2.4873 - val_accuracy: 0.2500\n",
            "Epoch 338/500\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.0928 - accuracy: 1.0000 - val_loss: 2.4251 - val_accuracy: 0.2656\n",
            "Epoch 339/500\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 0.0899 - accuracy: 1.0000 - val_loss: 2.4685 - val_accuracy: 0.1875\n",
            "Epoch 340/500\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.0921 - accuracy: 1.0000 - val_loss: 2.4923 - val_accuracy: 0.2031\n",
            "Epoch 341/500\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.0939 - accuracy: 1.0000 - val_loss: 2.4274 - val_accuracy: 0.2656\n",
            "Epoch 342/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.0920 - accuracy: 1.0000 - val_loss: 2.4924 - val_accuracy: 0.2188\n",
            "Epoch 343/500\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.0898 - accuracy: 1.0000 - val_loss: 2.4515 - val_accuracy: 0.2500\n",
            "Epoch 344/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.0878 - accuracy: 1.0000 - val_loss: 2.4253 - val_accuracy: 0.2812\n",
            "Epoch 345/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.0807 - accuracy: 1.0000 - val_loss: 2.4498 - val_accuracy: 0.2500\n",
            "Epoch 346/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.0798 - accuracy: 1.0000 - val_loss: 2.4529 - val_accuracy: 0.2656\n",
            "Epoch 347/500\n",
            "5/5 [==============================] - 0s 45ms/step - loss: 0.0782 - accuracy: 1.0000 - val_loss: 2.4584 - val_accuracy: 0.2188\n",
            "Epoch 348/500\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.0800 - accuracy: 1.0000 - val_loss: 2.4828 - val_accuracy: 0.2500\n",
            "Epoch 349/500\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.0808 - accuracy: 1.0000 - val_loss: 2.4665 - val_accuracy: 0.2500\n",
            "Epoch 350/500\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.0777 - accuracy: 1.0000 - val_loss: 2.4486 - val_accuracy: 0.2500\n",
            "Epoch 351/500\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.0741 - accuracy: 1.0000 - val_loss: 2.4388 - val_accuracy: 0.2656\n",
            "Epoch 352/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.0729 - accuracy: 1.0000 - val_loss: 2.4624 - val_accuracy: 0.2656\n",
            "Epoch 353/500\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.0733 - accuracy: 1.0000 - val_loss: 2.4812 - val_accuracy: 0.2344\n",
            "Epoch 354/500\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.0692 - accuracy: 1.0000 - val_loss: 2.4935 - val_accuracy: 0.2344\n",
            "Epoch 355/500\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.0720 - accuracy: 1.0000 - val_loss: 2.4427 - val_accuracy: 0.2812\n",
            "Epoch 356/500\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.0718 - accuracy: 1.0000 - val_loss: 2.4543 - val_accuracy: 0.2500\n",
            "Epoch 357/500\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 0.0669 - accuracy: 1.0000 - val_loss: 2.4429 - val_accuracy: 0.2500\n",
            "Epoch 358/500\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 0.0699 - accuracy: 1.0000 - val_loss: 2.4530 - val_accuracy: 0.2500\n",
            "Epoch 359/500\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.0664 - accuracy: 1.0000 - val_loss: 2.4838 - val_accuracy: 0.2344\n",
            "Epoch 360/500\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 0.0677 - accuracy: 1.0000 - val_loss: 2.4937 - val_accuracy: 0.2344\n",
            "Epoch 361/500\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.0667 - accuracy: 1.0000 - val_loss: 2.4839 - val_accuracy: 0.2500\n",
            "Epoch 362/500\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.0669 - accuracy: 1.0000 - val_loss: 2.4610 - val_accuracy: 0.2344\n",
            "Epoch 363/500\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.0602 - accuracy: 1.0000 - val_loss: 2.4846 - val_accuracy: 0.2344\n",
            "Epoch 364/500\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 0.0598 - accuracy: 1.0000 - val_loss: 2.4715 - val_accuracy: 0.2500\n",
            "Epoch 365/500\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 0.0580 - accuracy: 1.0000 - val_loss: 2.4670 - val_accuracy: 0.2656\n",
            "Epoch 366/500\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.0575 - accuracy: 1.0000 - val_loss: 2.5159 - val_accuracy: 0.2344\n",
            "Epoch 367/500\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.0623 - accuracy: 1.0000 - val_loss: 2.5033 - val_accuracy: 0.2344\n",
            "Epoch 368/500\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 0.0587 - accuracy: 1.0000 - val_loss: 2.4934 - val_accuracy: 0.2656\n",
            "Epoch 369/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.0577 - accuracy: 1.0000 - val_loss: 2.4756 - val_accuracy: 0.2500\n",
            "Epoch 370/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.0549 - accuracy: 1.0000 - val_loss: 2.4942 - val_accuracy: 0.2500\n",
            "Epoch 371/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.0551 - accuracy: 1.0000 - val_loss: 2.4693 - val_accuracy: 0.2500\n",
            "Epoch 372/500\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.0529 - accuracy: 1.0000 - val_loss: 2.5207 - val_accuracy: 0.2500\n",
            "Epoch 373/500\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.0573 - accuracy: 1.0000 - val_loss: 2.4963 - val_accuracy: 0.2500\n",
            "Epoch 374/500\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.0525 - accuracy: 1.0000 - val_loss: 2.5116 - val_accuracy: 0.2031\n",
            "Epoch 375/500\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.0560 - accuracy: 1.0000 - val_loss: 2.5284 - val_accuracy: 0.2188\n",
            "Epoch 376/500\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.0550 - accuracy: 1.0000 - val_loss: 2.4734 - val_accuracy: 0.2812\n",
            "Epoch 377/500\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 0.0530 - accuracy: 1.0000 - val_loss: 2.4984 - val_accuracy: 0.2656\n",
            "Epoch 378/500\n",
            "5/5 [==============================] - 0s 57ms/step - loss: 0.0516 - accuracy: 1.0000 - val_loss: 2.5033 - val_accuracy: 0.2344\n",
            "Epoch 379/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.0510 - accuracy: 1.0000 - val_loss: 2.5122 - val_accuracy: 0.2500\n",
            "Epoch 380/500\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.0484 - accuracy: 1.0000 - val_loss: 2.5079 - val_accuracy: 0.2344\n",
            "Epoch 381/500\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 0.0502 - accuracy: 1.0000 - val_loss: 2.5247 - val_accuracy: 0.2188\n",
            "Epoch 382/500\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 0.0514 - accuracy: 1.0000 - val_loss: 2.5320 - val_accuracy: 0.2500\n",
            "Epoch 383/500\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.0480 - accuracy: 1.0000 - val_loss: 2.4943 - val_accuracy: 0.2500\n",
            "Epoch 384/500\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.0491 - accuracy: 1.0000 - val_loss: 2.4780 - val_accuracy: 0.2656\n",
            "Epoch 385/500\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 0.0471 - accuracy: 1.0000 - val_loss: 2.5093 - val_accuracy: 0.2500\n",
            "Epoch 386/500\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 0.0483 - accuracy: 1.0000 - val_loss: 2.5654 - val_accuracy: 0.2188\n",
            "Epoch 387/500\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.0466 - accuracy: 1.0000 - val_loss: 2.4932 - val_accuracy: 0.2656\n",
            "Epoch 388/500\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 0.0450 - accuracy: 1.0000 - val_loss: 2.5066 - val_accuracy: 0.2344\n",
            "Epoch 389/500\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.0431 - accuracy: 1.0000 - val_loss: 2.5029 - val_accuracy: 0.2656\n",
            "Epoch 390/500\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.0440 - accuracy: 1.0000 - val_loss: 2.5516 - val_accuracy: 0.2344\n",
            "Epoch 391/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.0438 - accuracy: 1.0000 - val_loss: 2.5316 - val_accuracy: 0.2500\n",
            "Epoch 392/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.0453 - accuracy: 1.0000 - val_loss: 2.5636 - val_accuracy: 0.2344\n",
            "Epoch 393/500\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.0452 - accuracy: 1.0000 - val_loss: 2.4935 - val_accuracy: 0.2500\n",
            "Epoch 394/500\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.0423 - accuracy: 1.0000 - val_loss: 2.5253 - val_accuracy: 0.2812\n",
            "Epoch 395/500\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.0402 - accuracy: 1.0000 - val_loss: 2.5438 - val_accuracy: 0.2500\n",
            "Epoch 396/500\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.0415 - accuracy: 1.0000 - val_loss: 2.5651 - val_accuracy: 0.2344\n",
            "Epoch 397/500\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 0.0426 - accuracy: 1.0000 - val_loss: 2.5086 - val_accuracy: 0.2500\n",
            "Epoch 398/500\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.0418 - accuracy: 1.0000 - val_loss: 2.5298 - val_accuracy: 0.2656\n",
            "Epoch 399/500\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.0419 - accuracy: 1.0000 - val_loss: 2.5130 - val_accuracy: 0.2812\n",
            "Epoch 400/500\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.0434 - accuracy: 1.0000 - val_loss: 2.5319 - val_accuracy: 0.2500\n",
            "Epoch 401/500\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 0.0400 - accuracy: 1.0000 - val_loss: 2.5184 - val_accuracy: 0.2656\n",
            "Epoch 402/500\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.0390 - accuracy: 1.0000 - val_loss: 2.5457 - val_accuracy: 0.2344\n",
            "Epoch 403/500\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 0.0384 - accuracy: 1.0000 - val_loss: 2.5187 - val_accuracy: 0.2656\n",
            "Epoch 404/500\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 0.0366 - accuracy: 1.0000 - val_loss: 2.5145 - val_accuracy: 0.2812\n",
            "Epoch 405/500\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 0.0390 - accuracy: 1.0000 - val_loss: 2.5360 - val_accuracy: 0.2812\n",
            "Epoch 406/500\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.0385 - accuracy: 1.0000 - val_loss: 2.5206 - val_accuracy: 0.2656\n",
            "Epoch 407/500\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.0390 - accuracy: 1.0000 - val_loss: 2.4936 - val_accuracy: 0.2812\n",
            "Epoch 408/500\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.0368 - accuracy: 1.0000 - val_loss: 2.5384 - val_accuracy: 0.2344\n",
            "Epoch 409/500\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 0.0385 - accuracy: 1.0000 - val_loss: 2.5346 - val_accuracy: 0.2344\n",
            "Epoch 410/500\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.0375 - accuracy: 1.0000 - val_loss: 2.5377 - val_accuracy: 0.2656\n",
            "Epoch 411/500\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 0.0368 - accuracy: 1.0000 - val_loss: 2.5205 - val_accuracy: 0.2500\n",
            "Epoch 412/500\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.0381 - accuracy: 1.0000 - val_loss: 2.5375 - val_accuracy: 0.2500\n",
            "Epoch 413/500\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 0.0348 - accuracy: 1.0000 - val_loss: 2.5225 - val_accuracy: 0.2344\n",
            "Epoch 414/500\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 0.0351 - accuracy: 1.0000 - val_loss: 2.5926 - val_accuracy: 0.2188\n",
            "Epoch 415/500\n",
            "5/5 [==============================] - 0s 46ms/step - loss: 0.0348 - accuracy: 1.0000 - val_loss: 2.5274 - val_accuracy: 0.2656\n",
            "Epoch 416/500\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.0367 - accuracy: 1.0000 - val_loss: 2.5307 - val_accuracy: 0.2812\n",
            "Epoch 417/500\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.0328 - accuracy: 1.0000 - val_loss: 2.5500 - val_accuracy: 0.2344\n",
            "Epoch 418/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.0347 - accuracy: 1.0000 - val_loss: 2.5449 - val_accuracy: 0.2344\n",
            "Epoch 419/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.0346 - accuracy: 1.0000 - val_loss: 2.5349 - val_accuracy: 0.2188\n",
            "Epoch 420/500\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.0330 - accuracy: 1.0000 - val_loss: 2.6305 - val_accuracy: 0.2031\n",
            "Epoch 421/500\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 0.0347 - accuracy: 1.0000 - val_loss: 2.5484 - val_accuracy: 0.2344\n",
            "Epoch 422/500\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.0363 - accuracy: 1.0000 - val_loss: 2.5322 - val_accuracy: 0.2656\n",
            "Epoch 423/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.0344 - accuracy: 1.0000 - val_loss: 2.5719 - val_accuracy: 0.2656\n",
            "Epoch 424/500\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 0.0310 - accuracy: 1.0000 - val_loss: 2.5470 - val_accuracy: 0.2500\n",
            "Epoch 425/500\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.0323 - accuracy: 1.0000 - val_loss: 2.5806 - val_accuracy: 0.2500\n",
            "Epoch 426/500\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.0312 - accuracy: 1.0000 - val_loss: 2.5431 - val_accuracy: 0.2500\n",
            "Epoch 427/500\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 0.0325 - accuracy: 1.0000 - val_loss: 2.5404 - val_accuracy: 0.2812\n",
            "Epoch 428/500\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 0.0320 - accuracy: 1.0000 - val_loss: 2.5671 - val_accuracy: 0.2344\n",
            "Epoch 429/500\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 0.0320 - accuracy: 1.0000 - val_loss: 2.5488 - val_accuracy: 0.2656\n",
            "Epoch 430/500\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 0.0310 - accuracy: 1.0000 - val_loss: 2.5502 - val_accuracy: 0.2500\n",
            "Epoch 431/500\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.0308 - accuracy: 1.0000 - val_loss: 2.5585 - val_accuracy: 0.2344\n",
            "Epoch 432/500\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 0.0300 - accuracy: 1.0000 - val_loss: 2.5521 - val_accuracy: 0.2656\n",
            "Epoch 433/500\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 0.0300 - accuracy: 1.0000 - val_loss: 2.5469 - val_accuracy: 0.2500\n",
            "Epoch 434/500\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 0.0287 - accuracy: 1.0000 - val_loss: 2.5662 - val_accuracy: 0.2500\n",
            "Epoch 435/500\n",
            "5/5 [==============================] - 0s 45ms/step - loss: 0.0303 - accuracy: 1.0000 - val_loss: 2.5372 - val_accuracy: 0.2812\n",
            "Epoch 436/500\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 0.0280 - accuracy: 1.0000 - val_loss: 2.5557 - val_accuracy: 0.2812\n",
            "Epoch 437/500\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 0.0292 - accuracy: 1.0000 - val_loss: 2.5517 - val_accuracy: 0.2344\n",
            "Epoch 438/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.0285 - accuracy: 1.0000 - val_loss: 2.5530 - val_accuracy: 0.2500\n",
            "Epoch 439/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.0284 - accuracy: 1.0000 - val_loss: 2.5521 - val_accuracy: 0.2656\n",
            "Epoch 440/500\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.0281 - accuracy: 1.0000 - val_loss: 2.5472 - val_accuracy: 0.2500\n",
            "Epoch 441/500\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.0285 - accuracy: 1.0000 - val_loss: 2.5470 - val_accuracy: 0.2500\n",
            "Epoch 442/500\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.0288 - accuracy: 1.0000 - val_loss: 2.5877 - val_accuracy: 0.2344\n",
            "Epoch 443/500\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 0.0282 - accuracy: 1.0000 - val_loss: 2.5803 - val_accuracy: 0.2188\n",
            "Epoch 444/500\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 0.0293 - accuracy: 1.0000 - val_loss: 2.5667 - val_accuracy: 0.2500\n",
            "Epoch 445/500\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.0269 - accuracy: 1.0000 - val_loss: 2.5665 - val_accuracy: 0.2500\n",
            "Epoch 446/500\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 0.0280 - accuracy: 1.0000 - val_loss: 2.5721 - val_accuracy: 0.2500\n",
            "Epoch 447/500\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 0.0285 - accuracy: 1.0000 - val_loss: 2.5834 - val_accuracy: 0.2500\n",
            "Epoch 448/500\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 0.0259 - accuracy: 1.0000 - val_loss: 2.5597 - val_accuracy: 0.2500\n",
            "Epoch 449/500\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.0263 - accuracy: 1.0000 - val_loss: 2.5670 - val_accuracy: 0.2188\n",
            "Epoch 450/500\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 0.0266 - accuracy: 1.0000 - val_loss: 2.5641 - val_accuracy: 0.2188\n",
            "Epoch 451/500\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 0.0268 - accuracy: 1.0000 - val_loss: 2.5527 - val_accuracy: 0.2656\n",
            "Epoch 452/500\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 0.0252 - accuracy: 1.0000 - val_loss: 2.5593 - val_accuracy: 0.2500\n",
            "Epoch 453/500\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.0281 - accuracy: 1.0000 - val_loss: 2.5647 - val_accuracy: 0.2500\n",
            "Epoch 454/500\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 0.0264 - accuracy: 1.0000 - val_loss: 2.5624 - val_accuracy: 0.2656\n",
            "Epoch 455/500\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.0257 - accuracy: 1.0000 - val_loss: 2.5790 - val_accuracy: 0.2500\n",
            "Epoch 456/500\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 0.0253 - accuracy: 1.0000 - val_loss: 2.5728 - val_accuracy: 0.2500\n",
            "Epoch 457/500\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.0256 - accuracy: 1.0000 - val_loss: 2.5579 - val_accuracy: 0.2500\n",
            "Epoch 458/500\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.0243 - accuracy: 1.0000 - val_loss: 2.5548 - val_accuracy: 0.2812\n",
            "Epoch 459/500\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 0.0254 - accuracy: 1.0000 - val_loss: 2.5773 - val_accuracy: 0.2500\n",
            "Epoch 460/500\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.0243 - accuracy: 1.0000 - val_loss: 2.5591 - val_accuracy: 0.2500\n",
            "Epoch 461/500\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.0257 - accuracy: 1.0000 - val_loss: 2.6518 - val_accuracy: 0.2031\n",
            "Epoch 462/500\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 0.0248 - accuracy: 1.0000 - val_loss: 2.5841 - val_accuracy: 0.2500\n",
            "Epoch 463/500\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.0247 - accuracy: 1.0000 - val_loss: 2.6020 - val_accuracy: 0.2344\n",
            "Epoch 464/500\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.0237 - accuracy: 1.0000 - val_loss: 2.5753 - val_accuracy: 0.2344\n",
            "Epoch 465/500\n",
            "5/5 [==============================] - 0s 48ms/step - loss: 0.0252 - accuracy: 1.0000 - val_loss: 2.5821 - val_accuracy: 0.2344\n",
            "Epoch 466/500\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.0237 - accuracy: 1.0000 - val_loss: 2.6034 - val_accuracy: 0.2344\n",
            "Epoch 467/500\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.0250 - accuracy: 1.0000 - val_loss: 2.6192 - val_accuracy: 0.2188\n",
            "Epoch 468/500\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.0221 - accuracy: 1.0000 - val_loss: 2.5896 - val_accuracy: 0.2344\n",
            "Epoch 469/500\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 0.0248 - accuracy: 1.0000 - val_loss: 2.6344 - val_accuracy: 0.2031\n",
            "Epoch 470/500\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 0.0246 - accuracy: 1.0000 - val_loss: 2.5691 - val_accuracy: 0.2500\n",
            "Epoch 471/500\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.0256 - accuracy: 1.0000 - val_loss: 2.5782 - val_accuracy: 0.2344\n",
            "Epoch 472/500\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.0219 - accuracy: 1.0000 - val_loss: 2.5955 - val_accuracy: 0.2188\n",
            "Epoch 473/500\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.0227 - accuracy: 1.0000 - val_loss: 2.5778 - val_accuracy: 0.2344\n",
            "Epoch 474/500\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.0221 - accuracy: 1.0000 - val_loss: 2.5777 - val_accuracy: 0.2500\n",
            "Epoch 475/500\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.0235 - accuracy: 1.0000 - val_loss: 2.6050 - val_accuracy: 0.2188\n",
            "Epoch 476/500\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.0239 - accuracy: 1.0000 - val_loss: 2.6266 - val_accuracy: 0.2188\n",
            "Epoch 477/500\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 0.0224 - accuracy: 1.0000 - val_loss: 2.6290 - val_accuracy: 0.2031\n",
            "Epoch 478/500\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.0237 - accuracy: 1.0000 - val_loss: 2.6148 - val_accuracy: 0.2344\n",
            "Epoch 479/500\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.0227 - accuracy: 1.0000 - val_loss: 2.5780 - val_accuracy: 0.2344\n",
            "Epoch 480/500\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.0226 - accuracy: 1.0000 - val_loss: 2.6105 - val_accuracy: 0.2031\n",
            "Epoch 481/500\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.0205 - accuracy: 1.0000 - val_loss: 2.6011 - val_accuracy: 0.2031\n",
            "Epoch 482/500\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 0.0228 - accuracy: 1.0000 - val_loss: 2.6176 - val_accuracy: 0.2188\n",
            "Epoch 483/500\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 0.0227 - accuracy: 1.0000 - val_loss: 2.6117 - val_accuracy: 0.1875\n",
            "Epoch 484/500\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.0237 - accuracy: 1.0000 - val_loss: 2.7085 - val_accuracy: 0.2188\n",
            "Epoch 485/500\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 0.0223 - accuracy: 1.0000 - val_loss: 2.5901 - val_accuracy: 0.2344\n",
            "Epoch 486/500\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 0.0216 - accuracy: 1.0000 - val_loss: 2.5985 - val_accuracy: 0.2500\n",
            "Epoch 487/500\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 0.0220 - accuracy: 1.0000 - val_loss: 2.5954 - val_accuracy: 0.2344\n",
            "Epoch 488/500\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.0214 - accuracy: 1.0000 - val_loss: 2.6029 - val_accuracy: 0.2500\n",
            "Epoch 489/500\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.0211 - accuracy: 1.0000 - val_loss: 2.6009 - val_accuracy: 0.2188\n",
            "Epoch 490/500\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.0205 - accuracy: 1.0000 - val_loss: 2.5907 - val_accuracy: 0.2188\n",
            "Epoch 491/500\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.0198 - accuracy: 1.0000 - val_loss: 2.5863 - val_accuracy: 0.2500\n",
            "Epoch 492/500\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.0199 - accuracy: 1.0000 - val_loss: 2.5924 - val_accuracy: 0.2344\n",
            "Epoch 493/500\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.0203 - accuracy: 1.0000 - val_loss: 2.6023 - val_accuracy: 0.2500\n",
            "Epoch 494/500\n",
            "5/5 [==============================] - 0s 47ms/step - loss: 0.0201 - accuracy: 1.0000 - val_loss: 2.6048 - val_accuracy: 0.2188\n",
            "Epoch 495/500\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.0203 - accuracy: 1.0000 - val_loss: 2.6324 - val_accuracy: 0.2188\n",
            "Epoch 496/500\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.0204 - accuracy: 1.0000 - val_loss: 2.5983 - val_accuracy: 0.2344\n",
            "Epoch 497/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.0200 - accuracy: 1.0000 - val_loss: 2.6003 - val_accuracy: 0.2188\n",
            "Epoch 498/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.0182 - accuracy: 1.0000 - val_loss: 2.5992 - val_accuracy: 0.2344\n",
            "Epoch 499/500\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.0190 - accuracy: 1.0000 - val_loss: 2.6185 - val_accuracy: 0.2344\n",
            "Epoch 500/500\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.0199 - accuracy: 1.0000 - val_loss: 2.5995 - val_accuracy: 0.2344\n"
          ]
        }
      ],
      "source": [
        "pruningcallback_2=PruningCallback(init_step=100, end_step=250,\n",
        "                                init_sparsity=0.4, end_sparsity=0.85,pruning_step=5)\n",
        "tf.random.set_seed(1234)\n",
        "hist_p_2=model_to_prune_2.fit(X_train_50.reshape(-1,dim_50[0],dim_50[0],3), y_train, \n",
        "                     batch_size=50, epochs=500,\n",
        "                     callbacks=[pruningcallback_2],\n",
        "                     validation_data=(X_test_50.reshape(-1,dim_50[0],dim_50[0],3),y_test),verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZGHig-9o07fP",
        "outputId": "f2fd2c20-913a-433b-ad42-46ef9c52dbde",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n",
            "5/5 [==============================] - 1s 83ms/step - loss: 2.8292 - accuracy: 0.0973 - val_loss: 2.6390 - val_accuracy: 0.0781\n",
            "Epoch 2/500\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 2.0412 - accuracy: 0.3540 - val_loss: 2.6429 - val_accuracy: 0.0625\n",
            "Epoch 3/500\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 1.5359 - accuracy: 0.6327 - val_loss: 2.6433 - val_accuracy: 0.0625\n",
            "Epoch 4/500\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 1.2203 - accuracy: 0.7566 - val_loss: 2.6465 - val_accuracy: 0.0781\n",
            "Epoch 5/500\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.9611 - accuracy: 0.8894 - val_loss: 2.6522 - val_accuracy: 0.0938\n",
            "Epoch 6/500\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.7838 - accuracy: 0.9248 - val_loss: 2.6610 - val_accuracy: 0.1250\n",
            "Epoch 7/500\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.6109 - accuracy: 0.9690 - val_loss: 2.6675 - val_accuracy: 0.1094\n",
            "Epoch 8/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.4857 - accuracy: 0.9867 - val_loss: 2.6761 - val_accuracy: 0.0938\n",
            "Epoch 9/500\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.4120 - accuracy: 0.9956 - val_loss: 2.6847 - val_accuracy: 0.1094\n",
            "Epoch 10/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.3495 - accuracy: 0.9912 - val_loss: 2.6960 - val_accuracy: 0.0938\n",
            "Epoch 11/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.2858 - accuracy: 0.9956 - val_loss: 2.7073 - val_accuracy: 0.0781\n",
            "Epoch 12/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.2466 - accuracy: 1.0000 - val_loss: 2.7120 - val_accuracy: 0.0625\n",
            "Epoch 13/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.2111 - accuracy: 1.0000 - val_loss: 2.7252 - val_accuracy: 0.0781\n",
            "Epoch 14/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.1877 - accuracy: 1.0000 - val_loss: 2.7345 - val_accuracy: 0.0938\n",
            "Epoch 15/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.1669 - accuracy: 1.0000 - val_loss: 2.7496 - val_accuracy: 0.1094\n",
            "Epoch 16/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.1478 - accuracy: 1.0000 - val_loss: 2.7623 - val_accuracy: 0.0781\n",
            "Epoch 17/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.1392 - accuracy: 1.0000 - val_loss: 2.7749 - val_accuracy: 0.0625\n",
            "Epoch 18/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.1266 - accuracy: 1.0000 - val_loss: 2.7867 - val_accuracy: 0.0625\n",
            "Epoch 19/500\n",
            "5/5 [==============================] - 0s 32ms/step - loss: 0.1189 - accuracy: 1.0000 - val_loss: 2.7952 - val_accuracy: 0.0625\n",
            "Epoch 20/500\n",
            "5/5 [==============================] - 0s 32ms/step - loss: 0.1041 - accuracy: 1.0000 - val_loss: 2.8112 - val_accuracy: 0.0625\n",
            "Epoch 21/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.0945 - accuracy: 1.0000 - val_loss: 2.8255 - val_accuracy: 0.0938\n",
            "Epoch 22/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.0916 - accuracy: 1.0000 - val_loss: 2.8432 - val_accuracy: 0.0625\n",
            "Epoch 23/500\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.0864 - accuracy: 1.0000 - val_loss: 2.8623 - val_accuracy: 0.0625\n",
            "Epoch 24/500\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.0835 - accuracy: 1.0000 - val_loss: 2.8773 - val_accuracy: 0.0625\n",
            "Epoch 25/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.0770 - accuracy: 1.0000 - val_loss: 2.8874 - val_accuracy: 0.0781\n",
            "Epoch 26/500\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.0701 - accuracy: 1.0000 - val_loss: 2.9050 - val_accuracy: 0.0938\n",
            "Epoch 27/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.0679 - accuracy: 1.0000 - val_loss: 2.9195 - val_accuracy: 0.0781\n",
            "Epoch 28/500\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.0637 - accuracy: 1.0000 - val_loss: 2.9334 - val_accuracy: 0.0781\n",
            "Epoch 29/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.0630 - accuracy: 1.0000 - val_loss: 2.9425 - val_accuracy: 0.1094\n",
            "Epoch 30/500\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.0595 - accuracy: 1.0000 - val_loss: 2.9616 - val_accuracy: 0.0938\n",
            "Epoch 31/500\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.0585 - accuracy: 1.0000 - val_loss: 2.9794 - val_accuracy: 0.0938\n",
            "Epoch 32/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.0574 - accuracy: 1.0000 - val_loss: 2.9876 - val_accuracy: 0.0938\n",
            "Epoch 33/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.0532 - accuracy: 1.0000 - val_loss: 2.9938 - val_accuracy: 0.0781\n",
            "Epoch 34/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.0528 - accuracy: 1.0000 - val_loss: 3.0097 - val_accuracy: 0.0781\n",
            "Epoch 35/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.0482 - accuracy: 1.0000 - val_loss: 3.0227 - val_accuracy: 0.0781\n",
            "Epoch 36/500\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.0465 - accuracy: 1.0000 - val_loss: 3.0376 - val_accuracy: 0.0625\n",
            "Epoch 37/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.0433 - accuracy: 1.0000 - val_loss: 3.0469 - val_accuracy: 0.0625\n",
            "Epoch 38/500\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.0439 - accuracy: 1.0000 - val_loss: 3.0531 - val_accuracy: 0.0625\n",
            "Epoch 39/500\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 0.0433 - accuracy: 1.0000 - val_loss: 3.0655 - val_accuracy: 0.0625\n",
            "Epoch 40/500\n",
            "5/5 [==============================] - 0s 32ms/step - loss: 0.0413 - accuracy: 1.0000 - val_loss: 3.0813 - val_accuracy: 0.0625\n",
            "Epoch 41/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.0429 - accuracy: 1.0000 - val_loss: 3.0826 - val_accuracy: 0.0625\n",
            "Epoch 42/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.0379 - accuracy: 1.0000 - val_loss: 3.0970 - val_accuracy: 0.0625\n",
            "Epoch 43/500\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.0365 - accuracy: 1.0000 - val_loss: 3.1059 - val_accuracy: 0.0625\n",
            "Epoch 44/500\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.0366 - accuracy: 1.0000 - val_loss: 3.1148 - val_accuracy: 0.0625\n",
            "Epoch 45/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.0354 - accuracy: 1.0000 - val_loss: 3.1281 - val_accuracy: 0.0781\n",
            "Epoch 46/500\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.0343 - accuracy: 1.0000 - val_loss: 3.1400 - val_accuracy: 0.0625\n",
            "Epoch 47/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.0339 - accuracy: 1.0000 - val_loss: 3.1451 - val_accuracy: 0.0781\n",
            "Epoch 48/500\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.0322 - accuracy: 1.0000 - val_loss: 3.1548 - val_accuracy: 0.0781\n",
            "Epoch 49/500\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 0.0320 - accuracy: 1.0000 - val_loss: 3.1611 - val_accuracy: 0.0938\n",
            "Epoch 50/500\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.0310 - accuracy: 1.0000 - val_loss: 3.1635 - val_accuracy: 0.0938\n",
            "Epoch 51/500\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 0.0307 - accuracy: 1.0000 - val_loss: 3.1760 - val_accuracy: 0.0938\n",
            "Epoch 52/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.0294 - accuracy: 1.0000 - val_loss: 3.1814 - val_accuracy: 0.0938\n",
            "Epoch 53/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.0283 - accuracy: 1.0000 - val_loss: 3.1900 - val_accuracy: 0.0938\n",
            "Epoch 54/500\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.0285 - accuracy: 1.0000 - val_loss: 3.1877 - val_accuracy: 0.0938\n",
            "Epoch 55/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.0277 - accuracy: 1.0000 - val_loss: 3.1857 - val_accuracy: 0.0938\n",
            "Epoch 56/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.0265 - accuracy: 1.0000 - val_loss: 3.1897 - val_accuracy: 0.0938\n",
            "Epoch 57/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.0266 - accuracy: 1.0000 - val_loss: 3.1887 - val_accuracy: 0.0938\n",
            "Epoch 58/500\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.0258 - accuracy: 1.0000 - val_loss: 3.1881 - val_accuracy: 0.0938\n",
            "Epoch 59/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.0288 - accuracy: 1.0000 - val_loss: 3.1871 - val_accuracy: 0.0938\n",
            "Epoch 60/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.0248 - accuracy: 1.0000 - val_loss: 3.1822 - val_accuracy: 0.0938\n",
            "Epoch 61/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.0264 - accuracy: 1.0000 - val_loss: 3.1799 - val_accuracy: 0.0781\n",
            "Epoch 62/500\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.0249 - accuracy: 1.0000 - val_loss: 3.1716 - val_accuracy: 0.0781\n",
            "Epoch 63/500\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 0.0241 - accuracy: 1.0000 - val_loss: 3.1749 - val_accuracy: 0.0781\n",
            "Epoch 64/500\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.0248 - accuracy: 1.0000 - val_loss: 3.1718 - val_accuracy: 0.0781\n",
            "Epoch 65/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.0231 - accuracy: 1.0000 - val_loss: 3.1690 - val_accuracy: 0.0938\n",
            "Epoch 66/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.0222 - accuracy: 1.0000 - val_loss: 3.1645 - val_accuracy: 0.1094\n",
            "Epoch 67/500\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.0219 - accuracy: 1.0000 - val_loss: 3.1608 - val_accuracy: 0.1250\n",
            "Epoch 68/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.0220 - accuracy: 1.0000 - val_loss: 3.1504 - val_accuracy: 0.1250\n",
            "Epoch 69/500\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.0212 - accuracy: 1.0000 - val_loss: 3.1452 - val_accuracy: 0.1406\n",
            "Epoch 70/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.0229 - accuracy: 1.0000 - val_loss: 3.1304 - val_accuracy: 0.1406\n",
            "Epoch 71/500\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.0207 - accuracy: 1.0000 - val_loss: 3.1186 - val_accuracy: 0.1406\n",
            "Epoch 72/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.0204 - accuracy: 1.0000 - val_loss: 3.1078 - val_accuracy: 0.1406\n",
            "Epoch 73/500\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 0.0194 - accuracy: 1.0000 - val_loss: 3.1047 - val_accuracy: 0.1406\n",
            "Epoch 74/500\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.0195 - accuracy: 1.0000 - val_loss: 3.0930 - val_accuracy: 0.1719\n",
            "Epoch 75/500\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.0188 - accuracy: 1.0000 - val_loss: 3.0776 - val_accuracy: 0.1875\n",
            "Epoch 76/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.0198 - accuracy: 1.0000 - val_loss: 3.0662 - val_accuracy: 0.1875\n",
            "Epoch 77/500\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 0.0186 - accuracy: 1.0000 - val_loss: 3.0514 - val_accuracy: 0.1875\n",
            "Epoch 78/500\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.0188 - accuracy: 1.0000 - val_loss: 3.0425 - val_accuracy: 0.1875\n",
            "Epoch 79/500\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.0176 - accuracy: 1.0000 - val_loss: 3.0221 - val_accuracy: 0.1875\n",
            "Epoch 80/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.0172 - accuracy: 1.0000 - val_loss: 3.0101 - val_accuracy: 0.1875\n",
            "Epoch 81/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.0170 - accuracy: 1.0000 - val_loss: 2.9948 - val_accuracy: 0.1875\n",
            "Epoch 82/500\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.0167 - accuracy: 1.0000 - val_loss: 2.9799 - val_accuracy: 0.1875\n",
            "Epoch 83/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.0173 - accuracy: 1.0000 - val_loss: 2.9619 - val_accuracy: 0.1875\n",
            "Epoch 84/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.0166 - accuracy: 1.0000 - val_loss: 2.9453 - val_accuracy: 0.1875\n",
            "Epoch 85/500\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.0173 - accuracy: 1.0000 - val_loss: 2.9276 - val_accuracy: 0.1875\n",
            "Epoch 86/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.0161 - accuracy: 1.0000 - val_loss: 2.9089 - val_accuracy: 0.1875\n",
            "Epoch 87/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.0160 - accuracy: 1.0000 - val_loss: 2.8904 - val_accuracy: 0.1875\n",
            "Epoch 88/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.0162 - accuracy: 1.0000 - val_loss: 2.8719 - val_accuracy: 0.1875\n",
            "Epoch 89/500\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.0159 - accuracy: 1.0000 - val_loss: 2.8596 - val_accuracy: 0.1875\n",
            "Epoch 90/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.0152 - accuracy: 1.0000 - val_loss: 2.8330 - val_accuracy: 0.1875\n",
            "Epoch 91/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.0152 - accuracy: 1.0000 - val_loss: 2.8168 - val_accuracy: 0.1875\n",
            "Epoch 92/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.0155 - accuracy: 1.0000 - val_loss: 2.7856 - val_accuracy: 0.1875\n",
            "Epoch 93/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.0150 - accuracy: 1.0000 - val_loss: 2.7639 - val_accuracy: 0.2188\n",
            "Epoch 94/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.0148 - accuracy: 1.0000 - val_loss: 2.7449 - val_accuracy: 0.2031\n",
            "Epoch 95/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.0146 - accuracy: 1.0000 - val_loss: 2.7100 - val_accuracy: 0.2031\n",
            "Epoch 96/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.0142 - accuracy: 1.0000 - val_loss: 2.6953 - val_accuracy: 0.2031\n",
            "Epoch 97/500\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 0.0143 - accuracy: 1.0000 - val_loss: 2.6748 - val_accuracy: 0.2031\n",
            "Epoch 98/500\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 0.0142 - accuracy: 1.0000 - val_loss: 2.6506 - val_accuracy: 0.2031\n",
            "Epoch 99/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.0144 - accuracy: 1.0000 - val_loss: 2.6315 - val_accuracy: 0.2188\n",
            "Epoch 100/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.0140 - accuracy: 1.0000 - val_loss: 2.6174 - val_accuracy: 0.2344\n",
            "Epoch 101/500\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0137 - accuracy: 1.0000\n",
            " pruning [ = = = = ]\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 0.0137 - accuracy: 1.0000 - val_loss: 2.5954 - val_accuracy: 0.2500\n",
            "Epoch 102/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 2.3339 - accuracy: 0.2611 - val_loss: 2.8121 - val_accuracy: 0.1094\n",
            "Epoch 103/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 1.9492 - accuracy: 0.4381 - val_loss: 2.7759 - val_accuracy: 0.1094\n",
            "Epoch 104/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 1.6770 - accuracy: 0.5973 - val_loss: 2.7917 - val_accuracy: 0.1094\n",
            "Epoch 105/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 1.4932 - accuracy: 0.6903 - val_loss: 2.7486 - val_accuracy: 0.1094\n",
            "Epoch 106/500\n",
            "5/5 [==============================] - ETA: 0s - loss: 1.3246 - accuracy: 0.8407\n",
            " pruning [ = = = = ]\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 1.3246 - accuracy: 0.8407 - val_loss: 2.7801 - val_accuracy: 0.1094\n",
            "Epoch 107/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 1.4131 - accuracy: 0.7699 - val_loss: 2.6840 - val_accuracy: 0.1094\n",
            "Epoch 108/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 1.2251 - accuracy: 0.8673 - val_loss: 2.6909 - val_accuracy: 0.1094\n",
            "Epoch 109/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 1.1089 - accuracy: 0.8982 - val_loss: 2.6652 - val_accuracy: 0.0938\n",
            "Epoch 110/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.9987 - accuracy: 0.9248 - val_loss: 2.6566 - val_accuracy: 0.1406\n",
            "Epoch 111/500\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.8929 - accuracy: 0.9513\n",
            " pruning [ = = = = ]\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.8929 - accuracy: 0.9513 - val_loss: 2.6174 - val_accuracy: 0.1406\n",
            "Epoch 112/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 1.0655 - accuracy: 0.9115 - val_loss: 2.6514 - val_accuracy: 0.0938\n",
            "Epoch 113/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.9402 - accuracy: 0.9381 - val_loss: 2.6762 - val_accuracy: 0.1406\n",
            "Epoch 114/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.8211 - accuracy: 0.9513 - val_loss: 2.6581 - val_accuracy: 0.1406\n",
            "Epoch 115/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.7422 - accuracy: 0.9912 - val_loss: 2.6363 - val_accuracy: 0.1719\n",
            "Epoch 116/500\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.6860 - accuracy: 0.9779\n",
            " pruning [ = = = = ]\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.6860 - accuracy: 0.9779 - val_loss: 2.6037 - val_accuracy: 0.1250\n",
            "Epoch 117/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.8947 - accuracy: 0.9646 - val_loss: 2.5902 - val_accuracy: 0.1562\n",
            "Epoch 118/500\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 0.8515 - accuracy: 0.9558 - val_loss: 2.6290 - val_accuracy: 0.1406\n",
            "Epoch 119/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.6939 - accuracy: 0.9823 - val_loss: 2.5254 - val_accuracy: 0.2031\n",
            "Epoch 120/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.6176 - accuracy: 0.9912 - val_loss: 2.5869 - val_accuracy: 0.1250\n",
            "Epoch 121/500\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.5605 - accuracy: 0.9867\n",
            " pruning [ = = = = ]\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.5605 - accuracy: 0.9867 - val_loss: 2.5901 - val_accuracy: 0.1406\n",
            "Epoch 122/500\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.8206 - accuracy: 0.9823 - val_loss: 2.5698 - val_accuracy: 0.1562\n",
            "Epoch 123/500\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.6925 - accuracy: 0.9912 - val_loss: 2.5665 - val_accuracy: 0.2188\n",
            "Epoch 124/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.6260 - accuracy: 0.9912 - val_loss: 2.5482 - val_accuracy: 0.2031\n",
            "Epoch 125/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.5447 - accuracy: 0.9912 - val_loss: 2.5654 - val_accuracy: 0.1875\n",
            "Epoch 126/500\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.4765 - accuracy: 1.0000\n",
            " pruning [ = = = = ]\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.4765 - accuracy: 1.0000 - val_loss: 2.5193 - val_accuracy: 0.1875\n",
            "Epoch 127/500\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.6995 - accuracy: 0.9735 - val_loss: 2.4769 - val_accuracy: 0.1875\n",
            "Epoch 128/500\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.5889 - accuracy: 0.9912 - val_loss: 2.5093 - val_accuracy: 0.2344\n",
            "Epoch 129/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.5492 - accuracy: 0.9912 - val_loss: 2.4304 - val_accuracy: 0.1719\n",
            "Epoch 130/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.4879 - accuracy: 1.0000 - val_loss: 2.3921 - val_accuracy: 0.1875\n",
            "Epoch 131/500\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.4451 - accuracy: 0.9912\n",
            " pruning [ = = = = ]\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 0.4451 - accuracy: 0.9912 - val_loss: 2.4855 - val_accuracy: 0.2188\n",
            "Epoch 132/500\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 0.8533 - accuracy: 0.9735 - val_loss: 2.4899 - val_accuracy: 0.1562\n",
            "Epoch 133/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.7442 - accuracy: 0.9779 - val_loss: 2.3461 - val_accuracy: 0.2969\n",
            "Epoch 134/500\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.6349 - accuracy: 0.9912 - val_loss: 2.3436 - val_accuracy: 0.2031\n",
            "Epoch 135/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.6069 - accuracy: 0.9646 - val_loss: 2.4196 - val_accuracy: 0.2500\n",
            "Epoch 136/500\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.4998 - accuracy: 0.9956\n",
            " pruning [ = = = = ]\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.4998 - accuracy: 0.9956 - val_loss: 2.3597 - val_accuracy: 0.2500\n",
            "Epoch 137/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.7332 - accuracy: 0.9823 - val_loss: 2.5544 - val_accuracy: 0.1875\n",
            "Epoch 138/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.6555 - accuracy: 0.9690 - val_loss: 2.5015 - val_accuracy: 0.2031\n",
            "Epoch 139/500\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 0.5457 - accuracy: 0.9956 - val_loss: 2.3682 - val_accuracy: 0.2188\n",
            "Epoch 140/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.4869 - accuracy: 1.0000 - val_loss: 2.3614 - val_accuracy: 0.2344\n",
            "Epoch 141/500\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.4523 - accuracy: 0.9956\n",
            " pruning [ = = = = ]\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.4523 - accuracy: 0.9956 - val_loss: 2.3708 - val_accuracy: 0.2812\n",
            "Epoch 142/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.7184 - accuracy: 0.9735 - val_loss: 2.4188 - val_accuracy: 0.1719\n",
            "Epoch 143/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.6028 - accuracy: 0.9912 - val_loss: 2.3638 - val_accuracy: 0.2031\n",
            "Epoch 144/500\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.5249 - accuracy: 0.9956 - val_loss: 2.4647 - val_accuracy: 0.2031\n",
            "Epoch 145/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.4754 - accuracy: 1.0000 - val_loss: 2.3733 - val_accuracy: 0.1875\n",
            "Epoch 146/500\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.4191 - accuracy: 0.9912\n",
            " pruning [ = = = = ]\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.4191 - accuracy: 0.9912 - val_loss: 2.3920 - val_accuracy: 0.2656\n",
            "Epoch 147/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.6716 - accuracy: 0.9867 - val_loss: 2.3873 - val_accuracy: 0.1719\n",
            "Epoch 148/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.5687 - accuracy: 1.0000 - val_loss: 2.3852 - val_accuracy: 0.2344\n",
            "Epoch 149/500\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.5192 - accuracy: 1.0000 - val_loss: 2.2248 - val_accuracy: 0.2969\n",
            "Epoch 150/500\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.4483 - accuracy: 1.0000 - val_loss: 2.3500 - val_accuracy: 0.2188\n",
            "Epoch 151/500\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.4177 - accuracy: 1.0000\n",
            " pruning [ = = = = ]\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 0.4177 - accuracy: 1.0000 - val_loss: 2.1964 - val_accuracy: 0.2812\n",
            "Epoch 152/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.7162 - accuracy: 0.9867 - val_loss: 2.2580 - val_accuracy: 0.2969\n",
            "Epoch 153/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.5853 - accuracy: 0.9956 - val_loss: 2.4208 - val_accuracy: 0.1562\n",
            "Epoch 154/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.5120 - accuracy: 1.0000 - val_loss: 2.3799 - val_accuracy: 0.2188\n",
            "Epoch 155/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.4678 - accuracy: 1.0000 - val_loss: 2.3246 - val_accuracy: 0.2344\n",
            "Epoch 156/500\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.4071 - accuracy: 1.0000\n",
            " pruning [ = = = = ]\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 0.4071 - accuracy: 1.0000 - val_loss: 2.3016 - val_accuracy: 0.2656\n",
            "Epoch 157/500\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.7634 - accuracy: 0.9779 - val_loss: 2.3354 - val_accuracy: 0.2344\n",
            "Epoch 158/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.6722 - accuracy: 0.9779 - val_loss: 2.2932 - val_accuracy: 0.2031\n",
            "Epoch 159/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.6055 - accuracy: 0.9912 - val_loss: 2.3079 - val_accuracy: 0.2344\n",
            "Epoch 160/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.5026 - accuracy: 1.0000 - val_loss: 2.2049 - val_accuracy: 0.1719\n",
            "Epoch 161/500\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 0.5174 - accuracy: 1.0000\n",
            " pruning [ = = = = ]\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 0.5041 - accuracy: 1.0000 - val_loss: 2.2026 - val_accuracy: 0.3125\n",
            "Epoch 162/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.7759 - accuracy: 0.9690 - val_loss: 2.3718 - val_accuracy: 0.3125\n",
            "Epoch 163/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.6493 - accuracy: 0.9956 - val_loss: 2.2336 - val_accuracy: 0.2500\n",
            "Epoch 164/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.5636 - accuracy: 1.0000 - val_loss: 2.2511 - val_accuracy: 0.2344\n",
            "Epoch 165/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.4786 - accuracy: 1.0000 - val_loss: 2.2347 - val_accuracy: 0.2969\n",
            "Epoch 166/500\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.4420 - accuracy: 1.0000\n",
            " pruning [ = = = = ]\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.4420 - accuracy: 1.0000 - val_loss: 2.2287 - val_accuracy: 0.2500\n",
            "Epoch 167/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.6871 - accuracy: 0.9823 - val_loss: 2.5253 - val_accuracy: 0.1406\n",
            "Epoch 168/500\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.6063 - accuracy: 0.9956 - val_loss: 2.3540 - val_accuracy: 0.3125\n",
            "Epoch 169/500\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.5527 - accuracy: 0.9956 - val_loss: 2.2284 - val_accuracy: 0.2344\n",
            "Epoch 170/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.4641 - accuracy: 0.9956 - val_loss: 2.2902 - val_accuracy: 0.2500\n",
            "Epoch 171/500\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.4285 - accuracy: 1.0000\n",
            " pruning [ = = = = ]\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.4285 - accuracy: 1.0000 - val_loss: 2.2725 - val_accuracy: 0.3125\n",
            "Epoch 172/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.6687 - accuracy: 0.9867 - val_loss: 2.3618 - val_accuracy: 0.2656\n",
            "Epoch 173/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.5884 - accuracy: 0.9823 - val_loss: 2.3929 - val_accuracy: 0.2031\n",
            "Epoch 174/500\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.5189 - accuracy: 0.9956 - val_loss: 2.2352 - val_accuracy: 0.2500\n",
            "Epoch 175/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.4702 - accuracy: 1.0000 - val_loss: 2.2361 - val_accuracy: 0.2812\n",
            "Epoch 176/500\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.4073 - accuracy: 1.0000\n",
            " pruning [ = = = = ]\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.4073 - accuracy: 1.0000 - val_loss: 2.2600 - val_accuracy: 0.2656\n",
            "Epoch 177/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.8054 - accuracy: 0.9602 - val_loss: 2.4251 - val_accuracy: 0.2344\n",
            "Epoch 178/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.6374 - accuracy: 1.0000 - val_loss: 2.3011 - val_accuracy: 0.3125\n",
            "Epoch 179/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.5337 - accuracy: 1.0000 - val_loss: 2.3008 - val_accuracy: 0.2969\n",
            "Epoch 180/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.4986 - accuracy: 1.0000 - val_loss: 2.3826 - val_accuracy: 0.2344\n",
            "Epoch 181/500\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.4519 - accuracy: 1.0000\n",
            " pruning [ = = = = ]\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.4519 - accuracy: 1.0000 - val_loss: 2.2728 - val_accuracy: 0.3125\n",
            "Epoch 182/500\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.9028 - accuracy: 0.9602 - val_loss: 2.3337 - val_accuracy: 0.2344\n",
            "Epoch 183/500\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.7194 - accuracy: 0.9779 - val_loss: 2.3089 - val_accuracy: 0.2969\n",
            "Epoch 184/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.6347 - accuracy: 0.9779 - val_loss: 2.2825 - val_accuracy: 0.3125\n",
            "Epoch 185/500\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.5749 - accuracy: 0.9956 - val_loss: 2.3859 - val_accuracy: 0.2344\n",
            "Epoch 186/500\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.5302 - accuracy: 0.9867\n",
            " pruning [ = = = = ]\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 0.5302 - accuracy: 0.9867 - val_loss: 2.4462 - val_accuracy: 0.2344\n",
            "Epoch 187/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.9168 - accuracy: 0.9646 - val_loss: 2.3023 - val_accuracy: 0.2500\n",
            "Epoch 188/500\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.7234 - accuracy: 0.9823 - val_loss: 2.4987 - val_accuracy: 0.1719\n",
            "Epoch 189/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.6977 - accuracy: 0.9690 - val_loss: 2.2635 - val_accuracy: 0.3281\n",
            "Epoch 190/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.6238 - accuracy: 0.9823 - val_loss: 2.4311 - val_accuracy: 0.2500\n",
            "Epoch 191/500\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.5518 - accuracy: 1.0000\n",
            " pruning [ = = = = ]\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 0.5518 - accuracy: 1.0000 - val_loss: 2.1506 - val_accuracy: 0.2969\n",
            "Epoch 192/500\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.8886 - accuracy: 0.9735 - val_loss: 2.3186 - val_accuracy: 0.2656\n",
            "Epoch 193/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.7939 - accuracy: 0.9779 - val_loss: 2.2655 - val_accuracy: 0.2812\n",
            "Epoch 194/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.6924 - accuracy: 0.9867 - val_loss: 2.3965 - val_accuracy: 0.2031\n",
            "Epoch 195/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.6540 - accuracy: 0.9956 - val_loss: 2.2555 - val_accuracy: 0.2344\n",
            "Epoch 196/500\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.6243 - accuracy: 0.9912\n",
            " pruning [ = = = = ]\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 0.6243 - accuracy: 0.9912 - val_loss: 2.2798 - val_accuracy: 0.2812\n",
            "Epoch 197/500\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 0.9179 - accuracy: 0.9558 - val_loss: 2.2923 - val_accuracy: 0.2656\n",
            "Epoch 198/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.8280 - accuracy: 0.9867 - val_loss: 2.3522 - val_accuracy: 0.2500\n",
            "Epoch 199/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.7582 - accuracy: 0.9867 - val_loss: 2.3090 - val_accuracy: 0.2344\n",
            "Epoch 200/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.7013 - accuracy: 0.9867 - val_loss: 2.2527 - val_accuracy: 0.2344\n",
            "Epoch 201/500\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.6568 - accuracy: 1.0000\n",
            " pruning [ = = = = ]\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.6568 - accuracy: 1.0000 - val_loss: 2.1401 - val_accuracy: 0.3594\n",
            "Epoch 202/500\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 1.0885 - accuracy: 0.9248 - val_loss: 2.4297 - val_accuracy: 0.2500\n",
            "Epoch 203/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.8231 - accuracy: 0.9735 - val_loss: 2.3153 - val_accuracy: 0.2344\n",
            "Epoch 204/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.7769 - accuracy: 0.9690 - val_loss: 2.4105 - val_accuracy: 0.1875\n",
            "Epoch 205/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.7267 - accuracy: 0.9735 - val_loss: 2.3400 - val_accuracy: 0.2031\n",
            "Epoch 206/500\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 0.6191 - accuracy: 1.0000\n",
            " pruning [ = = = = ]\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.6103 - accuracy: 1.0000 - val_loss: 2.2168 - val_accuracy: 0.2656\n",
            "Epoch 207/500\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 1.2854 - accuracy: 0.8584 - val_loss: 2.3175 - val_accuracy: 0.2969\n",
            "Epoch 208/500\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 1.0968 - accuracy: 0.9381 - val_loss: 2.3325 - val_accuracy: 0.2656\n",
            "Epoch 209/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 1.0066 - accuracy: 0.9469 - val_loss: 2.2698 - val_accuracy: 0.2812\n",
            "Epoch 210/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.9268 - accuracy: 0.9823 - val_loss: 2.3615 - val_accuracy: 0.2656\n",
            "Epoch 211/500\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.8787 - accuracy: 0.9735\n",
            " pruning [ = = = = ]\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 0.8787 - accuracy: 0.9735 - val_loss: 2.2464 - val_accuracy: 0.3125\n",
            "Epoch 212/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 1.3368 - accuracy: 0.7920 - val_loss: 2.3280 - val_accuracy: 0.2812\n",
            "Epoch 213/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 1.1585 - accuracy: 0.9115 - val_loss: 2.3710 - val_accuracy: 0.2500\n",
            "Epoch 214/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 1.0853 - accuracy: 0.9513 - val_loss: 2.4482 - val_accuracy: 0.2344\n",
            "Epoch 215/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 1.0316 - accuracy: 0.9425 - val_loss: 2.2841 - val_accuracy: 0.2656\n",
            "Epoch 216/500\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.9694 - accuracy: 0.9469\n",
            " pruning [ = = = = ]\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.9694 - accuracy: 0.9469 - val_loss: 2.3785 - val_accuracy: 0.2344\n",
            "Epoch 217/500\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 1.3729 - accuracy: 0.8363 - val_loss: 2.3907 - val_accuracy: 0.2188\n",
            "Epoch 218/500\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 1.1688 - accuracy: 0.8938 - val_loss: 2.3900 - val_accuracy: 0.2812\n",
            "Epoch 219/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 1.0741 - accuracy: 0.9292 - val_loss: 2.4768 - val_accuracy: 0.2656\n",
            "Epoch 220/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 1.0260 - accuracy: 0.9336 - val_loss: 2.3299 - val_accuracy: 0.2500\n",
            "Epoch 221/500\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 0.9361 - accuracy: 0.9550\n",
            " pruning [ = = = = ]\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.9327 - accuracy: 0.9602 - val_loss: 2.3473 - val_accuracy: 0.2188\n",
            "Epoch 222/500\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 1.5811 - accuracy: 0.7434 - val_loss: 2.5150 - val_accuracy: 0.1875\n",
            "Epoch 223/500\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 1.3951 - accuracy: 0.8009 - val_loss: 2.4700 - val_accuracy: 0.2656\n",
            "Epoch 224/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 1.3161 - accuracy: 0.8540 - val_loss: 2.6017 - val_accuracy: 0.1562\n",
            "Epoch 225/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 1.2381 - accuracy: 0.8717 - val_loss: 2.3102 - val_accuracy: 0.2656\n",
            "Epoch 226/500\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 1.1506 - accuracy: 0.9000\n",
            " pruning [ = = = = ]\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 1.1633 - accuracy: 0.8982 - val_loss: 2.4873 - val_accuracy: 0.2031\n",
            "Epoch 227/500\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 1.5510 - accuracy: 0.7035 - val_loss: 2.4616 - val_accuracy: 0.2500\n",
            "Epoch 228/500\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 1.4867 - accuracy: 0.7522 - val_loss: 2.5266 - val_accuracy: 0.2344\n",
            "Epoch 229/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 1.2941 - accuracy: 0.8407 - val_loss: 2.4427 - val_accuracy: 0.2656\n",
            "Epoch 230/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 1.2653 - accuracy: 0.8274 - val_loss: 2.5989 - val_accuracy: 0.1562\n",
            "Epoch 231/500\n",
            "5/5 [==============================] - ETA: 0s - loss: 1.1819 - accuracy: 0.8584\n",
            " pruning [ = = = = ]\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 1.1819 - accuracy: 0.8584 - val_loss: 2.4348 - val_accuracy: 0.2344\n",
            "Epoch 232/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 1.7834 - accuracy: 0.5973 - val_loss: 2.6526 - val_accuracy: 0.1406\n",
            "Epoch 233/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 1.6051 - accuracy: 0.7655 - val_loss: 2.6654 - val_accuracy: 0.1406\n",
            "Epoch 234/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 1.5361 - accuracy: 0.7832 - val_loss: 2.5656 - val_accuracy: 0.2344\n",
            "Epoch 235/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 1.4933 - accuracy: 0.8274 - val_loss: 2.6253 - val_accuracy: 0.1250\n",
            "Epoch 236/500\n",
            "5/5 [==============================] - ETA: 0s - loss: 1.4373 - accuracy: 0.8230\n",
            " pruning [ = = = = ]\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 1.4373 - accuracy: 0.8230 - val_loss: 2.6162 - val_accuracy: 0.1406\n",
            "Epoch 237/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 1.6505 - accuracy: 0.7655 - val_loss: 2.5962 - val_accuracy: 0.1406\n",
            "Epoch 238/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 1.5716 - accuracy: 0.7611 - val_loss: 2.6548 - val_accuracy: 0.0938\n",
            "Epoch 239/500\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 1.5604 - accuracy: 0.7788 - val_loss: 2.5450 - val_accuracy: 0.1875\n",
            "Epoch 240/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 1.4643 - accuracy: 0.8319 - val_loss: 2.5939 - val_accuracy: 0.1406\n",
            "Epoch 241/500\n",
            "5/5 [==============================] - ETA: 0s - loss: 1.3951 - accuracy: 0.8628\n",
            " pruning [ = = = = ]\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 1.3951 - accuracy: 0.8628 - val_loss: 2.6801 - val_accuracy: 0.1406\n",
            "Epoch 242/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 1.9367 - accuracy: 0.5973 - val_loss: 2.5529 - val_accuracy: 0.1406\n",
            "Epoch 243/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 1.8328 - accuracy: 0.6814 - val_loss: 2.6162 - val_accuracy: 0.1406\n",
            "Epoch 244/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 1.7658 - accuracy: 0.6814 - val_loss: 2.6402 - val_accuracy: 0.1562\n",
            "Epoch 245/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 1.6732 - accuracy: 0.7478 - val_loss: 2.5686 - val_accuracy: 0.1562\n",
            "Epoch 246/500\n",
            "5/5 [==============================] - ETA: 0s - loss: 1.6382 - accuracy: 0.7301\n",
            " pruning [ = = = = ]\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 1.6382 - accuracy: 0.7301 - val_loss: 2.4549 - val_accuracy: 0.2188\n",
            "Epoch 247/500\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 2.1822 - accuracy: 0.3805 - val_loss: 2.5985 - val_accuracy: 0.1406\n",
            "Epoch 248/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 2.0348 - accuracy: 0.4779 - val_loss: 2.5842 - val_accuracy: 0.1719\n",
            "Epoch 249/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 1.9606 - accuracy: 0.5752 - val_loss: 2.6541 - val_accuracy: 0.1875\n",
            "Epoch 250/500\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 1.8882 - accuracy: 0.6018 - val_loss: 2.6456 - val_accuracy: 0.2031\n",
            "Epoch 251/500\n",
            "5/5 [==============================] - ETA: 0s - loss: 1.8319 - accuracy: 0.6504\n",
            " pruning [ = = = = ]\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 1.8319 - accuracy: 0.6504 - val_loss: 2.6183 - val_accuracy: 0.1562\n",
            "Epoch 252/500\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 2.2172 - accuracy: 0.4115 - val_loss: 2.5237 - val_accuracy: 0.1875\n",
            "Epoch 253/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 2.1163 - accuracy: 0.4469 - val_loss: 2.5095 - val_accuracy: 0.1719\n",
            "Epoch 254/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 2.0387 - accuracy: 0.5531 - val_loss: 2.5460 - val_accuracy: 0.1406\n",
            "Epoch 255/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 2.0345 - accuracy: 0.5442 - val_loss: 2.5218 - val_accuracy: 0.1719\n",
            "Epoch 256/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 1.9756 - accuracy: 0.5708 - val_loss: 2.5284 - val_accuracy: 0.1562\n",
            "Epoch 257/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 1.9305 - accuracy: 0.6018 - val_loss: 2.5558 - val_accuracy: 0.1875\n",
            "Epoch 258/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 1.8798 - accuracy: 0.6460 - val_loss: 2.5857 - val_accuracy: 0.1562\n",
            "Epoch 259/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 1.8921 - accuracy: 0.6195 - val_loss: 2.5531 - val_accuracy: 0.1562\n",
            "Epoch 260/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 1.8611 - accuracy: 0.6195 - val_loss: 2.4931 - val_accuracy: 0.1562\n",
            "Epoch 261/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 1.7975 - accuracy: 0.6903 - val_loss: 2.5231 - val_accuracy: 0.1875\n",
            "Epoch 262/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 1.7977 - accuracy: 0.6991 - val_loss: 2.5191 - val_accuracy: 0.1562\n",
            "Epoch 263/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 1.7381 - accuracy: 0.7080 - val_loss: 2.5436 - val_accuracy: 0.1719\n",
            "Epoch 264/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 1.7521 - accuracy: 0.7035 - val_loss: 2.5378 - val_accuracy: 0.2031\n",
            "Epoch 265/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 1.7169 - accuracy: 0.7124 - val_loss: 2.5289 - val_accuracy: 0.1719\n",
            "Epoch 266/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 1.7345 - accuracy: 0.6770 - val_loss: 2.4925 - val_accuracy: 0.1250\n",
            "Epoch 267/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 1.6947 - accuracy: 0.6726 - val_loss: 2.5465 - val_accuracy: 0.1719\n",
            "Epoch 268/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 1.6716 - accuracy: 0.7168 - val_loss: 2.5131 - val_accuracy: 0.2031\n",
            "Epoch 269/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 1.6115 - accuracy: 0.7743 - val_loss: 2.5033 - val_accuracy: 0.1719\n",
            "Epoch 270/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 1.5983 - accuracy: 0.7345 - val_loss: 2.5451 - val_accuracy: 0.1406\n",
            "Epoch 271/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 1.5704 - accuracy: 0.7655 - val_loss: 2.5988 - val_accuracy: 0.1562\n",
            "Epoch 272/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 1.5897 - accuracy: 0.7212 - val_loss: 2.4860 - val_accuracy: 0.1875\n",
            "Epoch 273/500\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 1.5504 - accuracy: 0.7611 - val_loss: 2.5431 - val_accuracy: 0.1406\n",
            "Epoch 274/500\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 1.5554 - accuracy: 0.7522 - val_loss: 2.7530 - val_accuracy: 0.1094\n",
            "Epoch 275/500\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 1.4988 - accuracy: 0.7699 - val_loss: 2.6186 - val_accuracy: 0.1250\n",
            "Epoch 276/500\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 1.5353 - accuracy: 0.7566 - val_loss: 2.4517 - val_accuracy: 0.1875\n",
            "Epoch 277/500\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 1.4882 - accuracy: 0.7566 - val_loss: 2.5194 - val_accuracy: 0.1250\n",
            "Epoch 278/500\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 1.3912 - accuracy: 0.8009 - val_loss: 2.6395 - val_accuracy: 0.1562\n",
            "Epoch 279/500\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 1.4438 - accuracy: 0.7743 - val_loss: 2.5595 - val_accuracy: 0.1562\n",
            "Epoch 280/500\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 1.3665 - accuracy: 0.8009 - val_loss: 2.4571 - val_accuracy: 0.1719\n",
            "Epoch 281/500\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 1.4373 - accuracy: 0.7611 - val_loss: 2.5545 - val_accuracy: 0.1094\n",
            "Epoch 282/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 1.4434 - accuracy: 0.7566 - val_loss: 2.5176 - val_accuracy: 0.1719\n",
            "Epoch 283/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 1.4003 - accuracy: 0.7788 - val_loss: 2.6808 - val_accuracy: 0.1094\n",
            "Epoch 284/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 1.3285 - accuracy: 0.8053 - val_loss: 2.4742 - val_accuracy: 0.1406\n",
            "Epoch 285/500\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 1.3147 - accuracy: 0.8142 - val_loss: 2.4513 - val_accuracy: 0.2031\n",
            "Epoch 286/500\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 1.2662 - accuracy: 0.8186 - val_loss: 2.5091 - val_accuracy: 0.1562\n",
            "Epoch 287/500\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 1.2771 - accuracy: 0.8097 - val_loss: 2.5450 - val_accuracy: 0.0938\n",
            "Epoch 288/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 1.2507 - accuracy: 0.8540 - val_loss: 2.6521 - val_accuracy: 0.0781\n",
            "Epoch 289/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 1.1737 - accuracy: 0.8496 - val_loss: 2.5847 - val_accuracy: 0.1562\n",
            "Epoch 290/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 1.2522 - accuracy: 0.8009 - val_loss: 2.4713 - val_accuracy: 0.1562\n",
            "Epoch 291/500\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 1.1378 - accuracy: 0.8584 - val_loss: 2.7896 - val_accuracy: 0.1094\n",
            "Epoch 292/500\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 1.1402 - accuracy: 0.8761 - val_loss: 2.5464 - val_accuracy: 0.0938\n",
            "Epoch 293/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 1.1458 - accuracy: 0.8584 - val_loss: 2.6148 - val_accuracy: 0.1562\n",
            "Epoch 294/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 1.1373 - accuracy: 0.8496 - val_loss: 2.4534 - val_accuracy: 0.1719\n",
            "Epoch 295/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 1.0727 - accuracy: 0.8717 - val_loss: 2.4864 - val_accuracy: 0.1875\n",
            "Epoch 296/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 1.0847 - accuracy: 0.8496 - val_loss: 2.5254 - val_accuracy: 0.1562\n",
            "Epoch 297/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 1.1435 - accuracy: 0.8319 - val_loss: 2.5991 - val_accuracy: 0.2031\n",
            "Epoch 298/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 1.0251 - accuracy: 0.8584 - val_loss: 2.5606 - val_accuracy: 0.1406\n",
            "Epoch 299/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 1.0013 - accuracy: 0.8761 - val_loss: 2.6119 - val_accuracy: 0.2188\n",
            "Epoch 300/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 1.0390 - accuracy: 0.8805 - val_loss: 2.5110 - val_accuracy: 0.1875\n",
            "Epoch 301/500\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 1.0182 - accuracy: 0.8628 - val_loss: 2.8231 - val_accuracy: 0.1094\n",
            "Epoch 302/500\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 1.0490 - accuracy: 0.8407 - val_loss: 2.5593 - val_accuracy: 0.2031\n",
            "Epoch 303/500\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 0.9114 - accuracy: 0.8805 - val_loss: 2.6109 - val_accuracy: 0.1250\n",
            "Epoch 304/500\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.9702 - accuracy: 0.8540 - val_loss: 2.8285 - val_accuracy: 0.1250\n",
            "Epoch 305/500\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.9822 - accuracy: 0.8673 - val_loss: 2.5973 - val_accuracy: 0.1562\n",
            "Epoch 306/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.9259 - accuracy: 0.8850 - val_loss: 2.5605 - val_accuracy: 0.1719\n",
            "Epoch 307/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.8898 - accuracy: 0.8982 - val_loss: 2.4643 - val_accuracy: 0.1406\n",
            "Epoch 308/500\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.8978 - accuracy: 0.8717 - val_loss: 2.6506 - val_accuracy: 0.1719\n",
            "Epoch 309/500\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.8968 - accuracy: 0.8850 - val_loss: 2.6573 - val_accuracy: 0.1250\n",
            "Epoch 310/500\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 0.8016 - accuracy: 0.9071 - val_loss: 2.4649 - val_accuracy: 0.2031\n",
            "Epoch 311/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.7630 - accuracy: 0.9159 - val_loss: 2.6019 - val_accuracy: 0.0781\n",
            "Epoch 312/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.8252 - accuracy: 0.9159 - val_loss: 2.4716 - val_accuracy: 0.1875\n",
            "Epoch 313/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.7460 - accuracy: 0.9248 - val_loss: 2.5351 - val_accuracy: 0.1562\n",
            "Epoch 314/500\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.7659 - accuracy: 0.9425 - val_loss: 2.5276 - val_accuracy: 0.1875\n",
            "Epoch 315/500\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.6965 - accuracy: 0.9292 - val_loss: 2.9286 - val_accuracy: 0.1094\n",
            "Epoch 316/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.8127 - accuracy: 0.8938 - val_loss: 2.5264 - val_accuracy: 0.1875\n",
            "Epoch 317/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.6655 - accuracy: 0.9425 - val_loss: 2.5471 - val_accuracy: 0.1875\n",
            "Epoch 318/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.6899 - accuracy: 0.9336 - val_loss: 2.5980 - val_accuracy: 0.1562\n",
            "Epoch 319/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.6796 - accuracy: 0.9381 - val_loss: 2.6996 - val_accuracy: 0.2031\n",
            "Epoch 320/500\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.6689 - accuracy: 0.9381 - val_loss: 2.5938 - val_accuracy: 0.1406\n",
            "Epoch 321/500\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 0.6709 - accuracy: 0.9248 - val_loss: 2.6145 - val_accuracy: 0.1406\n",
            "Epoch 322/500\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 0.6145 - accuracy: 0.9558 - val_loss: 2.6254 - val_accuracy: 0.1250\n",
            "Epoch 323/500\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.5808 - accuracy: 0.9469 - val_loss: 2.6252 - val_accuracy: 0.1094\n",
            "Epoch 324/500\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.6580 - accuracy: 0.9381 - val_loss: 2.6425 - val_accuracy: 0.1250\n",
            "Epoch 325/500\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 0.6363 - accuracy: 0.9336 - val_loss: 2.5625 - val_accuracy: 0.1875\n",
            "Epoch 326/500\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.5844 - accuracy: 0.9558 - val_loss: 2.8201 - val_accuracy: 0.1406\n",
            "Epoch 327/500\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 0.5589 - accuracy: 0.9469 - val_loss: 2.4635 - val_accuracy: 0.1406\n",
            "Epoch 328/500\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.5529 - accuracy: 0.9690 - val_loss: 2.6394 - val_accuracy: 0.1562\n",
            "Epoch 329/500\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 0.5714 - accuracy: 0.9602 - val_loss: 2.9831 - val_accuracy: 0.1406\n",
            "Epoch 330/500\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 0.5845 - accuracy: 0.9558 - val_loss: 2.6639 - val_accuracy: 0.1562\n",
            "Epoch 331/500\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 0.5535 - accuracy: 0.9690 - val_loss: 2.6130 - val_accuracy: 0.1094\n",
            "Epoch 332/500\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 0.5131 - accuracy: 0.9779 - val_loss: 2.7942 - val_accuracy: 0.0781\n",
            "Epoch 333/500\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 0.6661 - accuracy: 0.9204 - val_loss: 2.6473 - val_accuracy: 0.1562\n",
            "Epoch 334/500\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 0.4919 - accuracy: 0.9558 - val_loss: 2.6815 - val_accuracy: 0.1406\n",
            "Epoch 335/500\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.4589 - accuracy: 0.9602 - val_loss: 2.7256 - val_accuracy: 0.1406\n",
            "Epoch 336/500\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.4954 - accuracy: 0.9558 - val_loss: 2.6178 - val_accuracy: 0.1406\n",
            "Epoch 337/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.4446 - accuracy: 0.9823 - val_loss: 2.6532 - val_accuracy: 0.1562\n",
            "Epoch 338/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.4918 - accuracy: 0.9646 - val_loss: 2.7595 - val_accuracy: 0.1875\n",
            "Epoch 339/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.4396 - accuracy: 0.9823 - val_loss: 2.7749 - val_accuracy: 0.1250\n",
            "Epoch 340/500\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.4052 - accuracy: 0.9912 - val_loss: 2.8729 - val_accuracy: 0.0781\n",
            "Epoch 341/500\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.4297 - accuracy: 0.9735 - val_loss: 2.7222 - val_accuracy: 0.1406\n",
            "Epoch 342/500\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.4085 - accuracy: 0.9823 - val_loss: 2.8290 - val_accuracy: 0.1250\n",
            "Epoch 343/500\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 0.4984 - accuracy: 0.9690 - val_loss: 2.6425 - val_accuracy: 0.0938\n",
            "Epoch 344/500\n",
            "5/5 [==============================] - 0s 46ms/step - loss: 0.4722 - accuracy: 0.9646 - val_loss: 2.8439 - val_accuracy: 0.1250\n",
            "Epoch 345/500\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.3650 - accuracy: 0.9823 - val_loss: 2.7486 - val_accuracy: 0.1094\n",
            "Epoch 346/500\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.3649 - accuracy: 0.9912 - val_loss: 2.8536 - val_accuracy: 0.0938\n",
            "Epoch 347/500\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.3774 - accuracy: 0.9867 - val_loss: 2.6902 - val_accuracy: 0.0625\n",
            "Epoch 348/500\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 0.3707 - accuracy: 0.9956 - val_loss: 2.8287 - val_accuracy: 0.1094\n",
            "Epoch 349/500\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.3266 - accuracy: 0.9956 - val_loss: 2.6683 - val_accuracy: 0.0938\n",
            "Epoch 350/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.3170 - accuracy: 0.9867 - val_loss: 2.7122 - val_accuracy: 0.1250\n",
            "Epoch 351/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.3539 - accuracy: 0.9912 - val_loss: 2.9153 - val_accuracy: 0.0781\n",
            "Epoch 352/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.3789 - accuracy: 0.9867 - val_loss: 2.6990 - val_accuracy: 0.1406\n",
            "Epoch 353/500\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.3121 - accuracy: 0.9912 - val_loss: 2.8184 - val_accuracy: 0.1094\n",
            "Epoch 354/500\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.2854 - accuracy: 0.9956 - val_loss: 2.7323 - val_accuracy: 0.0938\n",
            "Epoch 355/500\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.3666 - accuracy: 0.9912 - val_loss: 2.8372 - val_accuracy: 0.1562\n",
            "Epoch 356/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.3218 - accuracy: 0.9867 - val_loss: 2.6872 - val_accuracy: 0.0781\n",
            "Epoch 357/500\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.2899 - accuracy: 0.9956 - val_loss: 2.8266 - val_accuracy: 0.0938\n",
            "Epoch 358/500\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 0.3362 - accuracy: 0.9867 - val_loss: 2.8044 - val_accuracy: 0.1094\n",
            "Epoch 359/500\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 0.2613 - accuracy: 0.9956 - val_loss: 2.8514 - val_accuracy: 0.0938\n",
            "Epoch 360/500\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.2776 - accuracy: 0.9823 - val_loss: 2.9165 - val_accuracy: 0.0781\n",
            "Epoch 361/500\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.3858 - accuracy: 0.9735 - val_loss: 2.6975 - val_accuracy: 0.1406\n",
            "Epoch 362/500\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.2637 - accuracy: 0.9956 - val_loss: 2.8271 - val_accuracy: 0.1562\n",
            "Epoch 363/500\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 0.2628 - accuracy: 0.9912 - val_loss: 2.9069 - val_accuracy: 0.1250\n",
            "Epoch 364/500\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.2564 - accuracy: 1.0000 - val_loss: 2.7440 - val_accuracy: 0.1094\n",
            "Epoch 365/500\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.2310 - accuracy: 0.9956 - val_loss: 2.7775 - val_accuracy: 0.1094\n",
            "Epoch 366/500\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.2283 - accuracy: 0.9956 - val_loss: 2.8215 - val_accuracy: 0.1094\n",
            "Epoch 367/500\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.2306 - accuracy: 0.9956 - val_loss: 3.2414 - val_accuracy: 0.0625\n",
            "Epoch 368/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.2265 - accuracy: 1.0000 - val_loss: 2.8619 - val_accuracy: 0.1094\n",
            "Epoch 369/500\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.2148 - accuracy: 1.0000 - val_loss: 2.7918 - val_accuracy: 0.0938\n",
            "Epoch 370/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.2155 - accuracy: 0.9956 - val_loss: 2.7000 - val_accuracy: 0.1406\n",
            "Epoch 371/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.2133 - accuracy: 0.9956 - val_loss: 2.7371 - val_accuracy: 0.0938\n",
            "Epoch 372/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.2062 - accuracy: 0.9956 - val_loss: 2.8762 - val_accuracy: 0.0938\n",
            "Epoch 373/500\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.2106 - accuracy: 0.9956 - val_loss: 3.0085 - val_accuracy: 0.1250\n",
            "Epoch 374/500\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.2187 - accuracy: 0.9956 - val_loss: 2.7975 - val_accuracy: 0.0938\n",
            "Epoch 375/500\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 0.2050 - accuracy: 0.9956 - val_loss: 2.7733 - val_accuracy: 0.1250\n",
            "Epoch 376/500\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.1940 - accuracy: 0.9956 - val_loss: 2.7825 - val_accuracy: 0.1094\n",
            "Epoch 377/500\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.1862 - accuracy: 0.9956 - val_loss: 2.8763 - val_accuracy: 0.1250\n",
            "Epoch 378/500\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.1851 - accuracy: 1.0000 - val_loss: 2.8066 - val_accuracy: 0.1406\n",
            "Epoch 379/500\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.1878 - accuracy: 0.9956 - val_loss: 2.9451 - val_accuracy: 0.0781\n",
            "Epoch 380/500\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 0.1690 - accuracy: 0.9956 - val_loss: 2.7909 - val_accuracy: 0.1094\n",
            "Epoch 381/500\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.1734 - accuracy: 0.9956 - val_loss: 2.8857 - val_accuracy: 0.1250\n",
            "Epoch 382/500\n",
            "5/5 [==============================] - 0s 45ms/step - loss: 0.1756 - accuracy: 1.0000 - val_loss: 2.9413 - val_accuracy: 0.1094\n",
            "Epoch 383/500\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.1667 - accuracy: 1.0000 - val_loss: 2.8991 - val_accuracy: 0.1406\n",
            "Epoch 384/500\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.1620 - accuracy: 1.0000 - val_loss: 2.8377 - val_accuracy: 0.1250\n",
            "Epoch 385/500\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.1584 - accuracy: 1.0000 - val_loss: 2.7380 - val_accuracy: 0.1094\n",
            "Epoch 386/500\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.1640 - accuracy: 1.0000 - val_loss: 3.0268 - val_accuracy: 0.0938\n",
            "Epoch 387/500\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.1615 - accuracy: 0.9956 - val_loss: 2.8103 - val_accuracy: 0.1094\n",
            "Epoch 388/500\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.1475 - accuracy: 1.0000 - val_loss: 2.9555 - val_accuracy: 0.1094\n",
            "Epoch 389/500\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 0.1503 - accuracy: 1.0000 - val_loss: 2.9762 - val_accuracy: 0.1562\n",
            "Epoch 390/500\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 0.1830 - accuracy: 0.9956 - val_loss: 2.8363 - val_accuracy: 0.1094\n",
            "Epoch 391/500\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 0.1517 - accuracy: 1.0000 - val_loss: 2.8201 - val_accuracy: 0.1250\n",
            "Epoch 392/500\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 0.1447 - accuracy: 0.9956 - val_loss: 2.8853 - val_accuracy: 0.1094\n",
            "Epoch 393/500\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.1378 - accuracy: 1.0000 - val_loss: 2.9373 - val_accuracy: 0.1250\n",
            "Epoch 394/500\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 0.1398 - accuracy: 0.9956 - val_loss: 2.8199 - val_accuracy: 0.0938\n",
            "Epoch 395/500\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.1301 - accuracy: 1.0000 - val_loss: 2.8701 - val_accuracy: 0.0938\n",
            "Epoch 396/500\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.1396 - accuracy: 0.9956 - val_loss: 2.9637 - val_accuracy: 0.0938\n",
            "Epoch 397/500\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.1414 - accuracy: 0.9956 - val_loss: 2.8724 - val_accuracy: 0.1250\n",
            "Epoch 398/500\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.1265 - accuracy: 1.0000 - val_loss: 2.8161 - val_accuracy: 0.0938\n",
            "Epoch 399/500\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.1332 - accuracy: 1.0000 - val_loss: 2.8028 - val_accuracy: 0.1094\n",
            "Epoch 400/500\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.1324 - accuracy: 1.0000 - val_loss: 2.8315 - val_accuracy: 0.0781\n",
            "Epoch 401/500\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.1271 - accuracy: 1.0000 - val_loss: 2.9981 - val_accuracy: 0.1094\n",
            "Epoch 402/500\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 0.1227 - accuracy: 1.0000 - val_loss: 2.8027 - val_accuracy: 0.0938\n",
            "Epoch 403/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.1254 - accuracy: 1.0000 - val_loss: 2.8964 - val_accuracy: 0.0938\n",
            "Epoch 404/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.1139 - accuracy: 1.0000 - val_loss: 2.8523 - val_accuracy: 0.1094\n",
            "Epoch 405/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.1150 - accuracy: 1.0000 - val_loss: 2.9706 - val_accuracy: 0.0938\n",
            "Epoch 406/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.1159 - accuracy: 1.0000 - val_loss: 2.7948 - val_accuracy: 0.0938\n",
            "Epoch 407/500\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.1214 - accuracy: 1.0000 - val_loss: 2.9195 - val_accuracy: 0.0781\n",
            "Epoch 408/500\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 0.1122 - accuracy: 1.0000 - val_loss: 2.9143 - val_accuracy: 0.0938\n",
            "Epoch 409/500\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.1116 - accuracy: 1.0000 - val_loss: 2.9657 - val_accuracy: 0.1094\n",
            "Epoch 410/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.1110 - accuracy: 1.0000 - val_loss: 3.0162 - val_accuracy: 0.1250\n",
            "Epoch 411/500\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.1071 - accuracy: 1.0000 - val_loss: 2.9469 - val_accuracy: 0.0938\n",
            "Epoch 412/500\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.1111 - accuracy: 1.0000 - val_loss: 2.8945 - val_accuracy: 0.0938\n",
            "Epoch 413/500\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.1050 - accuracy: 1.0000 - val_loss: 2.9294 - val_accuracy: 0.0781\n",
            "Epoch 414/500\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.1089 - accuracy: 1.0000 - val_loss: 3.0308 - val_accuracy: 0.1094\n",
            "Epoch 415/500\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.1016 - accuracy: 1.0000 - val_loss: 2.9750 - val_accuracy: 0.1094\n",
            "Epoch 416/500\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 0.1090 - accuracy: 1.0000 - val_loss: 3.0453 - val_accuracy: 0.1406\n",
            "Epoch 417/500\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.0984 - accuracy: 1.0000 - val_loss: 2.9749 - val_accuracy: 0.0938\n",
            "Epoch 418/500\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.0981 - accuracy: 1.0000 - val_loss: 2.9413 - val_accuracy: 0.0938\n",
            "Epoch 419/500\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.0998 - accuracy: 1.0000 - val_loss: 3.0317 - val_accuracy: 0.1094\n",
            "Epoch 420/500\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 0.0943 - accuracy: 1.0000 - val_loss: 3.1900 - val_accuracy: 0.1094\n",
            "Epoch 421/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.1000 - accuracy: 1.0000 - val_loss: 2.9710 - val_accuracy: 0.0938\n",
            "Epoch 422/500\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.0966 - accuracy: 1.0000 - val_loss: 2.9520 - val_accuracy: 0.1406\n",
            "Epoch 423/500\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.1094 - accuracy: 1.0000 - val_loss: 2.9280 - val_accuracy: 0.1094\n",
            "Epoch 424/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.0934 - accuracy: 1.0000 - val_loss: 3.0966 - val_accuracy: 0.0781\n",
            "Epoch 425/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.0946 - accuracy: 1.0000 - val_loss: 2.8792 - val_accuracy: 0.1094\n",
            "Epoch 426/500\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.0897 - accuracy: 1.0000 - val_loss: 2.9215 - val_accuracy: 0.1094\n",
            "Epoch 427/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.0890 - accuracy: 1.0000 - val_loss: 2.9471 - val_accuracy: 0.1094\n",
            "Epoch 428/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.0891 - accuracy: 1.0000 - val_loss: 2.9355 - val_accuracy: 0.0938\n",
            "Epoch 429/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.0873 - accuracy: 1.0000 - val_loss: 2.9857 - val_accuracy: 0.1094\n",
            "Epoch 430/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.0852 - accuracy: 1.0000 - val_loss: 3.0249 - val_accuracy: 0.1094\n",
            "Epoch 431/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.0856 - accuracy: 1.0000 - val_loss: 2.9306 - val_accuracy: 0.0938\n",
            "Epoch 432/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.0809 - accuracy: 1.0000 - val_loss: 2.9015 - val_accuracy: 0.1094\n",
            "Epoch 433/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.0800 - accuracy: 1.0000 - val_loss: 2.8805 - val_accuracy: 0.0938\n",
            "Epoch 434/500\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.0790 - accuracy: 1.0000 - val_loss: 3.0021 - val_accuracy: 0.0938\n",
            "Epoch 435/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.0809 - accuracy: 1.0000 - val_loss: 2.9376 - val_accuracy: 0.0938\n",
            "Epoch 436/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.0767 - accuracy: 1.0000 - val_loss: 2.9998 - val_accuracy: 0.1094\n",
            "Epoch 437/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.0774 - accuracy: 1.0000 - val_loss: 2.9515 - val_accuracy: 0.1094\n",
            "Epoch 438/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.0809 - accuracy: 1.0000 - val_loss: 2.9223 - val_accuracy: 0.1094\n",
            "Epoch 439/500\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.0759 - accuracy: 1.0000 - val_loss: 2.9157 - val_accuracy: 0.0938\n",
            "Epoch 440/500\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.0759 - accuracy: 1.0000 - val_loss: 2.9536 - val_accuracy: 0.0938\n",
            "Epoch 441/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.0747 - accuracy: 1.0000 - val_loss: 2.9050 - val_accuracy: 0.0938\n",
            "Epoch 442/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.0727 - accuracy: 1.0000 - val_loss: 2.9671 - val_accuracy: 0.1094\n",
            "Epoch 443/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.0736 - accuracy: 1.0000 - val_loss: 3.0284 - val_accuracy: 0.0938\n",
            "Epoch 444/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.0776 - accuracy: 1.0000 - val_loss: 3.1274 - val_accuracy: 0.0938\n",
            "Epoch 445/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.0744 - accuracy: 1.0000 - val_loss: 2.8834 - val_accuracy: 0.1094\n",
            "Epoch 446/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.0740 - accuracy: 1.0000 - val_loss: 2.9665 - val_accuracy: 0.0938\n",
            "Epoch 447/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.0724 - accuracy: 1.0000 - val_loss: 2.9920 - val_accuracy: 0.0938\n",
            "Epoch 448/500\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.0715 - accuracy: 1.0000 - val_loss: 3.0062 - val_accuracy: 0.0938\n",
            "Epoch 449/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.0678 - accuracy: 1.0000 - val_loss: 3.0116 - val_accuracy: 0.1250\n",
            "Epoch 450/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.0664 - accuracy: 1.0000 - val_loss: 3.0267 - val_accuracy: 0.0938\n",
            "Epoch 451/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.0661 - accuracy: 1.0000 - val_loss: 2.9937 - val_accuracy: 0.1094\n",
            "Epoch 452/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.0647 - accuracy: 1.0000 - val_loss: 3.0179 - val_accuracy: 0.0938\n",
            "Epoch 453/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.0647 - accuracy: 1.0000 - val_loss: 3.0492 - val_accuracy: 0.0938\n",
            "Epoch 454/500\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.0676 - accuracy: 1.0000 - val_loss: 3.0212 - val_accuracy: 0.0938\n",
            "Epoch 455/500\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.0659 - accuracy: 1.0000 - val_loss: 3.0588 - val_accuracy: 0.0938\n",
            "Epoch 456/500\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.0647 - accuracy: 1.0000 - val_loss: 2.9982 - val_accuracy: 0.0938\n",
            "Epoch 457/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.0639 - accuracy: 1.0000 - val_loss: 3.0365 - val_accuracy: 0.1094\n",
            "Epoch 458/500\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.0622 - accuracy: 1.0000 - val_loss: 2.9999 - val_accuracy: 0.1094\n",
            "Epoch 459/500\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 0.0636 - accuracy: 1.0000 - val_loss: 2.9950 - val_accuracy: 0.0938\n",
            "Epoch 460/500\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 0.0593 - accuracy: 1.0000 - val_loss: 3.0143 - val_accuracy: 0.0938\n",
            "Epoch 461/500\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.0597 - accuracy: 1.0000 - val_loss: 3.1242 - val_accuracy: 0.1094\n",
            "Epoch 462/500\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.0607 - accuracy: 1.0000 - val_loss: 3.0869 - val_accuracy: 0.1250\n",
            "Epoch 463/500\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.0618 - accuracy: 1.0000 - val_loss: 3.0037 - val_accuracy: 0.0938\n",
            "Epoch 464/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.0562 - accuracy: 1.0000 - val_loss: 2.9874 - val_accuracy: 0.0938\n",
            "Epoch 465/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.0598 - accuracy: 1.0000 - val_loss: 3.0326 - val_accuracy: 0.1094\n",
            "Epoch 466/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.0578 - accuracy: 1.0000 - val_loss: 3.1209 - val_accuracy: 0.0938\n",
            "Epoch 467/500\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.0608 - accuracy: 1.0000 - val_loss: 3.0147 - val_accuracy: 0.1250\n",
            "Epoch 468/500\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 0.0562 - accuracy: 1.0000 - val_loss: 3.0147 - val_accuracy: 0.0938\n",
            "Epoch 469/500\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.0584 - accuracy: 1.0000 - val_loss: 3.0943 - val_accuracy: 0.0938\n",
            "Epoch 470/500\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 0.0594 - accuracy: 1.0000 - val_loss: 2.8883 - val_accuracy: 0.1094\n",
            "Epoch 471/500\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.0623 - accuracy: 1.0000 - val_loss: 3.0302 - val_accuracy: 0.1094\n",
            "Epoch 472/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.0552 - accuracy: 1.0000 - val_loss: 2.9996 - val_accuracy: 0.1094\n",
            "Epoch 473/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.0549 - accuracy: 1.0000 - val_loss: 3.0936 - val_accuracy: 0.0938\n",
            "Epoch 474/500\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.0532 - accuracy: 1.0000 - val_loss: 2.9749 - val_accuracy: 0.0938\n",
            "Epoch 475/500\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.0584 - accuracy: 1.0000 - val_loss: 3.0906 - val_accuracy: 0.1094\n",
            "Epoch 476/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.0543 - accuracy: 1.0000 - val_loss: 3.1321 - val_accuracy: 0.1094\n",
            "Epoch 477/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.0534 - accuracy: 1.0000 - val_loss: 3.0743 - val_accuracy: 0.1094\n",
            "Epoch 478/500\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.0545 - accuracy: 1.0000 - val_loss: 3.0165 - val_accuracy: 0.0938\n",
            "Epoch 479/500\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.0562 - accuracy: 1.0000 - val_loss: 3.0690 - val_accuracy: 0.1094\n",
            "Epoch 480/500\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.0507 - accuracy: 1.0000 - val_loss: 3.1360 - val_accuracy: 0.1250\n",
            "Epoch 481/500\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.0490 - accuracy: 1.0000 - val_loss: 3.0562 - val_accuracy: 0.1094\n",
            "Epoch 482/500\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.0520 - accuracy: 1.0000 - val_loss: 3.1289 - val_accuracy: 0.1094\n",
            "Epoch 483/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.0524 - accuracy: 1.0000 - val_loss: 2.9955 - val_accuracy: 0.1094\n",
            "Epoch 484/500\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.0531 - accuracy: 1.0000 - val_loss: 3.1353 - val_accuracy: 0.0938\n",
            "Epoch 485/500\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.0521 - accuracy: 1.0000 - val_loss: 3.0439 - val_accuracy: 0.1094\n",
            "Epoch 486/500\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 0.0487 - accuracy: 1.0000 - val_loss: 3.0563 - val_accuracy: 0.0938\n",
            "Epoch 487/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.0514 - accuracy: 1.0000 - val_loss: 3.0390 - val_accuracy: 0.1094\n",
            "Epoch 488/500\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 0.0506 - accuracy: 1.0000 - val_loss: 3.0603 - val_accuracy: 0.0938\n",
            "Epoch 489/500\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.0484 - accuracy: 1.0000 - val_loss: 3.1026 - val_accuracy: 0.1094\n",
            "Epoch 490/500\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.0494 - accuracy: 1.0000 - val_loss: 3.0703 - val_accuracy: 0.1094\n",
            "Epoch 491/500\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.0459 - accuracy: 1.0000 - val_loss: 3.0203 - val_accuracy: 0.0938\n",
            "Epoch 492/500\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.0467 - accuracy: 1.0000 - val_loss: 3.1481 - val_accuracy: 0.1094\n",
            "Epoch 493/500\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.0458 - accuracy: 1.0000 - val_loss: 3.0804 - val_accuracy: 0.1094\n",
            "Epoch 494/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.0460 - accuracy: 1.0000 - val_loss: 3.1134 - val_accuracy: 0.1094\n",
            "Epoch 495/500\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.0453 - accuracy: 1.0000 - val_loss: 3.1357 - val_accuracy: 0.1094\n",
            "Epoch 496/500\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.0474 - accuracy: 1.0000 - val_loss: 3.1579 - val_accuracy: 0.0938\n",
            "Epoch 497/500\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 0.0455 - accuracy: 1.0000 - val_loss: 3.0638 - val_accuracy: 0.1094\n",
            "Epoch 498/500\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.0425 - accuracy: 1.0000 - val_loss: 3.0397 - val_accuracy: 0.1250\n",
            "Epoch 499/500\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 0.0428 - accuracy: 1.0000 - val_loss: 3.0900 - val_accuracy: 0.1094\n",
            "Epoch 500/500\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.0478 - accuracy: 1.0000 - val_loss: 3.1220 - val_accuracy: 0.1094\n"
          ]
        }
      ],
      "source": [
        "pruningcallback_3=PruningCallback(init_step=100, end_step=250,\n",
        "                                init_sparsity=0.4, end_sparsity=0.90,pruning_step=5)\n",
        "tf.random.set_seed(1234)\n",
        "hist_p_3=model_to_prune_3.fit(X_train_50.reshape(-1,dim_50[0],dim_50[0],3), y_train, \n",
        "                     batch_size=50, epochs=500,\n",
        "                     callbacks=[pruningcallback_3],\n",
        "                     validation_data=(X_test_50.reshape(-1,dim_50[0],dim_50[0],3),y_test),verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wmiv69fmx4WW",
        "outputId": "7738866f-d8a8-4469-da56-79168643451d",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n",
            "5/5 [==============================] - 1s 167ms/step - loss: 2.8283 - accuracy: 0.1018 - val_loss: 2.6388 - val_accuracy: 0.0781\n",
            "Epoch 2/500\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 2.0363 - accuracy: 0.3540 - val_loss: 2.6431 - val_accuracy: 0.0625\n",
            "Epoch 3/500\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 1.5625 - accuracy: 0.6062 - val_loss: 2.6426 - val_accuracy: 0.0625\n",
            "Epoch 4/500\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 1.2140 - accuracy: 0.7699 - val_loss: 2.6462 - val_accuracy: 0.0781\n",
            "Epoch 5/500\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.9568 - accuracy: 0.8850 - val_loss: 2.6515 - val_accuracy: 0.0781\n",
            "Epoch 6/500\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.7818 - accuracy: 0.9292 - val_loss: 2.6597 - val_accuracy: 0.0938\n",
            "Epoch 7/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.6009 - accuracy: 0.9823 - val_loss: 2.6663 - val_accuracy: 0.0781\n",
            "Epoch 8/500\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.4832 - accuracy: 0.9823 - val_loss: 2.6753 - val_accuracy: 0.0625\n",
            "Epoch 9/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.4098 - accuracy: 0.9912 - val_loss: 2.6833 - val_accuracy: 0.0781\n",
            "Epoch 10/500\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.3368 - accuracy: 0.9912 - val_loss: 2.6952 - val_accuracy: 0.0625\n",
            "Epoch 11/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.2898 - accuracy: 0.9956 - val_loss: 2.7055 - val_accuracy: 0.0938\n",
            "Epoch 12/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.2484 - accuracy: 1.0000 - val_loss: 2.7097 - val_accuracy: 0.0938\n",
            "Epoch 13/500\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.2115 - accuracy: 1.0000 - val_loss: 2.7229 - val_accuracy: 0.0938\n",
            "Epoch 14/500\n",
            "5/5 [==============================] - 0s 32ms/step - loss: 0.1906 - accuracy: 1.0000 - val_loss: 2.7317 - val_accuracy: 0.0781\n",
            "Epoch 15/500\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 0.1682 - accuracy: 1.0000 - val_loss: 2.7460 - val_accuracy: 0.0938\n",
            "Epoch 16/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.1489 - accuracy: 1.0000 - val_loss: 2.7591 - val_accuracy: 0.0781\n",
            "Epoch 17/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.1380 - accuracy: 1.0000 - val_loss: 2.7711 - val_accuracy: 0.0938\n",
            "Epoch 18/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.1268 - accuracy: 1.0000 - val_loss: 2.7830 - val_accuracy: 0.0938\n",
            "Epoch 19/500\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.1196 - accuracy: 1.0000 - val_loss: 2.7910 - val_accuracy: 0.0781\n",
            "Epoch 20/500\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.1044 - accuracy: 1.0000 - val_loss: 2.8055 - val_accuracy: 0.0781\n",
            "Epoch 21/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.0953 - accuracy: 1.0000 - val_loss: 2.8196 - val_accuracy: 0.0938\n",
            "Epoch 22/500\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.0929 - accuracy: 1.0000 - val_loss: 2.8363 - val_accuracy: 0.0781\n",
            "Epoch 23/500\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.0876 - accuracy: 1.0000 - val_loss: 2.8552 - val_accuracy: 0.0625\n",
            "Epoch 24/500\n",
            "5/5 [==============================] - 0s 32ms/step - loss: 0.0842 - accuracy: 1.0000 - val_loss: 2.8708 - val_accuracy: 0.0781\n",
            "Epoch 25/500\n",
            "5/5 [==============================] - 0s 32ms/step - loss: 0.0773 - accuracy: 1.0000 - val_loss: 2.8797 - val_accuracy: 0.0781\n",
            "Epoch 26/500\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 0.0700 - accuracy: 1.0000 - val_loss: 2.8957 - val_accuracy: 0.0625\n",
            "Epoch 27/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.0680 - accuracy: 1.0000 - val_loss: 2.9105 - val_accuracy: 0.0625\n",
            "Epoch 28/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.0638 - accuracy: 1.0000 - val_loss: 2.9242 - val_accuracy: 0.1094\n",
            "Epoch 29/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.0632 - accuracy: 1.0000 - val_loss: 2.9322 - val_accuracy: 0.0938\n",
            "Epoch 30/500\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.0597 - accuracy: 1.0000 - val_loss: 2.9504 - val_accuracy: 0.0938\n",
            "Epoch 31/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.0588 - accuracy: 1.0000 - val_loss: 2.9666 - val_accuracy: 0.0938\n",
            "Epoch 32/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.0577 - accuracy: 1.0000 - val_loss: 2.9759 - val_accuracy: 0.0781\n",
            "Epoch 33/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.0536 - accuracy: 1.0000 - val_loss: 2.9823 - val_accuracy: 0.0781\n",
            "Epoch 34/500\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 0.0527 - accuracy: 1.0000 - val_loss: 2.9986 - val_accuracy: 0.0781\n",
            "Epoch 35/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.0486 - accuracy: 1.0000 - val_loss: 3.0114 - val_accuracy: 0.0781\n",
            "Epoch 36/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.0465 - accuracy: 1.0000 - val_loss: 3.0256 - val_accuracy: 0.0938\n",
            "Epoch 37/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.0433 - accuracy: 1.0000 - val_loss: 3.0352 - val_accuracy: 0.0938\n",
            "Epoch 38/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.0440 - accuracy: 1.0000 - val_loss: 3.0410 - val_accuracy: 0.0938\n",
            "Epoch 39/500\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 0.0433 - accuracy: 1.0000 - val_loss: 3.0513 - val_accuracy: 0.0938\n",
            "Epoch 40/500\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 0.0412 - accuracy: 1.0000 - val_loss: 3.0654 - val_accuracy: 0.1250\n",
            "Epoch 41/500\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.0434 - accuracy: 1.0000 - val_loss: 3.0682 - val_accuracy: 0.1094\n",
            "Epoch 42/500\n",
            "5/5 [==============================] - 0s 32ms/step - loss: 0.0381 - accuracy: 1.0000 - val_loss: 3.0835 - val_accuracy: 0.1094\n",
            "Epoch 43/500\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.0368 - accuracy: 1.0000 - val_loss: 3.0914 - val_accuracy: 0.1094\n",
            "Epoch 44/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.0370 - accuracy: 1.0000 - val_loss: 3.1001 - val_accuracy: 0.1094\n",
            "Epoch 45/500\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.0356 - accuracy: 1.0000 - val_loss: 3.1145 - val_accuracy: 0.1094\n",
            "Epoch 46/500\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.0343 - accuracy: 1.0000 - val_loss: 3.1255 - val_accuracy: 0.1094\n",
            "Epoch 47/500\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 0.0340 - accuracy: 1.0000 - val_loss: 3.1303 - val_accuracy: 0.0938\n",
            "Epoch 48/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.0324 - accuracy: 1.0000 - val_loss: 3.1386 - val_accuracy: 0.0938\n",
            "Epoch 49/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.0323 - accuracy: 1.0000 - val_loss: 3.1447 - val_accuracy: 0.0938\n",
            "Epoch 50/500\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.0312 - accuracy: 1.0000 - val_loss: 3.1486 - val_accuracy: 0.0938\n",
            "Epoch 51/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.0310 - accuracy: 1.0000 - val_loss: 3.1601 - val_accuracy: 0.0938\n",
            "Epoch 52/500\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.0297 - accuracy: 1.0000 - val_loss: 3.1652 - val_accuracy: 0.0938\n",
            "Epoch 53/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.0285 - accuracy: 1.0000 - val_loss: 3.1746 - val_accuracy: 0.0781\n",
            "Epoch 54/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.0287 - accuracy: 1.0000 - val_loss: 3.1739 - val_accuracy: 0.0781\n",
            "Epoch 55/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.0276 - accuracy: 1.0000 - val_loss: 3.1720 - val_accuracy: 0.0781\n",
            "Epoch 56/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.0266 - accuracy: 1.0000 - val_loss: 3.1738 - val_accuracy: 0.0781\n",
            "Epoch 57/500\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 0.0265 - accuracy: 1.0000 - val_loss: 3.1758 - val_accuracy: 0.0781\n",
            "Epoch 58/500\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 0.0259 - accuracy: 1.0000 - val_loss: 3.1753 - val_accuracy: 0.0781\n",
            "Epoch 59/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.0290 - accuracy: 1.0000 - val_loss: 3.1744 - val_accuracy: 0.0781\n",
            "Epoch 60/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.0248 - accuracy: 1.0000 - val_loss: 3.1681 - val_accuracy: 0.0781\n",
            "Epoch 61/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.0264 - accuracy: 1.0000 - val_loss: 3.1651 - val_accuracy: 0.0781\n",
            "Epoch 62/500\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 0.0251 - accuracy: 1.0000 - val_loss: 3.1581 - val_accuracy: 0.0781\n",
            "Epoch 63/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.0242 - accuracy: 1.0000 - val_loss: 3.1581 - val_accuracy: 0.0938\n",
            "Epoch 64/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.0248 - accuracy: 1.0000 - val_loss: 3.1543 - val_accuracy: 0.1250\n",
            "Epoch 65/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.0231 - accuracy: 1.0000 - val_loss: 3.1501 - val_accuracy: 0.1094\n",
            "Epoch 66/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.0222 - accuracy: 1.0000 - val_loss: 3.1446 - val_accuracy: 0.1094\n",
            "Epoch 67/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.0220 - accuracy: 1.0000 - val_loss: 3.1413 - val_accuracy: 0.1250\n",
            "Epoch 68/500\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.0221 - accuracy: 1.0000 - val_loss: 3.1303 - val_accuracy: 0.1250\n",
            "Epoch 69/500\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.0213 - accuracy: 1.0000 - val_loss: 3.1220 - val_accuracy: 0.1406\n",
            "Epoch 70/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.0228 - accuracy: 1.0000 - val_loss: 3.1079 - val_accuracy: 0.1406\n",
            "Epoch 71/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.0207 - accuracy: 1.0000 - val_loss: 3.0970 - val_accuracy: 0.1406\n",
            "Epoch 72/500\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 0.0205 - accuracy: 1.0000 - val_loss: 3.0859 - val_accuracy: 0.1562\n",
            "Epoch 73/500\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.0195 - accuracy: 1.0000 - val_loss: 3.0845 - val_accuracy: 0.1562\n",
            "Epoch 74/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.0194 - accuracy: 1.0000 - val_loss: 3.0719 - val_accuracy: 0.1719\n",
            "Epoch 75/500\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.0189 - accuracy: 1.0000 - val_loss: 3.0581 - val_accuracy: 0.1719\n",
            "Epoch 76/500\n",
            "5/5 [==============================] - 0s 32ms/step - loss: 0.0198 - accuracy: 1.0000 - val_loss: 3.0386 - val_accuracy: 0.1719\n",
            "Epoch 77/500\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 0.0188 - accuracy: 1.0000 - val_loss: 3.0254 - val_accuracy: 0.1719\n",
            "Epoch 78/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.0189 - accuracy: 1.0000 - val_loss: 3.0155 - val_accuracy: 0.1719\n",
            "Epoch 79/500\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 0.0176 - accuracy: 1.0000 - val_loss: 2.9989 - val_accuracy: 0.1719\n",
            "Epoch 80/500\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.0172 - accuracy: 1.0000 - val_loss: 2.9820 - val_accuracy: 0.2031\n",
            "Epoch 81/500\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.0170 - accuracy: 1.0000 - val_loss: 2.9690 - val_accuracy: 0.1719\n",
            "Epoch 82/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.0167 - accuracy: 1.0000 - val_loss: 2.9533 - val_accuracy: 0.2031\n",
            "Epoch 83/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.0174 - accuracy: 1.0000 - val_loss: 2.9329 - val_accuracy: 0.2188\n",
            "Epoch 84/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.0167 - accuracy: 1.0000 - val_loss: 2.9122 - val_accuracy: 0.2031\n",
            "Epoch 85/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.0172 - accuracy: 1.0000 - val_loss: 2.8985 - val_accuracy: 0.2031\n",
            "Epoch 86/500\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.0161 - accuracy: 1.0000 - val_loss: 2.8769 - val_accuracy: 0.2031\n",
            "Epoch 87/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.0159 - accuracy: 1.0000 - val_loss: 2.8562 - val_accuracy: 0.2031\n",
            "Epoch 88/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.0163 - accuracy: 1.0000 - val_loss: 2.8385 - val_accuracy: 0.2031\n",
            "Epoch 89/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.0160 - accuracy: 1.0000 - val_loss: 2.8244 - val_accuracy: 0.2031\n",
            "Epoch 90/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.0153 - accuracy: 1.0000 - val_loss: 2.8018 - val_accuracy: 0.2188\n",
            "Epoch 91/500\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.0152 - accuracy: 1.0000 - val_loss: 2.7827 - val_accuracy: 0.2188\n",
            "Epoch 92/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.0156 - accuracy: 1.0000 - val_loss: 2.7520 - val_accuracy: 0.2188\n",
            "Epoch 93/500\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.0150 - accuracy: 1.0000 - val_loss: 2.7323 - val_accuracy: 0.2344\n",
            "Epoch 94/500\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.0147 - accuracy: 1.0000 - val_loss: 2.7163 - val_accuracy: 0.2500\n",
            "Epoch 95/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.0146 - accuracy: 1.0000 - val_loss: 2.6819 - val_accuracy: 0.2500\n",
            "Epoch 96/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.0143 - accuracy: 1.0000 - val_loss: 2.6676 - val_accuracy: 0.2656\n",
            "Epoch 97/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.0143 - accuracy: 1.0000 - val_loss: 2.6476 - val_accuracy: 0.2500\n",
            "Epoch 98/500\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.0142 - accuracy: 1.0000 - val_loss: 2.6238 - val_accuracy: 0.2500\n",
            "Epoch 99/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.0146 - accuracy: 1.0000 - val_loss: 2.6089 - val_accuracy: 0.2500\n",
            "Epoch 100/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.0141 - accuracy: 1.0000 - val_loss: 2.5919 - val_accuracy: 0.2500\n",
            "Epoch 101/500\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0138 - accuracy: 1.0000\n",
            " pruning [ = = = = ]\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.0138 - accuracy: 1.0000 - val_loss: 2.5718 - val_accuracy: 0.2656\n",
            "Epoch 102/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 2.3321 - accuracy: 0.2168 - val_loss: 2.7652 - val_accuracy: 0.0625\n",
            "Epoch 103/500\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 1.9460 - accuracy: 0.4381 - val_loss: 2.7648 - val_accuracy: 0.0781\n",
            "Epoch 104/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 1.6821 - accuracy: 0.6195 - val_loss: 2.7575 - val_accuracy: 0.0938\n",
            "Epoch 105/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 1.4823 - accuracy: 0.7212 - val_loss: 2.7692 - val_accuracy: 0.1094\n",
            "Epoch 106/500\n",
            "5/5 [==============================] - ETA: 0s - loss: 1.3353 - accuracy: 0.8009\n",
            " pruning [ = = = = ]\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 1.3353 - accuracy: 0.8009 - val_loss: 2.8031 - val_accuracy: 0.0781\n",
            "Epoch 107/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 1.4659 - accuracy: 0.7611 - val_loss: 2.7405 - val_accuracy: 0.1094\n",
            "Epoch 108/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 1.2640 - accuracy: 0.8363 - val_loss: 2.7260 - val_accuracy: 0.1094\n",
            "Epoch 109/500\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 1.1446 - accuracy: 0.8982 - val_loss: 2.6868 - val_accuracy: 0.1094\n",
            "Epoch 110/500\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 1.0324 - accuracy: 0.9292 - val_loss: 2.6992 - val_accuracy: 0.1250\n",
            "Epoch 111/500\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.9230 - accuracy: 0.9602\n",
            " pruning [ = = = = ]\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 0.9230 - accuracy: 0.9602 - val_loss: 2.7180 - val_accuracy: 0.1250\n",
            "Epoch 112/500\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 1.1012 - accuracy: 0.9115 - val_loss: 2.7411 - val_accuracy: 0.1406\n",
            "Epoch 113/500\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 0.9654 - accuracy: 0.9336 - val_loss: 2.7522 - val_accuracy: 0.1094\n",
            "Epoch 114/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.8487 - accuracy: 0.9558 - val_loss: 2.6903 - val_accuracy: 0.1250\n",
            "Epoch 115/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.7489 - accuracy: 0.9867 - val_loss: 2.6658 - val_accuracy: 0.1719\n",
            "Epoch 116/500\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.7014 - accuracy: 0.9867\n",
            " pruning [ = = = = ]\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 0.7014 - accuracy: 0.9867 - val_loss: 2.6528 - val_accuracy: 0.1406\n",
            "Epoch 117/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 1.0448 - accuracy: 0.9115 - val_loss: 2.7227 - val_accuracy: 0.0938\n",
            "Epoch 118/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.9226 - accuracy: 0.9159 - val_loss: 2.6332 - val_accuracy: 0.1875\n",
            "Epoch 119/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.7632 - accuracy: 0.9779 - val_loss: 2.6495 - val_accuracy: 0.2344\n",
            "Epoch 120/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.7007 - accuracy: 0.9867 - val_loss: 2.6002 - val_accuracy: 0.1719\n",
            "Epoch 121/500\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.6410 - accuracy: 0.9779\n",
            " pruning [ = = = = ]\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 0.6410 - accuracy: 0.9779 - val_loss: 2.6559 - val_accuracy: 0.1250\n",
            "Epoch 122/500\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.8867 - accuracy: 0.9646 - val_loss: 2.6579 - val_accuracy: 0.1406\n",
            "Epoch 123/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.7689 - accuracy: 0.9779 - val_loss: 2.7272 - val_accuracy: 0.1406\n",
            "Epoch 124/500\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.6953 - accuracy: 0.9779 - val_loss: 2.5938 - val_accuracy: 0.1875\n",
            "Epoch 125/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.6372 - accuracy: 0.9867 - val_loss: 2.6364 - val_accuracy: 0.1250\n",
            "Epoch 126/500\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.5503 - accuracy: 0.9912\n",
            " pruning [ = = = = ]\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.5503 - accuracy: 0.9912 - val_loss: 2.5453 - val_accuracy: 0.1875\n",
            "Epoch 127/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.8571 - accuracy: 0.9646 - val_loss: 2.5270 - val_accuracy: 0.2188\n",
            "Epoch 128/500\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.7282 - accuracy: 0.9646 - val_loss: 2.5851 - val_accuracy: 0.2188\n",
            "Epoch 129/500\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 0.6610 - accuracy: 0.9779 - val_loss: 2.5716 - val_accuracy: 0.2188\n",
            "Epoch 130/500\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.5850 - accuracy: 0.9912 - val_loss: 2.5268 - val_accuracy: 0.1875\n",
            "Epoch 131/500\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.5249 - accuracy: 0.9912\n",
            " pruning [ = = = = ]\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.5249 - accuracy: 0.9912 - val_loss: 2.5556 - val_accuracy: 0.1875\n",
            "Epoch 132/500\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.7379 - accuracy: 0.9823 - val_loss: 2.4539 - val_accuracy: 0.1719\n",
            "Epoch 133/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.6644 - accuracy: 0.9867 - val_loss: 2.3921 - val_accuracy: 0.2031\n",
            "Epoch 134/500\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.5794 - accuracy: 0.9912 - val_loss: 2.3874 - val_accuracy: 0.2500\n",
            "Epoch 135/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.5407 - accuracy: 0.9867 - val_loss: 2.5055 - val_accuracy: 0.2344\n",
            "Epoch 136/500\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.4882 - accuracy: 0.9912\n",
            " pruning [ = = = = ]\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.4882 - accuracy: 0.9912 - val_loss: 2.4321 - val_accuracy: 0.2656\n",
            "Epoch 137/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.7531 - accuracy: 0.9912 - val_loss: 2.4896 - val_accuracy: 0.1719\n",
            "Epoch 138/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.6458 - accuracy: 0.9867 - val_loss: 2.4192 - val_accuracy: 0.1719\n",
            "Epoch 139/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.5737 - accuracy: 0.9956 - val_loss: 2.3213 - val_accuracy: 0.1562\n",
            "Epoch 140/500\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.5049 - accuracy: 0.9956 - val_loss: 2.3901 - val_accuracy: 0.2344\n",
            "Epoch 141/500\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.4638 - accuracy: 0.9956\n",
            " pruning [ = = = = ]\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.4638 - accuracy: 0.9956 - val_loss: 2.3182 - val_accuracy: 0.2812\n",
            "Epoch 142/500\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.7665 - accuracy: 0.9823 - val_loss: 2.4106 - val_accuracy: 0.2188\n",
            "Epoch 143/500\n",
            "5/5 [==============================] - 0s 32ms/step - loss: 0.6408 - accuracy: 0.9867 - val_loss: 2.3713 - val_accuracy: 0.2188\n",
            "Epoch 144/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.5776 - accuracy: 0.9912 - val_loss: 2.4166 - val_accuracy: 0.1875\n",
            "Epoch 145/500\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.5213 - accuracy: 1.0000 - val_loss: 2.3912 - val_accuracy: 0.2031\n",
            "Epoch 146/500\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.4564 - accuracy: 1.0000\n",
            " pruning [ = = = = ]\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 0.4564 - accuracy: 1.0000 - val_loss: 2.3346 - val_accuracy: 0.2344\n",
            "Epoch 147/500\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 0.9486 - accuracy: 0.9425 - val_loss: 2.4487 - val_accuracy: 0.2031\n",
            "Epoch 148/500\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.7613 - accuracy: 0.9779 - val_loss: 2.4418 - val_accuracy: 0.2500\n",
            "Epoch 149/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.6974 - accuracy: 0.9779 - val_loss: 2.3600 - val_accuracy: 0.2812\n",
            "Epoch 150/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.6226 - accuracy: 0.9867 - val_loss: 2.4204 - val_accuracy: 0.2031\n",
            "Epoch 151/500\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.6074 - accuracy: 1.0000\n",
            " pruning [ = = = = ]\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 0.6074 - accuracy: 1.0000 - val_loss: 2.3287 - val_accuracy: 0.2344\n",
            "Epoch 152/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.7445 - accuracy: 0.9779 - val_loss: 2.3723 - val_accuracy: 0.2500\n",
            "Epoch 153/500\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.6556 - accuracy: 0.9867 - val_loss: 2.4094 - val_accuracy: 0.2344\n",
            "Epoch 154/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.5827 - accuracy: 0.9956 - val_loss: 2.3513 - val_accuracy: 0.2344\n",
            "Epoch 155/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.5460 - accuracy: 1.0000 - val_loss: 2.3840 - val_accuracy: 0.2344\n",
            "Epoch 156/500\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.4808 - accuracy: 1.0000\n",
            " pruning [ = = = = ]\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.4808 - accuracy: 1.0000 - val_loss: 2.3468 - val_accuracy: 0.2656\n",
            "Epoch 157/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.8680 - accuracy: 0.9690 - val_loss: 2.4118 - val_accuracy: 0.2031\n",
            "Epoch 158/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.7359 - accuracy: 0.9779 - val_loss: 2.3447 - val_accuracy: 0.2344\n",
            "Epoch 159/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.6433 - accuracy: 0.9823 - val_loss: 2.3450 - val_accuracy: 0.2500\n",
            "Epoch 160/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.5658 - accuracy: 0.9956 - val_loss: 2.3943 - val_accuracy: 0.2188\n",
            "Epoch 161/500\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.5413 - accuracy: 1.0000\n",
            " pruning [ = = = = ]\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.5413 - accuracy: 1.0000 - val_loss: 2.3374 - val_accuracy: 0.2500\n",
            "Epoch 162/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.7406 - accuracy: 0.9823 - val_loss: 2.3800 - val_accuracy: 0.2344\n",
            "Epoch 163/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.6407 - accuracy: 0.9956 - val_loss: 2.3177 - val_accuracy: 0.2344\n",
            "Epoch 164/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.5614 - accuracy: 0.9956 - val_loss: 2.2878 - val_accuracy: 0.2344\n",
            "Epoch 165/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.5061 - accuracy: 1.0000 - val_loss: 2.4094 - val_accuracy: 0.2344\n",
            "Epoch 166/500\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.4895 - accuracy: 1.0000\n",
            " pruning [ = = = = ]\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.4895 - accuracy: 1.0000 - val_loss: 2.3141 - val_accuracy: 0.2344\n",
            "Epoch 167/500\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 0.7028 - accuracy: 0.9867 - val_loss: 2.3822 - val_accuracy: 0.2188\n",
            "Epoch 168/500\n",
            "5/5 [==============================] - 0s 32ms/step - loss: 0.6537 - accuracy: 0.9867 - val_loss: 2.3407 - val_accuracy: 0.2812\n",
            "Epoch 169/500\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.6249 - accuracy: 0.9912 - val_loss: 2.2881 - val_accuracy: 0.2500\n",
            "Epoch 170/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.5438 - accuracy: 1.0000 - val_loss: 2.3459 - val_accuracy: 0.2188\n",
            "Epoch 171/500\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.4834 - accuracy: 0.9956\n",
            " pruning [ = = = = ]\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 0.4834 - accuracy: 0.9956 - val_loss: 2.2855 - val_accuracy: 0.2812\n",
            "Epoch 172/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.9149 - accuracy: 0.9646 - val_loss: 2.2704 - val_accuracy: 0.2969\n",
            "Epoch 173/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.7405 - accuracy: 0.9779 - val_loss: 2.4871 - val_accuracy: 0.2031\n",
            "Epoch 174/500\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.7161 - accuracy: 0.9823 - val_loss: 2.2709 - val_accuracy: 0.1875\n",
            "Epoch 175/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.6126 - accuracy: 0.9912 - val_loss: 2.2503 - val_accuracy: 0.2812\n",
            "Epoch 176/500\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.5099 - accuracy: 1.0000\n",
            " pruning [ = = = = ]\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.5099 - accuracy: 1.0000 - val_loss: 2.2551 - val_accuracy: 0.2500\n",
            "Epoch 177/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.8306 - accuracy: 0.9823 - val_loss: 2.3387 - val_accuracy: 0.2812\n",
            "Epoch 178/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.7407 - accuracy: 0.9823 - val_loss: 2.3145 - val_accuracy: 0.2188\n",
            "Epoch 179/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.6475 - accuracy: 1.0000 - val_loss: 2.3266 - val_accuracy: 0.2500\n",
            "Epoch 180/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.6301 - accuracy: 0.9735 - val_loss: 2.2996 - val_accuracy: 0.2812\n",
            "Epoch 181/500\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.5544 - accuracy: 0.9956\n",
            " pruning [ = = = = ]\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.5544 - accuracy: 0.9956 - val_loss: 2.2563 - val_accuracy: 0.2656\n",
            "Epoch 182/500\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.8635 - accuracy: 0.9779 - val_loss: 2.3579 - val_accuracy: 0.2031\n",
            "Epoch 183/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.6685 - accuracy: 0.9867 - val_loss: 2.2629 - val_accuracy: 0.2969\n",
            "Epoch 184/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.6378 - accuracy: 0.9956 - val_loss: 2.2753 - val_accuracy: 0.3125\n",
            "Epoch 185/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.5313 - accuracy: 0.9956 - val_loss: 2.3168 - val_accuracy: 0.2188\n",
            "Epoch 186/500\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.5088 - accuracy: 0.9956\n",
            " pruning [ = = = = ]\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.5088 - accuracy: 0.9956 - val_loss: 2.2696 - val_accuracy: 0.2812\n",
            "Epoch 187/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.9462 - accuracy: 0.9646 - val_loss: 2.2931 - val_accuracy: 0.2188\n",
            "Epoch 188/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.8046 - accuracy: 0.9912 - val_loss: 2.4008 - val_accuracy: 0.2031\n",
            "Epoch 189/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.7889 - accuracy: 0.9690 - val_loss: 2.3324 - val_accuracy: 0.2188\n",
            "Epoch 190/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.7081 - accuracy: 0.9912 - val_loss: 2.2811 - val_accuracy: 0.2344\n",
            "Epoch 191/500\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.6399 - accuracy: 0.9956\n",
            " pruning [ = = = = ]\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.6399 - accuracy: 0.9956 - val_loss: 2.1980 - val_accuracy: 0.2344\n",
            "Epoch 192/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 1.1567 - accuracy: 0.8805 - val_loss: 2.3074 - val_accuracy: 0.2812\n",
            "Epoch 193/500\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.9909 - accuracy: 0.9248 - val_loss: 2.4376 - val_accuracy: 0.2031\n",
            "Epoch 194/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.8642 - accuracy: 0.9558 - val_loss: 2.3292 - val_accuracy: 0.2031\n",
            "Epoch 195/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.8361 - accuracy: 0.9602 - val_loss: 2.3151 - val_accuracy: 0.2344\n",
            "Epoch 196/500\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.7872 - accuracy: 0.9646\n",
            " pruning [ = = = = ]\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 0.7872 - accuracy: 0.9646 - val_loss: 2.2813 - val_accuracy: 0.2344\n",
            "Epoch 197/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 1.3106 - accuracy: 0.8717 - val_loss: 2.3141 - val_accuracy: 0.2031\n",
            "Epoch 198/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 1.1355 - accuracy: 0.9292 - val_loss: 2.3096 - val_accuracy: 0.2188\n",
            "Epoch 199/500\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.9690 - accuracy: 0.9823 - val_loss: 2.4289 - val_accuracy: 0.2031\n",
            "Epoch 200/500\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.8956 - accuracy: 0.9779 - val_loss: 2.3614 - val_accuracy: 0.2344\n",
            "Epoch 201/500\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.8850 - accuracy: 0.9735\n",
            " pruning [ = = = = ]\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.8850 - accuracy: 0.9735 - val_loss: 2.2698 - val_accuracy: 0.2656\n",
            "Epoch 202/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 1.4603 - accuracy: 0.7876 - val_loss: 2.5509 - val_accuracy: 0.2031\n",
            "Epoch 203/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 1.2423 - accuracy: 0.8894 - val_loss: 2.4742 - val_accuracy: 0.1719\n",
            "Epoch 204/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 1.1714 - accuracy: 0.9248 - val_loss: 2.4105 - val_accuracy: 0.2188\n",
            "Epoch 205/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 1.0616 - accuracy: 0.9425 - val_loss: 2.4786 - val_accuracy: 0.2031\n",
            "Epoch 206/500\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.9968 - accuracy: 0.9381\n",
            " pruning [ = = = = ]\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.9968 - accuracy: 0.9381 - val_loss: 2.5174 - val_accuracy: 0.1562\n",
            "Epoch 207/500\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 1.4864 - accuracy: 0.7389 - val_loss: 2.4219 - val_accuracy: 0.2188\n",
            "Epoch 208/500\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 1.2741 - accuracy: 0.8584 - val_loss: 2.4002 - val_accuracy: 0.2188\n",
            "Epoch 209/500\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 1.1829 - accuracy: 0.8938 - val_loss: 2.4149 - val_accuracy: 0.1719\n",
            "Epoch 210/500\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 1.1111 - accuracy: 0.9115 - val_loss: 2.3747 - val_accuracy: 0.2344\n",
            "Epoch 211/500\n",
            "5/5 [==============================] - ETA: 0s - loss: 1.0217 - accuracy: 0.9292\n",
            " pruning [ = = = = ]\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 1.0217 - accuracy: 0.9292 - val_loss: 2.4179 - val_accuracy: 0.2031\n",
            "Epoch 212/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 1.5248 - accuracy: 0.8097 - val_loss: 2.4343 - val_accuracy: 0.1875\n",
            "Epoch 213/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 1.4150 - accuracy: 0.8319 - val_loss: 2.4594 - val_accuracy: 0.1875\n",
            "Epoch 214/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 1.3248 - accuracy: 0.8584 - val_loss: 2.4527 - val_accuracy: 0.2656\n",
            "Epoch 215/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 1.2389 - accuracy: 0.8805 - val_loss: 2.4145 - val_accuracy: 0.1406\n",
            "Epoch 216/500\n",
            "5/5 [==============================] - ETA: 0s - loss: 1.2495 - accuracy: 0.8628\n",
            " pruning [ = = = = ]\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 1.2495 - accuracy: 0.8628 - val_loss: 2.3999 - val_accuracy: 0.1875\n",
            "Epoch 217/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 1.8184 - accuracy: 0.6062 - val_loss: 2.5431 - val_accuracy: 0.0781\n",
            "Epoch 218/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 1.6578 - accuracy: 0.6858 - val_loss: 2.4815 - val_accuracy: 0.1094\n",
            "Epoch 219/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 1.5213 - accuracy: 0.7876 - val_loss: 2.5927 - val_accuracy: 0.1562\n",
            "Epoch 220/500\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 1.4274 - accuracy: 0.8274 - val_loss: 2.4519 - val_accuracy: 0.1562\n",
            "Epoch 221/500\n",
            "5/5 [==============================] - ETA: 0s - loss: 1.4105 - accuracy: 0.8142\n",
            " pruning [ = = = = ]\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 1.4105 - accuracy: 0.8142 - val_loss: 2.4763 - val_accuracy: 0.2344\n",
            "Epoch 222/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 1.8228 - accuracy: 0.6239 - val_loss: 2.5891 - val_accuracy: 0.1250\n",
            "Epoch 223/500\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 1.7153 - accuracy: 0.6681 - val_loss: 2.5149 - val_accuracy: 0.1250\n",
            "Epoch 224/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 1.6244 - accuracy: 0.7522 - val_loss: 2.4694 - val_accuracy: 0.1562\n",
            "Epoch 225/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 1.5486 - accuracy: 0.7655 - val_loss: 2.4766 - val_accuracy: 0.1094\n",
            "Epoch 226/500\n",
            "5/5 [==============================] - ETA: 0s - loss: 1.5449 - accuracy: 0.7743\n",
            " pruning [ = = = = ]\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 1.5449 - accuracy: 0.7743 - val_loss: 2.5164 - val_accuracy: 0.2812\n",
            "Epoch 227/500\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 2.0543 - accuracy: 0.4558 - val_loss: 2.5724 - val_accuracy: 0.2031\n",
            "Epoch 228/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 1.8553 - accuracy: 0.5664 - val_loss: 2.4905 - val_accuracy: 0.1875\n",
            "Epoch 229/500\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 1.7800 - accuracy: 0.6106 - val_loss: 2.5269 - val_accuracy: 0.1406\n",
            "Epoch 230/500\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 1.7146 - accuracy: 0.6062 - val_loss: 2.5930 - val_accuracy: 0.1406\n",
            "Epoch 231/500\n",
            "5/5 [==============================] - ETA: 0s - loss: 1.6237 - accuracy: 0.6549\n",
            " pruning [ = = = = ]\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 1.6237 - accuracy: 0.6549 - val_loss: 2.6013 - val_accuracy: 0.1250\n",
            "Epoch 232/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 2.2755 - accuracy: 0.3097 - val_loss: 2.5547 - val_accuracy: 0.1250\n",
            "Epoch 233/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 2.1249 - accuracy: 0.4071 - val_loss: 2.5533 - val_accuracy: 0.2188\n",
            "Epoch 234/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 2.0632 - accuracy: 0.4735 - val_loss: 2.5175 - val_accuracy: 0.2031\n",
            "Epoch 235/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 1.9843 - accuracy: 0.5221 - val_loss: 2.5020 - val_accuracy: 0.2500\n",
            "Epoch 236/500\n",
            "5/5 [==============================] - ETA: 0s - loss: 1.8996 - accuracy: 0.5841\n",
            " pruning [ = = = = ]\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 1.8996 - accuracy: 0.5841 - val_loss: 2.4783 - val_accuracy: 0.1719\n",
            "Epoch 237/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 2.3723 - accuracy: 0.2832 - val_loss: 2.5870 - val_accuracy: 0.1562\n",
            "Epoch 238/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 2.3225 - accuracy: 0.3097 - val_loss: 2.5933 - val_accuracy: 0.1094\n",
            "Epoch 239/500\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 2.2636 - accuracy: 0.3584 - val_loss: 2.6051 - val_accuracy: 0.1094\n",
            "Epoch 240/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 2.2324 - accuracy: 0.4115 - val_loss: 2.5963 - val_accuracy: 0.1406\n",
            "Epoch 241/500\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 2.1987 - accuracy: 0.4100\n",
            " pruning [ = = = = ]\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 2.2011 - accuracy: 0.4027 - val_loss: 2.6109 - val_accuracy: 0.1406\n",
            "Epoch 242/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 2.3371 - accuracy: 0.2743 - val_loss: 2.5965 - val_accuracy: 0.1250\n",
            "Epoch 243/500\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 2.3044 - accuracy: 0.3053 - val_loss: 2.6137 - val_accuracy: 0.1250\n",
            "Epoch 244/500\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 2.2784 - accuracy: 0.3496 - val_loss: 2.6117 - val_accuracy: 0.0938\n",
            "Epoch 245/500\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 2.2238 - accuracy: 0.4204 - val_loss: 2.5849 - val_accuracy: 0.1562\n",
            "Epoch 246/500\n",
            "5/5 [==============================] - ETA: 0s - loss: 2.2260 - accuracy: 0.4115\n",
            " pruning [ = = = = ]\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 2.2260 - accuracy: 0.4115 - val_loss: 2.6114 - val_accuracy: 0.1250\n",
            "Epoch 247/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 2.6134 - accuracy: 0.1106 - val_loss: 2.6394 - val_accuracy: 0.0781\n",
            "Epoch 248/500\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 2.5810 - accuracy: 0.1283 - val_loss: 2.6433 - val_accuracy: 0.0781\n",
            "Epoch 249/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 2.5717 - accuracy: 0.1372 - val_loss: 2.6453 - val_accuracy: 0.1094\n",
            "Epoch 250/500\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 2.5462 - accuracy: 0.1858 - val_loss: 2.6247 - val_accuracy: 0.0938\n",
            "Epoch 251/500\n",
            "5/5 [==============================] - ETA: 0s - loss: 2.5432 - accuracy: 0.1858\n",
            " pruning [ = = = = ]\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 2.5432 - accuracy: 0.1858 - val_loss: 2.6225 - val_accuracy: 0.1094\n",
            "Epoch 252/500\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 2.6068 - accuracy: 0.1150 - val_loss: 2.6237 - val_accuracy: 0.0938\n",
            "Epoch 253/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 2.5964 - accuracy: 0.1018 - val_loss: 2.6217 - val_accuracy: 0.0938\n",
            "Epoch 254/500\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 2.5869 - accuracy: 0.1504 - val_loss: 2.6237 - val_accuracy: 0.0938\n",
            "Epoch 255/500\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 2.5808 - accuracy: 0.1416 - val_loss: 2.6233 - val_accuracy: 0.0938\n",
            "Epoch 256/500\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 2.5789 - accuracy: 0.1637 - val_loss: 2.6219 - val_accuracy: 0.0938\n",
            "Epoch 257/500\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 2.5710 - accuracy: 0.1814 - val_loss: 2.6200 - val_accuracy: 0.0938\n",
            "Epoch 258/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 2.5748 - accuracy: 0.1593 - val_loss: 2.6235 - val_accuracy: 0.0938\n",
            "Epoch 259/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 2.5621 - accuracy: 0.1726 - val_loss: 2.6257 - val_accuracy: 0.0938\n",
            "Epoch 260/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 2.5581 - accuracy: 0.1637 - val_loss: 2.6210 - val_accuracy: 0.1094\n",
            "Epoch 261/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 2.5558 - accuracy: 0.1858 - val_loss: 2.6239 - val_accuracy: 0.1094\n",
            "Epoch 262/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 2.5446 - accuracy: 0.1903 - val_loss: 2.6205 - val_accuracy: 0.1094\n",
            "Epoch 263/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 2.5366 - accuracy: 0.1858 - val_loss: 2.6225 - val_accuracy: 0.1094\n",
            "Epoch 264/500\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 2.5386 - accuracy: 0.1770 - val_loss: 2.6205 - val_accuracy: 0.1094\n",
            "Epoch 265/500\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 2.5385 - accuracy: 0.1903 - val_loss: 2.6224 - val_accuracy: 0.0938\n",
            "Epoch 266/500\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 2.5294 - accuracy: 0.2035 - val_loss: 2.6190 - val_accuracy: 0.1094\n",
            "Epoch 267/500\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 2.5242 - accuracy: 0.2035 - val_loss: 2.6237 - val_accuracy: 0.1094\n",
            "Epoch 268/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 2.5220 - accuracy: 0.2124 - val_loss: 2.6182 - val_accuracy: 0.1406\n",
            "Epoch 269/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 2.5285 - accuracy: 0.2168 - val_loss: 2.6238 - val_accuracy: 0.0781\n",
            "Epoch 270/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 2.5141 - accuracy: 0.2212 - val_loss: 2.6168 - val_accuracy: 0.0781\n",
            "Epoch 271/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 2.5039 - accuracy: 0.2389 - val_loss: 2.6203 - val_accuracy: 0.0938\n",
            "Epoch 272/500\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 2.5127 - accuracy: 0.2212 - val_loss: 2.6232 - val_accuracy: 0.0938\n",
            "Epoch 273/500\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 2.4911 - accuracy: 0.2522 - val_loss: 2.6163 - val_accuracy: 0.0781\n",
            "Epoch 274/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 2.5030 - accuracy: 0.2035 - val_loss: 2.6160 - val_accuracy: 0.1250\n",
            "Epoch 275/500\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 2.5025 - accuracy: 0.1814 - val_loss: 2.6220 - val_accuracy: 0.0625\n",
            "Epoch 276/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 2.5034 - accuracy: 0.2124 - val_loss: 2.6179 - val_accuracy: 0.1250\n",
            "Epoch 277/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 2.4928 - accuracy: 0.1903 - val_loss: 2.6188 - val_accuracy: 0.0938\n",
            "Epoch 278/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 2.4929 - accuracy: 0.2168 - val_loss: 2.6224 - val_accuracy: 0.0625\n",
            "Epoch 279/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 2.4689 - accuracy: 0.2699 - val_loss: 2.6177 - val_accuracy: 0.0938\n",
            "Epoch 280/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 2.4610 - accuracy: 0.2345 - val_loss: 2.6073 - val_accuracy: 0.1094\n",
            "Epoch 281/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 2.4816 - accuracy: 0.2212 - val_loss: 2.6208 - val_accuracy: 0.0781\n",
            "Epoch 282/500\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 2.4634 - accuracy: 0.2699 - val_loss: 2.6303 - val_accuracy: 0.0781\n",
            "Epoch 283/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 2.4450 - accuracy: 0.2611 - val_loss: 2.6232 - val_accuracy: 0.0938\n",
            "Epoch 284/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 2.4610 - accuracy: 0.2478 - val_loss: 2.6212 - val_accuracy: 0.0938\n",
            "Epoch 285/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 2.4391 - accuracy: 0.2611 - val_loss: 2.6161 - val_accuracy: 0.0938\n",
            "Epoch 286/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 2.4493 - accuracy: 0.2434 - val_loss: 2.6148 - val_accuracy: 0.1250\n",
            "Epoch 287/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 2.4325 - accuracy: 0.2611 - val_loss: 2.6144 - val_accuracy: 0.0625\n",
            "Epoch 288/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 2.4274 - accuracy: 0.2566 - val_loss: 2.6281 - val_accuracy: 0.0938\n",
            "Epoch 289/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 2.4360 - accuracy: 0.2566 - val_loss: 2.6284 - val_accuracy: 0.0781\n",
            "Epoch 290/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 2.4208 - accuracy: 0.2788 - val_loss: 2.6120 - val_accuracy: 0.0625\n",
            "Epoch 291/500\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 2.4147 - accuracy: 0.2611 - val_loss: 2.6334 - val_accuracy: 0.0938\n",
            "Epoch 292/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 2.4002 - accuracy: 0.2876 - val_loss: 2.6071 - val_accuracy: 0.0938\n",
            "Epoch 293/500\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 2.4074 - accuracy: 0.2566 - val_loss: 2.6166 - val_accuracy: 0.1250\n",
            "Epoch 294/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 2.4181 - accuracy: 0.2522 - val_loss: 2.6106 - val_accuracy: 0.1094\n",
            "Epoch 295/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 2.3919 - accuracy: 0.2655 - val_loss: 2.6200 - val_accuracy: 0.1250\n",
            "Epoch 296/500\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 2.3802 - accuracy: 0.2743 - val_loss: 2.6115 - val_accuracy: 0.0938\n",
            "Epoch 297/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 2.3683 - accuracy: 0.2743 - val_loss: 2.6107 - val_accuracy: 0.0938\n",
            "Epoch 298/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 2.4242 - accuracy: 0.2301 - val_loss: 2.6259 - val_accuracy: 0.0781\n",
            "Epoch 299/500\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 2.3644 - accuracy: 0.3009 - val_loss: 2.6409 - val_accuracy: 0.1094\n",
            "Epoch 300/500\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 2.3673 - accuracy: 0.2655 - val_loss: 2.6366 - val_accuracy: 0.1094\n",
            "Epoch 301/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 2.3533 - accuracy: 0.2920 - val_loss: 2.6596 - val_accuracy: 0.0781\n",
            "Epoch 302/500\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 2.3539 - accuracy: 0.2566 - val_loss: 2.6646 - val_accuracy: 0.0938\n",
            "Epoch 303/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 2.3655 - accuracy: 0.2611 - val_loss: 2.6393 - val_accuracy: 0.0938\n",
            "Epoch 304/500\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 2.3304 - accuracy: 0.2920 - val_loss: 2.6474 - val_accuracy: 0.0781\n",
            "Epoch 305/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 2.3169 - accuracy: 0.2965 - val_loss: 2.6444 - val_accuracy: 0.1094\n",
            "Epoch 306/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 2.3606 - accuracy: 0.2876 - val_loss: 2.6456 - val_accuracy: 0.1094\n",
            "Epoch 307/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 2.3511 - accuracy: 0.2611 - val_loss: 2.7040 - val_accuracy: 0.0781\n",
            "Epoch 308/500\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 2.3471 - accuracy: 0.2566 - val_loss: 2.6715 - val_accuracy: 0.0938\n",
            "Epoch 309/500\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 2.3345 - accuracy: 0.2788 - val_loss: 2.6644 - val_accuracy: 0.0781\n",
            "Epoch 310/500\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 2.3190 - accuracy: 0.3097 - val_loss: 2.6829 - val_accuracy: 0.0781\n",
            "Epoch 311/500\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 2.2942 - accuracy: 0.2876 - val_loss: 2.6749 - val_accuracy: 0.1562\n",
            "Epoch 312/500\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 2.3395 - accuracy: 0.2655 - val_loss: 2.6809 - val_accuracy: 0.1406\n",
            "Epoch 313/500\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 2.3021 - accuracy: 0.2832 - val_loss: 2.7136 - val_accuracy: 0.1406\n",
            "Epoch 314/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 2.3143 - accuracy: 0.2743 - val_loss: 2.6844 - val_accuracy: 0.1250\n",
            "Epoch 315/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 2.2768 - accuracy: 0.3186 - val_loss: 2.6646 - val_accuracy: 0.1094\n",
            "Epoch 316/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 2.2829 - accuracy: 0.2788 - val_loss: 2.6881 - val_accuracy: 0.0938\n",
            "Epoch 317/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 2.3126 - accuracy: 0.2876 - val_loss: 2.8813 - val_accuracy: 0.1094\n",
            "Epoch 318/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 2.3027 - accuracy: 0.2743 - val_loss: 2.7041 - val_accuracy: 0.1250\n",
            "Epoch 319/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 2.3097 - accuracy: 0.2743 - val_loss: 2.7428 - val_accuracy: 0.1250\n",
            "Epoch 320/500\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 2.2610 - accuracy: 0.3009 - val_loss: 2.6698 - val_accuracy: 0.0938\n",
            "Epoch 321/500\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 2.3043 - accuracy: 0.2611 - val_loss: 2.7388 - val_accuracy: 0.1094\n",
            "Epoch 322/500\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 2.2292 - accuracy: 0.3009 - val_loss: 2.7604 - val_accuracy: 0.0781\n",
            "Epoch 323/500\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 2.2479 - accuracy: 0.3053 - val_loss: 2.7217 - val_accuracy: 0.0938\n",
            "Epoch 324/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 2.2389 - accuracy: 0.3053 - val_loss: 2.7797 - val_accuracy: 0.0938\n",
            "Epoch 325/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 2.2330 - accuracy: 0.3053 - val_loss: 2.7121 - val_accuracy: 0.1094\n",
            "Epoch 326/500\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 2.2237 - accuracy: 0.3186 - val_loss: 2.7201 - val_accuracy: 0.0938\n",
            "Epoch 327/500\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 2.1935 - accuracy: 0.3407 - val_loss: 2.7616 - val_accuracy: 0.0781\n",
            "Epoch 328/500\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 2.2143 - accuracy: 0.2832 - val_loss: 2.7480 - val_accuracy: 0.0781\n",
            "Epoch 329/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 2.1942 - accuracy: 0.3274 - val_loss: 2.7816 - val_accuracy: 0.1250\n",
            "Epoch 330/500\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 2.1930 - accuracy: 0.3142 - val_loss: 2.7667 - val_accuracy: 0.0781\n",
            "Epoch 331/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 2.3056 - accuracy: 0.2478 - val_loss: 2.7499 - val_accuracy: 0.0781\n",
            "Epoch 332/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 2.1894 - accuracy: 0.3009 - val_loss: 2.7721 - val_accuracy: 0.1094\n",
            "Epoch 333/500\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 2.1893 - accuracy: 0.3230 - val_loss: 2.9134 - val_accuracy: 0.1250\n",
            "Epoch 334/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 2.1813 - accuracy: 0.3142 - val_loss: 2.8125 - val_accuracy: 0.1094\n",
            "Epoch 335/500\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 2.1800 - accuracy: 0.3009 - val_loss: 2.7518 - val_accuracy: 0.0781\n",
            "Epoch 336/500\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 2.1605 - accuracy: 0.2965 - val_loss: 2.8271 - val_accuracy: 0.0625\n",
            "Epoch 337/500\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 2.2022 - accuracy: 0.2832 - val_loss: 2.8227 - val_accuracy: 0.0781\n",
            "Epoch 338/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 2.1909 - accuracy: 0.2965 - val_loss: 2.8213 - val_accuracy: 0.0938\n",
            "Epoch 339/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 2.1424 - accuracy: 0.3142 - val_loss: 2.7844 - val_accuracy: 0.0625\n",
            "Epoch 340/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 2.1633 - accuracy: 0.3053 - val_loss: 2.8199 - val_accuracy: 0.0781\n",
            "Epoch 341/500\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 2.1515 - accuracy: 0.3053 - val_loss: 2.8531 - val_accuracy: 0.0781\n",
            "Epoch 342/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 2.1206 - accuracy: 0.3186 - val_loss: 2.8058 - val_accuracy: 0.1094\n",
            "Epoch 343/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 2.1273 - accuracy: 0.3097 - val_loss: 2.8762 - val_accuracy: 0.0781\n",
            "Epoch 344/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 2.1416 - accuracy: 0.2920 - val_loss: 2.7854 - val_accuracy: 0.0938\n",
            "Epoch 345/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 2.1454 - accuracy: 0.2876 - val_loss: 2.7876 - val_accuracy: 0.0781\n",
            "Epoch 346/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 2.1368 - accuracy: 0.3142 - val_loss: 2.8652 - val_accuracy: 0.1250\n",
            "Epoch 347/500\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 2.1361 - accuracy: 0.3053 - val_loss: 2.9241 - val_accuracy: 0.1094\n",
            "Epoch 348/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 2.1340 - accuracy: 0.3186 - val_loss: 2.7709 - val_accuracy: 0.0938\n",
            "Epoch 349/500\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 2.1006 - accuracy: 0.3186 - val_loss: 2.7761 - val_accuracy: 0.0781\n",
            "Epoch 350/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 2.0872 - accuracy: 0.3274 - val_loss: 2.8429 - val_accuracy: 0.0938\n",
            "Epoch 351/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 2.0958 - accuracy: 0.3274 - val_loss: 2.8125 - val_accuracy: 0.1094\n",
            "Epoch 352/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 2.0939 - accuracy: 0.3097 - val_loss: 2.8519 - val_accuracy: 0.0625\n",
            "Epoch 353/500\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 2.0948 - accuracy: 0.3186 - val_loss: 2.8749 - val_accuracy: 0.0781\n",
            "Epoch 354/500\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 2.0814 - accuracy: 0.3186 - val_loss: 2.9416 - val_accuracy: 0.1406\n",
            "Epoch 355/500\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 2.0892 - accuracy: 0.3097 - val_loss: 2.8639 - val_accuracy: 0.0938\n",
            "Epoch 356/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 2.0642 - accuracy: 0.3053 - val_loss: 3.0910 - val_accuracy: 0.0781\n",
            "Epoch 357/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 2.0932 - accuracy: 0.3009 - val_loss: 2.8165 - val_accuracy: 0.0781\n",
            "Epoch 358/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 2.0594 - accuracy: 0.3142 - val_loss: 2.8936 - val_accuracy: 0.1406\n",
            "Epoch 359/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 2.1016 - accuracy: 0.2920 - val_loss: 2.8375 - val_accuracy: 0.0781\n",
            "Epoch 360/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 2.0140 - accuracy: 0.3230 - val_loss: 2.7766 - val_accuracy: 0.1406\n",
            "Epoch 361/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 2.0727 - accuracy: 0.3097 - val_loss: 2.8195 - val_accuracy: 0.0938\n",
            "Epoch 362/500\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 2.0213 - accuracy: 0.3097 - val_loss: 2.7837 - val_accuracy: 0.0938\n",
            "Epoch 363/500\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 2.0426 - accuracy: 0.3230 - val_loss: 2.8191 - val_accuracy: 0.1250\n",
            "Epoch 364/500\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 2.0277 - accuracy: 0.3142 - val_loss: 3.6205 - val_accuracy: 0.0938\n",
            "Epoch 365/500\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 2.0573 - accuracy: 0.3009 - val_loss: 2.7905 - val_accuracy: 0.0469\n",
            "Epoch 366/500\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 2.0224 - accuracy: 0.3097 - val_loss: 2.9258 - val_accuracy: 0.0938\n",
            "Epoch 367/500\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 2.0149 - accuracy: 0.3186 - val_loss: 2.8396 - val_accuracy: 0.0781\n",
            "Epoch 368/500\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 1.9633 - accuracy: 0.3319 - val_loss: 2.8336 - val_accuracy: 0.0938\n",
            "Epoch 369/500\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 1.9609 - accuracy: 0.3186 - val_loss: 2.8115 - val_accuracy: 0.0938\n",
            "Epoch 370/500\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 2.0013 - accuracy: 0.3142 - val_loss: 2.9116 - val_accuracy: 0.1094\n",
            "Epoch 371/500\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 2.0220 - accuracy: 0.3009 - val_loss: 2.7645 - val_accuracy: 0.1250\n",
            "Epoch 372/500\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 1.9817 - accuracy: 0.3496 - val_loss: 2.8453 - val_accuracy: 0.0938\n",
            "Epoch 373/500\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 1.9588 - accuracy: 0.3274 - val_loss: 2.9266 - val_accuracy: 0.1250\n",
            "Epoch 374/500\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 1.9984 - accuracy: 0.3142 - val_loss: 2.9957 - val_accuracy: 0.0625\n",
            "Epoch 375/500\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 2.0075 - accuracy: 0.3319 - val_loss: 2.8829 - val_accuracy: 0.0781\n",
            "Epoch 376/500\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 1.9560 - accuracy: 0.3319 - val_loss: 2.8487 - val_accuracy: 0.1250\n",
            "Epoch 377/500\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 1.9501 - accuracy: 0.3496 - val_loss: 2.8225 - val_accuracy: 0.1094\n",
            "Epoch 378/500\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 1.9302 - accuracy: 0.3274 - val_loss: 2.8048 - val_accuracy: 0.0781\n",
            "Epoch 379/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 1.9686 - accuracy: 0.3142 - val_loss: 2.8541 - val_accuracy: 0.0938\n",
            "Epoch 380/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 1.9447 - accuracy: 0.3142 - val_loss: 2.8449 - val_accuracy: 0.0781\n",
            "Epoch 381/500\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 1.9726 - accuracy: 0.3142 - val_loss: 2.9393 - val_accuracy: 0.0781\n",
            "Epoch 382/500\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 1.9893 - accuracy: 0.3053 - val_loss: 2.8991 - val_accuracy: 0.0938\n",
            "Epoch 383/500\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 1.8972 - accuracy: 0.3496 - val_loss: 2.8458 - val_accuracy: 0.1094\n",
            "Epoch 384/500\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 1.9175 - accuracy: 0.3274 - val_loss: 2.8652 - val_accuracy: 0.1250\n",
            "Epoch 385/500\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 1.9202 - accuracy: 0.3451 - val_loss: 2.7997 - val_accuracy: 0.0938\n",
            "Epoch 386/500\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 1.9862 - accuracy: 0.3230 - val_loss: 2.8701 - val_accuracy: 0.1094\n",
            "Epoch 387/500\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 1.9251 - accuracy: 0.3274 - val_loss: 2.9406 - val_accuracy: 0.0781\n",
            "Epoch 388/500\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 1.9146 - accuracy: 0.3319 - val_loss: 2.8049 - val_accuracy: 0.0781\n",
            "Epoch 389/500\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 1.8940 - accuracy: 0.3407 - val_loss: 2.8674 - val_accuracy: 0.1406\n",
            "Epoch 390/500\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 1.9278 - accuracy: 0.3274 - val_loss: 2.8469 - val_accuracy: 0.0938\n",
            "Epoch 391/500\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 1.9502 - accuracy: 0.3142 - val_loss: 2.7941 - val_accuracy: 0.0625\n",
            "Epoch 392/500\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 1.8739 - accuracy: 0.3540 - val_loss: 2.8644 - val_accuracy: 0.0625\n",
            "Epoch 393/500\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 1.8760 - accuracy: 0.3451 - val_loss: 2.9198 - val_accuracy: 0.0938\n",
            "Epoch 394/500\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 1.8811 - accuracy: 0.3230 - val_loss: 2.8798 - val_accuracy: 0.1094\n",
            "Epoch 395/500\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 1.8592 - accuracy: 0.3363 - val_loss: 2.8756 - val_accuracy: 0.0938\n",
            "Epoch 396/500\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 1.9072 - accuracy: 0.3274 - val_loss: 2.8332 - val_accuracy: 0.1250\n",
            "Epoch 397/500\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 1.8502 - accuracy: 0.3407 - val_loss: 2.8344 - val_accuracy: 0.0781\n",
            "Epoch 398/500\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 1.8619 - accuracy: 0.3451 - val_loss: 2.8747 - val_accuracy: 0.1094\n",
            "Epoch 399/500\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 1.9781 - accuracy: 0.3274 - val_loss: 2.9247 - val_accuracy: 0.1406\n",
            "Epoch 400/500\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 1.8985 - accuracy: 0.3363 - val_loss: 2.9778 - val_accuracy: 0.0938\n",
            "Epoch 401/500\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 1.8407 - accuracy: 0.3407 - val_loss: 2.7750 - val_accuracy: 0.1250\n",
            "Epoch 402/500\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 1.9124 - accuracy: 0.3186 - val_loss: 3.3251 - val_accuracy: 0.1094\n",
            "Epoch 403/500\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 1.8604 - accuracy: 0.3363 - val_loss: 2.8830 - val_accuracy: 0.0781\n",
            "Epoch 404/500\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 1.8167 - accuracy: 0.3540 - val_loss: 3.0301 - val_accuracy: 0.1250\n",
            "Epoch 405/500\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 1.8663 - accuracy: 0.3540 - val_loss: 2.8696 - val_accuracy: 0.1094\n",
            "Epoch 406/500\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 1.8753 - accuracy: 0.3451 - val_loss: 2.9049 - val_accuracy: 0.1250\n",
            "Epoch 407/500\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 1.8709 - accuracy: 0.3584 - val_loss: 2.8877 - val_accuracy: 0.1250\n",
            "Epoch 408/500\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 1.8058 - accuracy: 0.3363 - val_loss: 2.8799 - val_accuracy: 0.0625\n",
            "Epoch 409/500\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 1.8143 - accuracy: 0.3761 - val_loss: 3.0166 - val_accuracy: 0.1250\n",
            "Epoch 410/500\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 1.8652 - accuracy: 0.3407 - val_loss: 2.9518 - val_accuracy: 0.0625\n",
            "Epoch 411/500\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 1.8130 - accuracy: 0.3717 - val_loss: 2.8913 - val_accuracy: 0.0781\n",
            "Epoch 412/500\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 1.7952 - accuracy: 0.3319 - val_loss: 2.9038 - val_accuracy: 0.0781\n",
            "Epoch 413/500\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 1.8019 - accuracy: 0.3407 - val_loss: 2.9778 - val_accuracy: 0.0938\n",
            "Epoch 414/500\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 1.8414 - accuracy: 0.3274 - val_loss: 2.9096 - val_accuracy: 0.0938\n",
            "Epoch 415/500\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 1.7621 - accuracy: 0.3673 - val_loss: 2.9561 - val_accuracy: 0.1094\n",
            "Epoch 416/500\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 1.8435 - accuracy: 0.3363 - val_loss: 2.9301 - val_accuracy: 0.1250\n",
            "Epoch 417/500\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 1.8022 - accuracy: 0.3540 - val_loss: 3.0287 - val_accuracy: 0.0781\n",
            "Epoch 418/500\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 1.7673 - accuracy: 0.3673 - val_loss: 2.8544 - val_accuracy: 0.1250\n",
            "Epoch 419/500\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 1.8410 - accuracy: 0.3496 - val_loss: 2.8903 - val_accuracy: 0.1250\n",
            "Epoch 420/500\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 1.7747 - accuracy: 0.3496 - val_loss: 2.8987 - val_accuracy: 0.0938\n",
            "Epoch 421/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 1.7989 - accuracy: 0.3761 - val_loss: 2.9299 - val_accuracy: 0.1094\n",
            "Epoch 422/500\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 1.7720 - accuracy: 0.3540 - val_loss: 2.8487 - val_accuracy: 0.0938\n",
            "Epoch 423/500\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 1.7752 - accuracy: 0.3805 - val_loss: 2.9350 - val_accuracy: 0.1406\n",
            "Epoch 424/500\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 1.8058 - accuracy: 0.3451 - val_loss: 2.9350 - val_accuracy: 0.0781\n",
            "Epoch 425/500\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 1.8076 - accuracy: 0.3540 - val_loss: 2.9190 - val_accuracy: 0.1250\n",
            "Epoch 426/500\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 1.7304 - accuracy: 0.3673 - val_loss: 2.8734 - val_accuracy: 0.1562\n",
            "Epoch 427/500\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 1.8057 - accuracy: 0.3496 - val_loss: 2.9144 - val_accuracy: 0.0938\n",
            "Epoch 428/500\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 1.7820 - accuracy: 0.3584 - val_loss: 2.9324 - val_accuracy: 0.1250\n",
            "Epoch 429/500\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 1.7282 - accuracy: 0.3894 - val_loss: 2.9183 - val_accuracy: 0.1094\n",
            "Epoch 430/500\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 1.7756 - accuracy: 0.3850 - val_loss: 2.9054 - val_accuracy: 0.1250\n",
            "Epoch 431/500\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 1.7358 - accuracy: 0.3805 - val_loss: 2.8454 - val_accuracy: 0.0938\n",
            "Epoch 432/500\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 1.7245 - accuracy: 0.4204 - val_loss: 2.9668 - val_accuracy: 0.1094\n",
            "Epoch 433/500\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 1.7259 - accuracy: 0.3673 - val_loss: 3.0985 - val_accuracy: 0.0938\n",
            "Epoch 434/500\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 1.7296 - accuracy: 0.3717 - val_loss: 2.9327 - val_accuracy: 0.0781\n",
            "Epoch 435/500\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 1.7189 - accuracy: 0.3894 - val_loss: 2.9862 - val_accuracy: 0.0781\n",
            "Epoch 436/500\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 1.6984 - accuracy: 0.3805 - val_loss: 3.0922 - val_accuracy: 0.1250\n",
            "Epoch 437/500\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 1.7885 - accuracy: 0.3805 - val_loss: 2.9959 - val_accuracy: 0.1094\n",
            "Epoch 438/500\n",
            "5/5 [==============================] - 0s 45ms/step - loss: 1.7720 - accuracy: 0.3628 - val_loss: 2.9115 - val_accuracy: 0.1094\n",
            "Epoch 439/500\n",
            "5/5 [==============================] - 0s 45ms/step - loss: 1.6888 - accuracy: 0.3982 - val_loss: 2.9530 - val_accuracy: 0.0625\n",
            "Epoch 440/500\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 1.7198 - accuracy: 0.3673 - val_loss: 3.0967 - val_accuracy: 0.1406\n",
            "Epoch 441/500\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 1.7273 - accuracy: 0.3717 - val_loss: 3.0206 - val_accuracy: 0.0938\n",
            "Epoch 442/500\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 1.7113 - accuracy: 0.3850 - val_loss: 3.0107 - val_accuracy: 0.0938\n",
            "Epoch 443/500\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 1.6891 - accuracy: 0.3761 - val_loss: 2.8966 - val_accuracy: 0.1406\n",
            "Epoch 444/500\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 1.7679 - accuracy: 0.3717 - val_loss: 3.0621 - val_accuracy: 0.0938\n",
            "Epoch 445/500\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 1.6898 - accuracy: 0.4027 - val_loss: 2.9179 - val_accuracy: 0.1250\n",
            "Epoch 446/500\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 1.7416 - accuracy: 0.3673 - val_loss: 3.0612 - val_accuracy: 0.1094\n",
            "Epoch 447/500\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 1.6946 - accuracy: 0.3938 - val_loss: 2.9461 - val_accuracy: 0.1250\n",
            "Epoch 448/500\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 1.7213 - accuracy: 0.3584 - val_loss: 3.0188 - val_accuracy: 0.1094\n",
            "Epoch 449/500\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 1.6851 - accuracy: 0.3982 - val_loss: 2.9614 - val_accuracy: 0.0781\n",
            "Epoch 450/500\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 1.7061 - accuracy: 0.3982 - val_loss: 3.0455 - val_accuracy: 0.0938\n",
            "Epoch 451/500\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 1.6851 - accuracy: 0.3805 - val_loss: 2.9574 - val_accuracy: 0.1094\n",
            "Epoch 452/500\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 1.6402 - accuracy: 0.4204 - val_loss: 2.9825 - val_accuracy: 0.1250\n",
            "Epoch 453/500\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 1.6692 - accuracy: 0.3982 - val_loss: 3.0360 - val_accuracy: 0.0938\n",
            "Epoch 454/500\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 1.6436 - accuracy: 0.3982 - val_loss: 3.0310 - val_accuracy: 0.1094\n",
            "Epoch 455/500\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 1.6283 - accuracy: 0.3805 - val_loss: 2.9627 - val_accuracy: 0.1094\n",
            "Epoch 456/500\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 1.6712 - accuracy: 0.3982 - val_loss: 2.8869 - val_accuracy: 0.1406\n",
            "Epoch 457/500\n",
            "5/5 [==============================] - 0s 45ms/step - loss: 1.7118 - accuracy: 0.3673 - val_loss: 2.9580 - val_accuracy: 0.1250\n",
            "Epoch 458/500\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 1.6588 - accuracy: 0.4159 - val_loss: 2.9762 - val_accuracy: 0.0938\n",
            "Epoch 459/500\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 1.6191 - accuracy: 0.4027 - val_loss: 3.0313 - val_accuracy: 0.1250\n",
            "Epoch 460/500\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 1.6406 - accuracy: 0.4071 - val_loss: 2.9557 - val_accuracy: 0.1094\n",
            "Epoch 461/500\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 1.7320 - accuracy: 0.3540 - val_loss: 3.1159 - val_accuracy: 0.1094\n",
            "Epoch 462/500\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 1.6341 - accuracy: 0.4248 - val_loss: 3.1247 - val_accuracy: 0.1250\n",
            "Epoch 463/500\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 1.6397 - accuracy: 0.3938 - val_loss: 2.9444 - val_accuracy: 0.1094\n",
            "Epoch 464/500\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 1.6394 - accuracy: 0.4071 - val_loss: 2.9419 - val_accuracy: 0.1094\n",
            "Epoch 465/500\n",
            "5/5 [==============================] - 0s 45ms/step - loss: 1.6105 - accuracy: 0.4115 - val_loss: 2.9460 - val_accuracy: 0.0938\n",
            "Epoch 466/500\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 1.5998 - accuracy: 0.3850 - val_loss: 3.1254 - val_accuracy: 0.0938\n",
            "Epoch 467/500\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 1.7373 - accuracy: 0.3363 - val_loss: 2.9962 - val_accuracy: 0.0938\n",
            "Epoch 468/500\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 1.6020 - accuracy: 0.4204 - val_loss: 3.0004 - val_accuracy: 0.0938\n",
            "Epoch 469/500\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 1.6208 - accuracy: 0.3805 - val_loss: 3.1116 - val_accuracy: 0.0781\n",
            "Epoch 470/500\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 1.5840 - accuracy: 0.4115 - val_loss: 3.0185 - val_accuracy: 0.1406\n",
            "Epoch 471/500\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 1.7465 - accuracy: 0.3761 - val_loss: 3.0480 - val_accuracy: 0.1406\n",
            "Epoch 472/500\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 1.6387 - accuracy: 0.3717 - val_loss: 2.9677 - val_accuracy: 0.0938\n",
            "Epoch 473/500\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 1.5988 - accuracy: 0.3982 - val_loss: 3.1314 - val_accuracy: 0.1406\n",
            "Epoch 474/500\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 1.5836 - accuracy: 0.3938 - val_loss: 2.9078 - val_accuracy: 0.1250\n",
            "Epoch 475/500\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 1.6126 - accuracy: 0.3938 - val_loss: 3.0437 - val_accuracy: 0.1094\n",
            "Epoch 476/500\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 1.6057 - accuracy: 0.4071 - val_loss: 3.0891 - val_accuracy: 0.0938\n",
            "Epoch 477/500\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 1.6762 - accuracy: 0.3938 - val_loss: 3.0462 - val_accuracy: 0.0781\n",
            "Epoch 478/500\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 1.5968 - accuracy: 0.3938 - val_loss: 3.1121 - val_accuracy: 0.0938\n",
            "Epoch 479/500\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 1.6118 - accuracy: 0.4115 - val_loss: 3.0964 - val_accuracy: 0.0938\n",
            "Epoch 480/500\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 1.5960 - accuracy: 0.4115 - val_loss: 3.0871 - val_accuracy: 0.0938\n",
            "Epoch 481/500\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 1.5728 - accuracy: 0.4115 - val_loss: 2.9922 - val_accuracy: 0.1562\n",
            "Epoch 482/500\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 1.6379 - accuracy: 0.4027 - val_loss: 3.2486 - val_accuracy: 0.1094\n",
            "Epoch 483/500\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 1.6183 - accuracy: 0.4159 - val_loss: 2.9701 - val_accuracy: 0.1094\n",
            "Epoch 484/500\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 1.6286 - accuracy: 0.4071 - val_loss: 3.0457 - val_accuracy: 0.0781\n",
            "Epoch 485/500\n",
            "5/5 [==============================] - 0s 45ms/step - loss: 1.5498 - accuracy: 0.4425 - val_loss: 3.1160 - val_accuracy: 0.1406\n",
            "Epoch 486/500\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 1.5742 - accuracy: 0.4159 - val_loss: 3.0687 - val_accuracy: 0.1250\n",
            "Epoch 487/500\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 1.5390 - accuracy: 0.4292 - val_loss: 3.0538 - val_accuracy: 0.1094\n",
            "Epoch 488/500\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 1.5735 - accuracy: 0.4248 - val_loss: 3.1382 - val_accuracy: 0.0938\n",
            "Epoch 489/500\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 1.5520 - accuracy: 0.4292 - val_loss: 3.1842 - val_accuracy: 0.0781\n",
            "Epoch 490/500\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 1.6280 - accuracy: 0.4027 - val_loss: 3.0213 - val_accuracy: 0.0938\n",
            "Epoch 491/500\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 1.5324 - accuracy: 0.4292 - val_loss: 3.2221 - val_accuracy: 0.0938\n",
            "Epoch 492/500\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 1.6045 - accuracy: 0.4071 - val_loss: 3.0281 - val_accuracy: 0.1250\n",
            "Epoch 493/500\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 1.7021 - accuracy: 0.3982 - val_loss: 3.0874 - val_accuracy: 0.1250\n",
            "Epoch 494/500\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 1.5292 - accuracy: 0.4513 - val_loss: 3.0488 - val_accuracy: 0.1250\n",
            "Epoch 495/500\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 1.5077 - accuracy: 0.4469 - val_loss: 3.1936 - val_accuracy: 0.1094\n",
            "Epoch 496/500\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 1.5639 - accuracy: 0.4425 - val_loss: 3.3461 - val_accuracy: 0.1250\n",
            "Epoch 497/500\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 1.5541 - accuracy: 0.4292 - val_loss: 3.1328 - val_accuracy: 0.0938\n",
            "Epoch 498/500\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 1.4990 - accuracy: 0.4425 - val_loss: 3.0682 - val_accuracy: 0.1406\n",
            "Epoch 499/500\n",
            "5/5 [==============================] - 0s 45ms/step - loss: 1.5765 - accuracy: 0.4071 - val_loss: 3.1422 - val_accuracy: 0.0938\n",
            "Epoch 500/500\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 1.5760 - accuracy: 0.4336 - val_loss: 3.0406 - val_accuracy: 0.1094\n"
          ]
        }
      ],
      "source": [
        "pruningcallback_4=PruningCallback(init_step=100, end_step=250,\n",
        "                                init_sparsity=0.4, end_sparsity=0.95,pruning_step=5)\n",
        "tf.random.set_seed(1234)\n",
        "hist_p_4=model_to_prune_4.fit(X_train_50.reshape(-1,dim_50[0],dim_50[0],3), y_train, \n",
        "                     batch_size=50, epochs=500,\n",
        "                     callbacks=[pruningcallback_4],\n",
        "                     validation_data=(X_test_50.reshape(-1,dim_50[0],dim_50[0],3),y_test),verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "omxT4tj3lYld",
        "outputId": "cfb0846c-653b-4102-88b4-a600317fb274",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(3, 3, 3, 15)\n",
            "-3.5597796 0.0\n",
            "(3, 3, 15, 31)\n",
            "-4.2089963 0.0\n",
            "(3, 3, 31, 47)\n",
            "-12.879557 0.0\n",
            "(3, 3, 47, 63)\n",
            "-55.139633 0.0\n",
            "(3, 3, 3, 12)\n",
            "-4.0412245 0.0\n",
            "(3, 3, 12, 25)\n",
            "-3.062991 0.0\n",
            "(3, 3, 25, 38)\n",
            "-10.902722 0.0\n",
            "(3, 3, 38, 51)\n",
            "-42.384537 0.0\n",
            "(3, 3, 3, 9)\n",
            "-3.0295405 0.0\n",
            "(3, 3, 9, 19)\n",
            "-4.071889 0.0\n",
            "(3, 3, 19, 28)\n",
            "-7.494157 0.0\n",
            "(3, 3, 28, 38)\n",
            "-26.545746 0.0\n",
            "(3, 3, 3, 6)\n",
            "-2.5146465 0.0\n",
            "(3, 3, 6, 12)\n",
            "-2.656652 0.0\n",
            "(3, 3, 12, 19)\n",
            "-5.752376 0.0\n",
            "(3, 3, 19, 25)\n",
            "-16.011307 0.0\n",
            "(3, 3, 3, 3)\n",
            "-3.4244688 0.0\n",
            "(3, 3, 3, 6)\n",
            "-0.2145229 0.0\n",
            "(3, 3, 6, 9)\n",
            "-5.5826225 0.0\n",
            "(3, 3, 9, 12)\n",
            "-2.581008 0.0\n"
          ]
        }
      ],
      "source": [
        "new_pruned_model_0=pruningcallback_0.get_thinner_model()\n",
        "new_pruned_model_1=pruningcallback_1.get_thinner_model()\n",
        "new_pruned_model_2=pruningcallback_2.get_thinner_model()\n",
        "new_pruned_model_3=pruningcallback_3.get_thinner_model()\n",
        "new_pruned_model_4=pruningcallback_4.get_thinner_model()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "The \"get_thinner_model()\" function is a method provided by the TensorFlow Model \n",
        "Pruning library, it returns a new version of the model with the pruned layers.\n",
        "The new pruned models are smaller in size and have fewer parameters, as some of \n",
        "the neurons in the original model were removed during the pruning process.\n",
        "\n",
        "\"\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0UDO6Qidyle2",
        "outputId": "8b2f2484-ae5f-4ba6-a2d7-e4a1938ab578",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2/2 [==============================] - 0s 11ms/step - loss: 2.1618 - accuracy: 0.3281\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 2.2788 - accuracy: 0.2969\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 2.6440 - accuracy: 0.1719\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 2.5994 - accuracy: 0.2344\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 3.1221 - accuracy: 0.1094\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 3.0462 - accuracy: 0.1094\n",
            "\n",
            "\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 2.5772 - accuracy: 0.2969\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 2.8514 - accuracy: 0.1719\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 2.7325 - accuracy: 0.2344\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:5 out of the last 1019 calls to <function Model.make_test_function.<locals>.test_function at 0x7f93f6248dc0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2/2 [==============================] - 0s 7ms/step - loss: 3.2073 - accuracy: 0.1094\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:6 out of the last 1021 calls to <function Model.make_test_function.<locals>.test_function at 0x7f93f652a550> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2/2 [==============================] - 0s 9ms/step - loss: 3.0925 - accuracy: 0.1094\n"
          ]
        }
      ],
      "source": [
        "score=model_simple.evaluate(X_test_50.reshape(-1,dim_50[0],dim_50[0],3), y_test)\n",
        "score=model_to_prune_0.evaluate(X_test_50.reshape(-1,dim_50[0],dim_50[0],3), y_test)\n",
        "score=model_to_prune_1.evaluate(X_test_50.reshape(-1,dim_50[0],dim_50[0],3), y_test)\n",
        "score=model_to_prune_2.evaluate(X_test_50.reshape(-1,dim_50[0],dim_50[0],3), y_test)\n",
        "score=model_to_prune_3.evaluate(X_test_50.reshape(-1,dim_50[0],dim_50[0],3), y_test)\n",
        "score=model_to_prune_4.evaluate(X_test_50.reshape(-1,dim_50[0],dim_50[0],3), y_test)\n",
        "print(\"\\n\")\n",
        "score=new_pruned_model_0.evaluate(X_test_50.reshape(-1,dim_50[0],dim_50[0],3), y_test)\n",
        "score=new_pruned_model_1.evaluate(X_test_50.reshape(-1,dim_50[0],dim_50[0],3), y_test)\n",
        "score=new_pruned_model_2.evaluate(X_test_50.reshape(-1,dim_50[0],dim_50[0],3), y_test)\n",
        "score=new_pruned_model_3.evaluate(X_test_50.reshape(-1,dim_50[0],dim_50[0],3), y_test)\n",
        "score=new_pruned_model_4.evaluate(X_test_50.reshape(-1,dim_50[0],dim_50[0],3), y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 551
        },
        "id": "-CSg8dROmM79",
        "outputId": "5e0a7257-a4e5-48b9-9789-73212d476e37",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': [2.8276913166046143, 2.0351076126098633, 1.5675456523895264, 1.2044334411621094, 0.9520672559738159, 0.787437915802002, 0.593935489654541, 0.4812377691268921, 0.41255977749824524, 0.34856298565864563, 0.28841471672058105, 0.24759437143802643, 0.213842511177063, 0.19148659706115723, 0.1679050177335739, 0.14987076818943024, 0.138986736536026, 0.12677747011184692, 0.11938400566577911, 0.10496050119400024, 0.09602716565132141, 0.09260571002960205, 0.08736848086118698, 0.08437823504209518, 0.07768025994300842, 0.07066547870635986, 0.06839131563901901, 0.06358873844146729, 0.06354433298110962, 0.05978238210082054, 0.059423722326755524, 0.057765450328588486, 0.05379537492990494, 0.053133223205804825, 0.04871766269207001, 0.04708335921168327, 0.043373867869377136, 0.044284313917160034, 0.043722428381443024, 0.04145725816488266, 0.04363059252500534, 0.038445547223091125, 0.037104543298482895, 0.03705567866563797, 0.035780929028987885, 0.03452225774526596, 0.03430408611893654, 0.03264651820063591, 0.0325213186442852, 0.03143438696861267, 0.031043829396367073, 0.029706507921218872, 0.02867250144481659, 0.028844162821769714, 0.027830876410007477, 0.026760844513773918, 0.026688093319535255, 0.0260862335562706, 0.029214639216661453, 0.025035109370946884, 0.02671424113214016, 0.02522152103483677, 0.02442355640232563, 0.02483368292450905, 0.023192869499325752, 0.022368907928466797, 0.022079600021243095, 0.022112255915999413, 0.02138243056833744, 0.02284831739962101, 0.020841877907514572, 0.02066374383866787, 0.019674791023135185, 0.019622335210442543, 0.01903909258544445, 0.020134372636675835, 0.018899058923125267, 0.018993820995092392, 0.01777871511876583, 0.017336750403046608, 0.017175445333123207, 0.016812585294246674, 0.01752142235636711, 0.0167679563164711, 0.01740177348256111, 0.016245855018496513, 0.01615152508020401, 0.016404347494244576, 0.016086697578430176, 0.015296947211027145, 0.015336110256612301, 0.015686195343732834, 0.01508205384016037, 0.014886153861880302, 0.014624282717704773, 0.014369106851518154, 0.014426172710955143, 0.014320120215415955, 0.014638876542448997, 0.014196335338056087, 0.013919168151915073, 2.294860601425171, 1.9131451845169067, 1.653092384338379, 1.4477226734161377, 1.3040499687194824, 1.1675233840942383, 1.0310543775558472, 0.9564248919487, 0.857237696647644, 0.7550536394119263, 1.1870622634887695, 0.986104428768158, 0.8446634411811829, 0.755027711391449, 0.6890566945075989, 0.625862181186676, 0.6028298139572144, 0.5148853063583374, 0.47350767254829407, 0.4307284951210022, 0.7050496339797974, 0.6050169467926025, 0.5363077521324158, 0.4851163327693939, 0.40393227338790894, 0.38788673281669617, 0.3411814272403717, 0.3149051070213318, 0.2981175184249878, 0.2735840678215027, 0.7609825730323792, 0.6679030060768127, 0.5112553238868713, 0.46202898025512695, 0.40412476658821106, 0.3520744740962982, 0.31924110651016235, 0.29822203516960144, 0.26775413751602173, 0.25843381881713867, 0.6194817423820496, 0.5257643461227417, 0.44487810134887695, 0.40404754877090454, 0.34564855694770813, 0.30802586674690247, 0.2860778272151947, 0.25525203347206116, 0.23808270692825317, 0.23615600168704987, 0.7243987321853638, 0.5527980923652649, 0.45810258388519287, 0.42909562587738037, 0.3517717123031616, 0.3051256835460663, 0.2694900333881378, 0.26079660654067993, 0.23271112143993378, 0.2131728082895279, 0.5633359551429749, 0.4279930889606476, 0.3923039436340332, 0.3563757836818695, 0.30396831035614014, 0.2651609480381012, 0.2632187604904175, 0.23375405371189117, 0.22612430155277252, 0.20513828098773956, 0.7615653276443481, 0.6074792146682739, 0.5377198457717896, 0.41924065351486206, 0.3521890640258789, 0.3177984654903412, 0.27717968821525574, 0.2478267401456833, 0.24080052971839905, 0.21410520374774933, 0.6041112542152405, 0.4490676820278168, 0.39545342326164246, 0.33923396468162537, 0.31157800555229187, 0.28976568579673767, 0.2583119869232178, 0.2488711029291153, 0.21226492524147034, 0.19688594341278076, 0.5017486810684204, 0.4261470139026642, 0.3440180718898773, 0.3221212327480316, 0.26707154512405396, 0.23127341270446777, 0.21879827976226807, 0.19170038402080536, 0.18314118683338165, 0.18371030688285828, 0.6645859479904175, 0.5176737904548645, 0.385457843542099, 0.3853590488433838, 0.31559082865715027, 0.2903847396373749, 0.26050153374671936, 0.24670153856277466, 0.21739692986011505, 0.2062961608171463, 0.8874725699424744, 0.6470293998718262, 0.5867456197738647, 0.4395592510700226, 0.41114601492881775, 0.34741729497909546, 0.3117610514163971, 0.29090070724487305, 0.25984373688697815, 0.24295806884765625, 0.7384411096572876, 0.5942105054855347, 0.5426907539367676, 0.5180307030677795, 0.45461270213127136, 0.3736836612224579, 0.3361109495162964, 0.3145644962787628, 0.2822988033294678, 0.26534518599510193, 1.051261305809021, 0.8528631925582886, 0.6684758067131042, 0.6291685700416565, 0.527351438999176, 0.4653279185295105, 0.4399421513080597, 0.3988668918609619, 0.3824208676815033, 0.3223663568496704, 1.1626079082489014, 0.9085581302642822, 0.7368499040603638, 0.6174758076667786, 0.5919666886329651, 0.5185564160346985, 0.4765235185623169, 0.45828887820243835, 0.3818371593952179, 0.3503616452217102, 1.3004323244094849, 1.12511146068573, 0.9463400840759277, 0.8596933484077454, 0.8457120656967163, 0.7429801225662231, 0.631631076335907, 0.6052104234695435, 0.5550521016120911, 0.505184531211853, 0.4222480058670044, 0.418669730424881, 0.3698744773864746, 0.34968841075897217, 0.3417072594165802, 0.3035694360733032, 0.2763257622718811, 0.27089473605155945, 0.25583651661872864, 0.22941485047340393, 0.2324003428220749, 0.2067710906267166, 0.20532307028770447, 0.19699934124946594, 0.18650846183300018, 0.17702838778495789, 0.16359014809131622, 0.1688118278980255, 0.15180404484272003, 0.1487235724925995, 0.1387435495853424, 0.13159887492656708, 0.12725730240345, 0.12684252858161926, 0.12328747659921646, 0.12014852464199066, 0.11912219971418381, 0.10786939412355423, 0.10410727560520172, 0.1028241217136383, 0.09864946454763412, 0.0953594446182251, 0.09373507648706436, 0.09009958058595657, 0.08822377771139145, 0.0856700986623764, 0.08369719237089157, 0.08466137945652008, 0.07806529849767685, 0.08036179840564728, 0.08165358752012253, 0.07497791945934296, 0.06961553543806076, 0.06942781060934067, 0.06875909119844437, 0.07071185111999512, 0.06744996458292007, 0.06647615879774094, 0.0627342164516449, 0.06233466789126396, 0.06104069575667381, 0.06156038120388985, 0.062339942902326584, 0.05704773962497711, 0.06037328764796257, 0.05853096395730972, 0.055014271289110184, 0.05203605070710182, 0.05433410033583641, 0.052833735942840576, 0.05119325593113899, 0.049287308007478714, 0.04969390109181404, 0.04969951510429382, 0.050958216190338135, 0.04788874834775925, 0.04659270495176315, 0.046453893184661865, 0.04682300612330437, 0.046798866242170334, 0.04388684779405594, 0.04294123873114586, 0.04327631741762161, 0.04310150071978569, 0.041609570384025574, 0.040990784764289856, 0.04017556458711624, 0.039056748151779175, 0.04027416557073593, 0.03953878954052925, 0.039186958223581314, 0.03793257474899292, 0.038190748542547226, 0.036922041326761246, 0.03736201301217079, 0.036055319011211395, 0.03703419119119644, 0.03615378215909004, 0.03486296534538269, 0.034057337790727615, 0.03360067680478096, 0.034258659929037094, 0.03277112543582916, 0.03465881571173668, 0.03340254724025726, 0.03167536109685898, 0.03244232013821602, 0.031030911952257156, 0.03218556568026543, 0.032061658799648285, 0.03111978992819786, 0.02956501767039299, 0.029886702075600624, 0.028690796345472336, 0.029290463775396347, 0.02878662943840027, 0.02806895598769188, 0.028998762369155884, 0.027267612516880035, 0.027958175167441368, 0.027079986408352852, 0.028235305100679398, 0.02700711227953434, 0.027439052239060402, 0.027558360248804092, 0.026267103850841522, 0.02594502829015255, 0.02580474503338337, 0.025039779022336006, 0.02628934010863304, 0.02612178772687912, 0.02487759105861187, 0.02490691840648651, 0.024486856535077095, 0.0242434274405241, 0.023892151191830635, 0.023450391367077827, 0.02330176532268524, 0.02394137717783451, 0.0238824300467968, 0.024126263335347176, 0.022568045184016228, 0.02271861396729946, 0.02215319685637951, 0.02217094413936138, 0.022402163594961166, 0.02249436266720295, 0.022775869816541672, 0.022495033219456673, 0.0217762291431427, 0.02069501206278801, 0.02091660536825657, 0.020613783970475197, 0.021623121574521065, 0.020739367231726646, 0.021062511950731277, 0.02066558413207531, 0.02099432982504368, 0.019963394850492477, 0.0199784766882658, 0.02084456942975521, 0.019548799842596054, 0.019660932943224907, 0.019469309598207474, 0.020120887085795403, 0.01847088523209095, 0.01961367577314377, 0.019468842074275017, 0.018497813493013382, 0.01937507465481758, 0.01934773474931717, 0.019539915025234222, 0.017704268917441368, 0.01856647990643978, 0.017848186194896698, 0.01876498945057392, 0.018350515514612198, 0.017621291801333427, 0.017737485468387604, 0.017372630536556244, 0.01767212338745594, 0.01702716015279293, 0.01643584668636322, 0.017259418964385986, 0.01645016111433506, 0.016712656244635582, 0.01632857508957386, 0.01627829484641552, 0.01635970175266266, 0.016521738842129707, 0.01674615778028965, 0.016561882570385933, 0.017220165580511093, 0.015636388212442398, 0.016315868124365807, 0.016553299501538277, 0.015857381746172905, 0.015790030360221863, 0.015564009547233582, 0.01538631971925497, 0.014985631220042706, 0.015539023093879223, 0.015602641738951206, 0.015224793925881386, 0.014804269187152386, 0.014795184135437012, 0.015147969126701355, 0.01470014825463295, 0.014310726895928383, 0.015038570389151573, 0.01462077908217907, 0.014528502710163593, 0.014313378371298313, 0.014663816429674625, 0.014088965021073818, 0.015233464539051056, 0.013409540057182312, 0.014786256477236748, 0.014158395119011402, 0.014374845661222935, 0.013428403064608574, 0.013823277316987514, 0.01356205902993679, 0.014172835275530815, 0.014133871532976627, 0.01353604719042778, 0.01377369649708271, 0.013632697984576225, 0.013361027464270592, 0.012700376100838184, 0.013618513941764832, 0.013663464225828648, 0.01438932679593563, 0.012966020032763481, 0.012967834249138832, 0.012967974878847599, 0.012695190496742725, 0.01276946160942316, 0.012715833261609077, 0.01228475570678711, 0.01246662251651287, 0.012223933823406696, 0.012721654959022999, 0.01226066704839468, 0.012255781330168247, 0.012419544160366058, 0.01140652783215046, 0.01194019615650177, 0.011975930072367191], 'accuracy': [0.10176990926265717, 0.36283186078071594, 0.6238937973976135, 0.7831858396530151, 0.8938053250312805, 0.9247787594795227, 0.982300877571106, 0.982300877571106, 0.9955752491950989, 0.9955752491950989, 0.9955752491950989, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.2566371560096741, 0.47345131635665894, 0.6460176706314087, 0.730088472366333, 0.8185840845108032, 0.8849557638168335, 0.9336283206939697, 0.9247787594795227, 0.9469026327133179, 0.9734513163566589, 0.8938053250312805, 0.9115044474601746, 0.9690265655517578, 0.9778761267662048, 0.9778761267662048, 0.982300877571106, 0.991150438785553, 1.0, 1.0, 0.9955752491950989, 0.9867256879806519, 0.982300877571106, 1.0, 0.9955752491950989, 1.0, 0.9955752491950989, 1.0, 0.9955752491950989, 1.0, 1.0, 0.991150438785553, 0.9734513163566589, 1.0, 0.9955752491950989, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9955752491950989, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9867256879806519, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9690265655517578, 0.9867256879806519, 0.9955752491950989, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9955752491950989, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.991150438785553, 0.991150438785553, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9336283206939697, 0.9955752491950989, 0.982300877571106, 0.991150438785553, 0.9955752491950989, 1.0, 1.0, 1.0, 1.0, 1.0, 0.991150438785553, 0.982300877571106, 0.991150438785553, 1.0, 0.991150438785553, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8761062026023865, 0.9380530714988708, 0.9867256879806519, 0.9778761267662048, 1.0, 0.9955752491950989, 1.0, 1.0, 0.9955752491950989, 1.0, 0.8230088353157043, 0.9247787594795227, 0.9778761267662048, 0.982300877571106, 0.991150438785553, 0.991150438785553, 0.9955752491950989, 1.0, 1.0, 1.0, 0.76106196641922, 0.8495575189590454, 0.9159291982650757, 0.9336283206939697, 0.9247787594795227, 0.9646017551422119, 1.0, 1.0, 0.9955752491950989, 0.9955752491950989, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], 'val_loss': [2.6389150619506836, 2.642634630203247, 2.642807960510254, 2.6462767124176025, 2.6523149013519287, 2.6600635051727295, 2.6671030521392822, 2.6762475967407227, 2.684762716293335, 2.6969332695007324, 2.7074971199035645, 2.712131977081299, 2.7261767387390137, 2.7354302406311035, 2.7500088214874268, 2.7631983757019043, 2.7758872509002686, 2.7880501747131348, 2.7959699630737305, 2.812105178833008, 2.826749801635742, 2.8442671298980713, 2.8642330169677734, 2.879624605178833, 2.890336036682129, 2.9070849418640137, 2.9215869903564453, 2.935605525970459, 2.9446334838867188, 2.9642462730407715, 2.981632709503174, 2.9917683601379395, 2.9984002113342285, 3.014960527420044, 3.0285956859588623, 3.041738986968994, 3.05259370803833, 3.05910325050354, 3.069709300994873, 3.085114002227783, 3.0864968299865723, 3.101473808288574, 3.1103973388671875, 3.1193599700927734, 3.1315367221832275, 3.14304518699646, 3.147493600845337, 3.1555800437927246, 3.1617791652679443, 3.1644999980926514, 3.176710605621338, 3.1815004348754883, 3.1887879371643066, 3.1888480186462402, 3.186293125152588, 3.187520980834961, 3.187115430831909, 3.1844310760498047, 3.183685064315796, 3.1782002449035645, 3.174964189529419, 3.168727397918701, 3.1687421798706055, 3.166156053543091, 3.1631197929382324, 3.157212734222412, 3.1524438858032227, 3.1431949138641357, 3.133983850479126, 3.118194818496704, 3.105351209640503, 3.0952188968658447, 3.089082956314087, 3.078005313873291, 3.0626461505889893, 3.0467607975006104, 3.0322442054748535, 3.0249717235565186, 3.002817153930664, 2.9873263835906982, 2.975886583328247, 2.961573600769043, 2.9397220611572266, 2.9201974868774414, 2.9115493297576904, 2.8840861320495605, 2.8660531044006348, 2.843165874481201, 2.831991672515869, 2.8096401691436768, 2.790229082107544, 2.7596869468688965, 2.740621328353882, 2.719071626663208, 2.687030792236328, 2.671966552734375, 2.6517505645751953, 2.6251535415649414, 2.613771438598633, 2.5954480171203613, 2.5704920291900635, 2.767244338989258, 2.741663932800293, 2.7183690071105957, 2.7545359134674072, 2.7817187309265137, 2.7111451625823975, 2.7376773357391357, 2.7008235454559326, 2.6283679008483887, 2.7385523319244385, 2.6772103309631348, 2.711120367050171, 2.6500940322875977, 2.609090566635132, 2.6762845516204834, 2.6017792224884033, 2.567136764526367, 2.5859718322753906, 2.551950454711914, 2.5791542530059814, 2.5908775329589844, 2.569753408432007, 2.602057695388794, 2.5395150184631348, 2.496857166290283, 2.4646427631378174, 2.46250581741333, 2.4410529136657715, 2.413353443145752, 2.4684603214263916, 2.500609874725342, 2.41457200050354, 2.426438808441162, 2.496610164642334, 2.4288368225097656, 2.4297025203704834, 2.355734348297119, 2.3406500816345215, 2.3596978187561035, 2.3525519371032715, 2.3536570072174072, 2.326380491256714, 2.504558801651001, 2.367424964904785, 2.3342151641845703, 2.346614360809326, 2.2963457107543945, 2.2868499755859375, 2.319260597229004, 2.247405529022217, 2.407874822616577, 2.53560209274292, 2.357815742492676, 2.446488857269287, 2.3804931640625, 2.2708559036254883, 2.2160844802856445, 2.3001537322998047, 2.188636064529419, 2.237342357635498, 2.3872926235198975, 2.2686920166015625, 2.3642258644104004, 2.3229286670684814, 2.2767419815063477, 2.305485725402832, 2.3126180171966553, 2.3158621788024902, 2.3420543670654297, 2.320796012878418, 2.3659565448760986, 2.7430453300476074, 2.3281314373016357, 2.4223151206970215, 2.3021039962768555, 2.437615394592285, 2.36002254486084, 2.307670831680298, 2.32348370552063, 2.2823853492736816, 2.3490021228790283, 2.367267370223999, 2.307961940765381, 2.3535878658294678, 2.4896435737609863, 2.4395828247070312, 2.344243288040161, 2.26335072517395, 2.282881498336792, 2.285670757293701, 2.3748881816864014, 2.381255865097046, 2.3510496616363525, 2.356961727142334, 2.2868916988372803, 2.2723186016082764, 2.2423183917999268, 2.2660677433013916, 2.272118091583252, 2.236448049545288, 2.5053868293762207, 2.3143415451049805, 2.261688232421875, 2.3173811435699463, 2.2940993309020996, 2.2362430095672607, 2.2826104164123535, 2.2107574939727783, 2.2015185356140137, 2.2534916400909424, 2.2331655025482178, 2.3410768508911133, 2.301215171813965, 2.2386300563812256, 2.2686076164245605, 2.3739609718322754, 2.285224199295044, 2.2287747859954834, 2.18080997467041, 2.187727212905884, 2.3671436309814453, 2.300652503967285, 2.5161616802215576, 2.32196044921875, 2.569976568222046, 2.3106822967529297, 2.239067792892456, 2.2319324016571045, 2.321408748626709, 2.3015811443328857, 2.709411144256592, 2.4289143085479736, 2.3391265869140625, 2.450469970703125, 2.380213499069214, 2.326554775238037, 2.3883934020996094, 2.6154613494873047, 2.3220930099487305, 2.4184799194335938, 2.49611234664917, 2.4000141620635986, 2.5239970684051514, 2.316537380218506, 2.318831443786621, 2.367870807647705, 2.378952980041504, 2.2362983226776123, 2.428865909576416, 2.3333818912506104, 2.4889912605285645, 2.410594940185547, 2.458369731903076, 2.6063599586486816, 2.298011302947998, 2.430935859680176, 2.3882498741149902, 2.437549591064453, 2.2730207443237305, 2.3911688327789307, 2.3761041164398193, 2.226874351501465, 2.3469302654266357, 2.2670037746429443, 2.2156577110290527, 2.3123390674591064, 2.3462207317352295, 2.272665023803711, 2.322307586669922, 2.283367395401001, 2.3249897956848145, 2.283477783203125, 2.344219207763672, 2.2593517303466797, 2.210468053817749, 2.3317666053771973, 2.334031105041504, 2.2862470149993896, 2.1999948024749756, 2.260979175567627, 2.1979403495788574, 2.21223783493042, 2.2437973022460938, 2.2327353954315186, 2.2092251777648926, 2.2288410663604736, 2.2563085556030273, 2.187840461730957, 2.2081141471862793, 2.2709662914276123, 2.270299196243286, 2.2170400619506836, 2.2296271324157715, 2.1942243576049805, 2.2272496223449707, 2.218536376953125, 2.2180051803588867, 2.20171856880188, 2.211566686630249, 2.219712972640991, 2.224944591522217, 2.1948273181915283, 2.2218048572540283, 2.2218947410583496, 2.2006402015686035, 2.204638957977295, 2.1825413703918457, 2.1966915130615234, 2.1981143951416016, 2.249384641647339, 2.190105438232422, 2.2115631103515625, 2.193305253982544, 2.2314071655273438, 2.212918519973755, 2.2291746139526367, 2.200673818588257, 2.2193245887756348, 2.1845569610595703, 2.2236900329589844, 2.229719400405884, 2.2350878715515137, 2.2531418800354004, 2.230191469192505, 2.260535478591919, 2.2243735790252686, 2.212006092071533, 2.214690923690796, 2.2355215549468994, 2.214040994644165, 2.196488857269287, 2.225100517272949, 2.2330217361450195, 2.1966214179992676, 2.226264238357544, 2.2619380950927734, 2.2165474891662598, 2.2467408180236816, 2.243565559387207, 2.2350199222564697, 2.224813461303711, 2.2202117443084717, 2.2323036193847656, 2.228327751159668, 2.2367241382598877, 2.21636700630188, 2.2191274166107178, 2.2444097995758057, 2.2384700775146484, 2.2460131645202637, 2.211103916168213, 2.2264914512634277, 2.254140615463257, 2.233001470565796, 2.2353897094726562, 2.225130081176758, 2.2368993759155273, 2.224472999572754, 2.2460641860961914, 2.2280406951904297, 2.228567123413086, 2.2469491958618164, 2.247422218322754, 2.2348475456237793, 2.2329354286193848, 2.2399563789367676, 2.2360498905181885, 2.2537431716918945, 2.238389492034912, 2.234968662261963, 2.265281915664673, 2.250692844390869, 2.249457836151123, 2.248507261276245, 2.2393200397491455, 2.2286019325256348, 2.2372162342071533, 2.261667013168335, 2.246023416519165, 2.2446770668029785, 2.246779441833496, 2.2420616149902344, 2.241697311401367, 2.2300260066986084, 2.2456257343292236, 2.2334063053131104, 2.253540515899658, 2.2460482120513916, 2.240743398666382, 2.2592878341674805, 2.2493948936462402, 2.2352547645568848, 2.243492841720581, 2.2399322986602783, 2.270195960998535, 2.2505762577056885, 2.242065668106079, 2.2271015644073486, 2.2411508560180664, 2.2431015968322754, 2.2402215003967285, 2.2300405502319336, 2.2406280040740967, 2.2478435039520264, 2.2420825958251953, 2.242205858230591, 2.2454371452331543, 2.2670209407806396, 2.251027822494507, 2.254936695098877, 2.259648084640503, 2.2353413105010986, 2.2669780254364014, 2.2348859310150146, 2.252781629562378, 2.258065938949585, 2.2588000297546387, 2.251128911972046, 2.2784910202026367, 2.258000135421753, 2.236219882965088, 2.2390530109405518, 2.2451236248016357, 2.257498025894165, 2.2479987144470215, 2.2645061016082764, 2.2587599754333496, 2.248516798019409, 2.250760078430176, 2.2459142208099365, 2.2446115016937256, 2.245124340057373, 2.2577552795410156, 2.2465550899505615, 2.2509920597076416, 2.247500419616699, 2.246661901473999, 2.245241165161133, 2.2518513202667236, 2.2471113204956055, 2.2590956687927246, 2.2568862438201904, 2.248728036880493, 2.250817060470581, 2.261923313140869, 2.2675600051879883, 2.2442619800567627, 2.2593131065368652, 2.274697780609131, 2.270672559738159, 2.2674319744110107, 2.2542600631713867, 2.253746271133423, 2.2589452266693115, 2.2604832649230957, 2.260826587677002, 2.2554218769073486, 2.2695653438568115, 2.265888214111328, 2.281196117401123, 2.296243190765381, 2.275970458984375, 2.2665252685546875, 2.25620698928833, 2.2662296295166016, 2.2649893760681152, 2.267822504043579, 2.2921838760375977, 2.254821300506592, 2.254713296890259, 2.266101837158203, 2.2650914192199707, 2.2573506832122803, 2.2669448852539062, 2.2698795795440674, 2.26975154876709, 2.286773204803467, 2.2782421112060547, 2.2700891494750977, 2.2709126472473145, 2.2691361904144287, 2.2587368488311768, 2.257720470428467, 2.260493516921997, 2.272207021713257, 2.2560534477233887, 2.270517349243164, 2.2793948650360107, 2.2666068077087402, 2.269894599914551, 2.277696371078491, 2.2787888050079346, 2.2727019786834717, 2.2619471549987793, 2.2673163414001465, 2.274444818496704, 2.266624927520752, 2.2716500759124756, 2.278825283050537], 'val_accuracy': [0.078125, 0.0625, 0.0625, 0.078125, 0.109375, 0.125, 0.09375, 0.0625, 0.078125, 0.125, 0.09375, 0.125, 0.09375, 0.109375, 0.140625, 0.09375, 0.078125, 0.09375, 0.046875, 0.0625, 0.0625, 0.046875, 0.0625, 0.078125, 0.0625, 0.0625, 0.0625, 0.09375, 0.0625, 0.078125, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.078125, 0.078125, 0.078125, 0.078125, 0.078125, 0.078125, 0.09375, 0.09375, 0.09375, 0.09375, 0.09375, 0.09375, 0.09375, 0.09375, 0.09375, 0.09375, 0.109375, 0.09375, 0.09375, 0.09375, 0.09375, 0.09375, 0.09375, 0.09375, 0.078125, 0.078125, 0.09375, 0.109375, 0.125, 0.15625, 0.15625, 0.15625, 0.15625, 0.171875, 0.171875, 0.171875, 0.171875, 0.1875, 0.1875, 0.1875, 0.1875, 0.1875, 0.1875, 0.1875, 0.1875, 0.203125, 0.203125, 0.1875, 0.1875, 0.1875, 0.203125, 0.203125, 0.21875, 0.21875, 0.203125, 0.21875, 0.21875, 0.25, 0.234375, 0.234375, 0.234375, 0.234375, 0.234375, 0.234375, 0.09375, 0.078125, 0.109375, 0.109375, 0.09375, 0.125, 0.078125, 0.125, 0.15625, 0.125, 0.125, 0.15625, 0.1875, 0.234375, 0.171875, 0.1875, 0.171875, 0.171875, 0.203125, 0.1875, 0.15625, 0.21875, 0.1875, 0.234375, 0.265625, 0.234375, 0.203125, 0.234375, 0.21875, 0.21875, 0.109375, 0.234375, 0.1875, 0.234375, 0.1875, 0.203125, 0.203125, 0.21875, 0.21875, 0.21875, 0.234375, 0.296875, 0.1875, 0.25, 0.28125, 0.25, 0.265625, 0.28125, 0.203125, 0.296875, 0.203125, 0.171875, 0.21875, 0.1875, 0.234375, 0.28125, 0.265625, 0.25, 0.28125, 0.28125, 0.28125, 0.296875, 0.25, 0.25, 0.25, 0.265625, 0.25, 0.234375, 0.25, 0.25, 0.265625, 0.125, 0.203125, 0.234375, 0.265625, 0.234375, 0.28125, 0.28125, 0.265625, 0.265625, 0.234375, 0.296875, 0.25, 0.25, 0.21875, 0.21875, 0.296875, 0.28125, 0.25, 0.3125, 0.265625, 0.265625, 0.28125, 0.265625, 0.265625, 0.3125, 0.34375, 0.3125, 0.234375, 0.28125, 0.21875, 0.296875, 0.265625, 0.296875, 0.265625, 0.296875, 0.328125, 0.328125, 0.25, 0.265625, 0.28125, 0.234375, 0.28125, 0.25, 0.296875, 0.21875, 0.328125, 0.34375, 0.25, 0.3125, 0.203125, 0.28125, 0.203125, 0.25, 0.140625, 0.296875, 0.234375, 0.28125, 0.21875, 0.21875, 0.140625, 0.265625, 0.21875, 0.171875, 0.25, 0.28125, 0.234375, 0.171875, 0.21875, 0.21875, 0.125, 0.3125, 0.203125, 0.234375, 0.21875, 0.203125, 0.25, 0.296875, 0.25, 0.203125, 0.25, 0.25, 0.234375, 0.1875, 0.25, 0.25, 0.234375, 0.234375, 0.234375, 0.171875, 0.234375, 0.28125, 0.1875, 0.21875, 0.328125, 0.234375, 0.25, 0.234375, 0.21875, 0.25, 0.234375, 0.234375, 0.265625, 0.234375, 0.203125, 0.21875, 0.25, 0.25, 0.25, 0.234375, 0.328125, 0.28125, 0.234375, 0.296875, 0.265625, 0.25, 0.21875, 0.25, 0.265625, 0.28125, 0.265625, 0.28125, 0.25, 0.28125, 0.265625, 0.25, 0.265625, 0.265625, 0.3125, 0.28125, 0.25, 0.296875, 0.265625, 0.265625, 0.28125, 0.25, 0.296875, 0.265625, 0.3125, 0.25, 0.28125, 0.265625, 0.3125, 0.265625, 0.28125, 0.28125, 0.296875, 0.296875, 0.296875, 0.28125, 0.25, 0.265625, 0.25, 0.296875, 0.25, 0.328125, 0.3125, 0.3125, 0.28125, 0.28125, 0.3125, 0.265625, 0.3125, 0.296875, 0.328125, 0.3125, 0.265625, 0.25, 0.25, 0.296875, 0.234375, 0.296875, 0.265625, 0.296875, 0.296875, 0.25, 0.265625, 0.296875, 0.265625, 0.296875, 0.3125, 0.28125, 0.21875, 0.296875, 0.328125, 0.296875, 0.296875, 0.296875, 0.28125, 0.328125, 0.28125, 0.28125, 0.296875, 0.3125, 0.3125, 0.296875, 0.296875, 0.28125, 0.296875, 0.28125, 0.28125, 0.3125, 0.296875, 0.28125, 0.28125, 0.328125, 0.28125, 0.28125, 0.28125, 0.28125, 0.296875, 0.296875, 0.296875, 0.28125, 0.3125, 0.296875, 0.28125, 0.28125, 0.28125, 0.28125, 0.28125, 0.28125, 0.296875, 0.3125, 0.28125, 0.296875, 0.28125, 0.3125, 0.296875, 0.3125, 0.296875, 0.3125, 0.28125, 0.28125, 0.28125, 0.3125, 0.3125, 0.28125, 0.28125, 0.28125, 0.3125, 0.28125, 0.296875, 0.28125, 0.296875, 0.296875, 0.296875, 0.28125, 0.296875, 0.296875, 0.296875, 0.28125, 0.296875, 0.296875, 0.28125, 0.28125, 0.28125, 0.296875, 0.296875, 0.3125, 0.296875, 0.296875, 0.28125, 0.3125, 0.28125, 0.296875, 0.296875, 0.296875, 0.28125, 0.296875, 0.265625, 0.296875, 0.3125, 0.296875, 0.296875, 0.296875, 0.296875, 0.28125, 0.296875, 0.28125, 0.296875, 0.28125, 0.296875, 0.328125, 0.28125, 0.28125, 0.28125, 0.28125, 0.28125, 0.28125, 0.265625, 0.28125, 0.28125, 0.28125, 0.296875, 0.296875, 0.28125, 0.265625, 0.3125, 0.296875, 0.296875, 0.28125, 0.28125, 0.296875, 0.28125, 0.28125, 0.3125, 0.296875, 0.296875, 0.296875, 0.296875, 0.28125, 0.296875, 0.28125, 0.296875, 0.296875, 0.3125, 0.3125, 0.3125, 0.28125, 0.265625, 0.296875, 0.28125, 0.28125, 0.296875, 0.296875, 0.28125, 0.28125, 0.296875]}\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "print(hist_p.history)\n",
        "import matplotlib.pyplot as plt\n",
        "plt.plot(hist_p.history[\"loss\"])\n",
        "plt.plot(hist_p.history[\"val_loss\"])\n",
        "plt.show()\n",
        "\n",
        "plt.plot(hist_p.history[\"accuracy\"])\n",
        "plt.plot(hist_p.history[\"val_accuracy\"])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 551
        },
        "id": "d2Iq1o930PGb",
        "outputId": "bbfdfd04-09fb-4171-afd2-2170b7933da6",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': [2.8277809619903564, 2.0500166416168213, 1.5563673973083496, 1.2246882915496826, 0.9600787162780762, 0.7792167067527771, 0.598508894443512, 0.48421838879585266, 0.40808939933776855, 0.33944857120513916, 0.28316667675971985, 0.24336282908916473, 0.21202875673770905, 0.18740582466125488, 0.16797341406345367, 0.14847956597805023, 0.13781587779521942, 0.12678804993629456, 0.12020590156316757, 0.10366636514663696, 0.0952065959572792, 0.09234840422868729, 0.08719197660684586, 0.08366959542036057, 0.0765915960073471, 0.06990914046764374, 0.06788826733827591, 0.06379356980323792, 0.06282113492488861, 0.059471070766448975, 0.058786578476428986, 0.05788949131965637, 0.0536658875644207, 0.053079720586538315, 0.04855501651763916, 0.04671023041009903, 0.04341559112071991, 0.04412819817662239, 0.043681371957063675, 0.04139092564582825, 0.043306197971105576, 0.03834697604179382, 0.03684345632791519, 0.03689314052462578, 0.03556651249527931, 0.03465845808386803, 0.034067004919052124, 0.0324801541864872, 0.032304879277944565, 0.03145303949713707, 0.030988149344921112, 0.02975851483643055, 0.028520679101347923, 0.028762534260749817, 0.027919352054595947, 0.026690680533647537, 0.02678672783076763, 0.025991925969719887, 0.029080389067530632, 0.024962838739156723, 0.026595352217555046, 0.025258637964725494, 0.02429322898387909, 0.024927159771323204, 0.02330854907631874, 0.022280827164649963, 0.022058766335248947, 0.022264627739787102, 0.021397119387984276, 0.02285175956785679, 0.020644141361117363, 0.02061222307384014, 0.019694609567523003, 0.019556889310479164, 0.01889982633292675, 0.019902605563402176, 0.018840063363313675, 0.018964912742376328, 0.017610469833016396, 0.01738489419221878, 0.017110269516706467, 0.016777291893959045, 0.017505738884210587, 0.0166957788169384, 0.01735485903918743, 0.016176585108041763, 0.01614692248404026, 0.01632888987660408, 0.016099324449896812, 0.015338906086981297, 0.015336845070123672, 0.01557747833430767, 0.015054771676659584, 0.014813955873250961, 0.014624224044382572, 0.0142831327393651, 0.014317089691758156, 0.014249900355935097, 0.01464449055492878, 0.014118816703557968, 0.013871564529836178, 0.013329326175153255, 0.013764853589236736, 0.014039183035492897, 0.013240373693406582, 0.013161800801753998, 0.013323362916707993, 0.012657581828534603, 0.012762854807078838, 0.012314118444919586, 0.012519544921815395, 0.012572485022246838, 0.012345204129815102, 0.0124364597722888, 0.011614770628511906, 0.011571492999792099, 0.01181971374899149, 0.011342119425535202, 0.0115437563508749, 0.011716869659721851, 0.011677238158881664, 0.011122425086796284, 0.010821342468261719, 0.01156762894243002, 0.011317290365695953, 0.010260512121021748, 0.010803697630763054, 0.01047550793737173, 0.010324917733669281, 0.010812987573444843, 0.010488343425095081, 0.010057899169623852, 0.010213050991296768, 0.010268038138747215, 0.010028466582298279, 0.009901019744575024, 0.009723066352307796, 0.010099360719323158, 0.00977225974202156, 0.009684335440397263, 0.009287836961448193, 0.009602486155927181, 0.010274925269186497, 0.009190967306494713, 0.00910436362028122, 0.010119663551449776, 0.008832014165818691, 0.009162265807390213, 0.008803663775324821, 0.009334998205304146, 0.008947399444878101, 0.008587062358856201, 0.008513428270816803, 0.00861648004502058, 0.009088031947612762, 0.008930403739213943, 0.008720982819795609, 0.007878851145505905, 0.008392583578824997, 0.008477259427309036, 0.007793087977916002, 0.008466723375022411, 0.007991866208612919, 0.008172156289219856, 0.007697692606598139, 0.007860920391976833, 0.008013659156858921, 0.007637945003807545, 0.007913745008409023, 0.007611861918121576, 0.007960917428135872, 0.007450846489518881, 0.007832160219550133, 0.007488981820642948, 0.0078031099401414394, 0.007972635328769684, 0.0074509852565824986, 0.007333677727729082, 0.007153645157814026, 0.006938790902495384, 0.006878979969769716, 0.007410679943859577, 0.006930171977728605, 0.007182106375694275, 0.006756237242370844, 0.00715711759403348, 0.007384532131254673, 0.007069588638842106, 0.006805354729294777, 0.006857160944491625, 0.006581160239875317, 0.006720841862261295, 0.007191798184067011, 0.007033805828541517, 0.006644058506935835, 0.006528981029987335, 0.006497721653431654, 0.006517663598060608, 0.006393846124410629, 0.006486128084361553, 0.0061615509912371635, 0.0067838625982403755, 0.006218399852514267, 0.0060917288064956665, 0.006633227691054344, 0.006541874725371599, 0.006166708189994097, 0.006638013292104006, 0.00652658985927701, 0.006282523740082979, 0.006106178276240826, 0.006109153386205435, 0.006108140107244253, 0.006143838632851839, 0.005810762755572796, 0.006054390221834183, 0.00582868792116642, 0.006001965142786503, 0.0059821754693984985, 0.005923244636505842, 0.0056352801620960236, 0.005933266133069992, 0.0059868586249649525, 0.005682599265128374, 0.005710839293897152, 0.005893897730857134, 0.005685789510607719, 0.005617206916213036, 0.0056856777518987656, 0.005505326669663191, 0.005357761867344379, 0.005746255628764629, 0.005606547929346561, 0.005342621356248856, 0.00545537332072854, 0.005372267682105303, 0.005562779027968645, 0.0055542984046041965, 0.005247795023024082, 0.005364543758332729, 0.005357432644814253, 0.005159219726920128, 0.005082566291093826, 0.005302053410559893, 0.005914140958338976, 0.0055413637310266495, 0.00486306706443429, 0.004804745316505432, 0.005002261139452457, 0.005189619027078152, 0.005167700350284576, 0.005419382359832525, 0.005614715162664652, 0.005097740329802036, 0.005291691981256008, 0.005363599397242069, 0.005345722194761038, 0.005350927356630564, 0.004963386338204145, 0.004901669919490814, 0.004761356394737959, 0.004615556914359331, 0.004739772994071245, 0.0047963629476726055, 0.0046747406013309956, 0.004667504224926233, 0.004932143725454807, 0.0045787012204527855, 0.004773037042468786, 0.004902265965938568, 0.004411619156599045, 0.004762701690196991, 0.0045981258153915405, 0.004708311520516872, 0.004689258988946676, 0.004473110195249319, 0.004496205132454634, 0.004319368861615658, 0.004697142634540796, 0.004570654593408108, 0.004602960776537657, 0.004508596379309893, 0.00435475492849946, 0.004277992062270641, 0.004568161908537149, 0.00447829207405448, 0.004649737384170294, 0.004612342920154333, 0.004459583666175604, 0.0043702865950763226, 0.004316068720072508, 0.004368903581053019, 0.004266005475074053, 0.0042426404543221, 0.004134957678616047, 0.004053550772368908, 0.004179995507001877, 0.004304586909711361, 0.004249396733939648, 0.004235973581671715, 0.0043165674433112144, 0.004404307808727026, 0.004244384355843067, 0.003926559817045927, 0.003915059845894575, 0.0039858026430010796, 0.004259875975549221, 0.004159136209636927, 0.004004210699349642, 0.003978055436164141, 0.0038735864218324423, 0.003928801976144314, 0.004055888392031193, 0.003903911681845784, 0.0039791082963347435, 0.004465933423489332, 0.004100639373064041, 0.003895991249009967, 0.0037247552536427975, 0.003966870252043009, 0.0037748839240521193, 0.0037783293519169092, 0.003640059381723404, 0.00381280155852437, 0.003933666739612818, 0.004020241554826498, 0.0037919168826192617, 0.003708220086991787, 0.00378594477660954, 0.0038641479332000017, 0.0039003747515380383, 0.0036913882941007614, 0.003679842222481966, 0.003716596169397235, 0.003779911668971181, 0.0037457183934748173, 0.0037270020693540573, 0.003606728743761778, 0.003466956317424774, 0.0035558263771235943, 0.003709061536937952, 0.003706814954057336, 0.0035336739383637905, 0.003722798079252243, 0.0035865996032953262, 0.0037288847379386425, 0.003507434157654643, 0.0037848008796572685, 0.00391666404902935, 0.0034396371338516474, 0.003429324831813574, 0.003456142731010914, 0.003531268099322915, 0.0033336973283439875, 0.0035778952296823263, 0.003480144776403904, 0.0035160058178007603, 0.0034512635320425034, 0.0032704705372452736, 0.003542848164215684, 0.0035955728963017464, 0.0035989531315863132, 0.0032626078464090824, 0.003284759819507599, 0.0032192689832299948, 0.0032933091279119253, 0.0033650253899395466, 0.003143837908282876, 0.003477557795122266, 0.003191208466887474, 0.0034234020859003067, 0.0032069021835923195, 0.003392892424017191, 0.0033788050059229136, 0.0033672370482236147, 0.003373592859134078, 0.003440855536609888, 0.0032987650483846664, 0.003211751813068986, 0.0030649041291326284, 0.0032961724791675806, 0.0034123267978429794, 0.0032045128755271435, 0.003316625254228711, 0.0030656668823212385, 0.003177111502736807, 0.0031012536492198706, 0.0031323954463005066, 0.003147784387692809, 0.0033653753343969584, 0.003152904799208045, 0.00339883123524487, 0.003160815918818116, 0.0030657195020467043, 0.002966636326164007, 0.0030249892733991146, 0.003042043885216117, 0.003179356688633561, 0.003151011886075139, 0.00311842723749578, 0.003148271469399333, 0.0030477438122034073, 0.0030333083122968674, 0.0030063854064792395, 0.0030969344079494476, 0.0030004626605659723, 0.003190384479239583, 0.003090325277298689, 0.0031057687010616064, 0.0029178294353187084, 0.0029045946430414915, 0.0029938656371086836, 0.002888624556362629, 0.0028851605020463467, 0.0028073047287762165, 0.003098831744864583, 0.0027387570589780807, 0.003051481442525983, 0.002828051568940282, 0.0028460819739848375, 0.0029993397183716297, 0.0030624314676970243, 0.003272844012826681, 0.0028091189451515675, 0.0029743670020252466, 0.0028013228438794613, 0.002959860721603036, 0.0030795151833444834, 0.002804503543302417, 0.0027788460720330477, 0.002743854420259595, 0.0030167342629283667, 0.0027690809220075607, 0.002630408853292465, 0.00281138950958848, 0.0026465211994946003, 0.002879221923649311, 0.002761065261438489, 0.0026860630605369806, 0.002688065404072404, 0.0028105988167226315, 0.002817354863509536, 0.0028002141043543816, 0.002848641015589237, 0.002702370984479785, 0.002863117726519704, 0.002925954991951585, 0.002673575421795249, 0.0026220420841127634, 0.0026382668875157833, 0.0026273848488926888, 0.002635411685332656, 0.0028189020231366158, 0.002787549514323473, 0.0026965641882270575, 0.0025732452049851418, 0.0025392903480678797, 0.0026190292555838823, 0.0027559560257941484, 0.00256291963160038, 0.002889390802010894, 0.002739202929660678, 0.002576283412054181, 0.002579686464741826, 0.0027628468815237284, 0.0025933936703950167, 0.002691509434953332, 0.0024852347560226917, 0.002945409854874015, 0.002629578812047839, 0.0025842448230832815, 0.0024457371328026056, 0.0025526657700538635, 0.0025017692241817713, 0.002569548785686493, 0.002899013226851821, 0.002572267781943083, 0.002494239713996649, 0.002597781829535961, 0.0025110661517828703, 0.002354737836867571, 0.0026743514463305473, 0.0026452289894223213, 0.002805029973387718, 0.00248349760659039, 0.002537717577069998, 0.002539942506700754, 0.0024835593067109585, 0.002430284395813942, 0.002490393817424774, 0.002341590356081724, 0.0023870128206908703, 0.002398013835772872, 0.0025571389123797417, 0.0025558590423315763, 0.0025126615073531866, 0.0024378339294344187, 0.0021803416311740875, 0.002311074873432517, 0.002328535309061408], 'accuracy': [0.10176990926265717, 0.3495575189590454, 0.6327433586120605, 0.76106196641922, 0.8716813921928406, 0.9424778819084167, 0.9778761267662048, 0.982300877571106, 0.9955752491950989, 0.9955752491950989, 0.9955752491950989, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], 'val_loss': [2.6389312744140625, 2.642808675765991, 2.6431541442871094, 2.6459250450134277, 2.6516928672790527, 2.66007137298584, 2.666961431503296, 2.6765291690826416, 2.684227466583252, 2.6964645385742188, 2.707921266555786, 2.7127890586853027, 2.726201057434082, 2.7356553077697754, 2.749573230743408, 2.762876272201538, 2.7753217220306396, 2.7875797748565674, 2.795222759246826, 2.811509609222412, 2.825977325439453, 2.843590259552002, 2.862724781036377, 2.878497362136841, 2.8886666297912598, 2.906062126159668, 2.9217236042022705, 2.934751510620117, 2.945173978805542, 2.9625353813171387, 2.9803247451782227, 2.990438461303711, 2.998030185699463, 3.014519691467285, 3.029414176940918, 3.0429859161376953, 3.05399227142334, 3.061171770095825, 3.0721468925476074, 3.08792781829834, 3.090622901916504, 3.1046032905578613, 3.114899158477783, 3.123202323913574, 3.1381287574768066, 3.149625778198242, 3.1553421020507812, 3.164102077484131, 3.172301769256592, 3.1753504276275635, 3.188500165939331, 3.1923179626464844, 3.2031102180480957, 3.2024576663970947, 3.203707218170166, 3.2076125144958496, 3.207519054412842, 3.207779884338379, 3.2068214416503906, 3.204014301300049, 3.2004902362823486, 3.193819999694824, 3.1925048828125, 3.192753553390503, 3.1893081665039062, 3.1834425926208496, 3.180971145629883, 3.1698975563049316, 3.161008834838867, 3.150928258895874, 3.139431953430176, 3.1271724700927734, 3.1214699745178223, 3.1100335121154785, 3.0976674556732178, 3.0846967697143555, 3.0689785480499268, 3.059732437133789, 3.043391227722168, 3.0266942977905273, 3.0127768516540527, 2.9971604347229004, 2.980006217956543, 2.9626219272613525, 2.945432662963867, 2.9270315170288086, 2.913527011871338, 2.8858823776245117, 2.8715479373931885, 2.846226692199707, 2.8323655128479004, 2.7961742877960205, 2.783008098602295, 2.760964870452881, 2.7294039726257324, 2.712005376815796, 2.6935367584228516, 2.6706995964050293, 2.6508076190948486, 2.634045124053955, 2.6116886138916016, 2.5923144817352295, 2.567673683166504, 2.541621685028076, 2.528073310852051, 2.5110971927642822, 2.4950482845306396, 2.4705123901367188, 2.458678722381592, 2.432800054550171, 2.4169936180114746, 2.3999009132385254, 2.384643077850342, 2.3711018562316895, 2.349792957305908, 2.342144012451172, 2.330756187438965, 2.3150296211242676, 2.2995707988739014, 2.292123556137085, 2.28399658203125, 2.2749481201171875, 2.2643330097198486, 2.2564592361450195, 2.2464492321014404, 2.235508918762207, 2.225416898727417, 2.22114896774292, 2.210592746734619, 2.2042407989501953, 2.200770378112793, 2.2011303901672363, 2.1956405639648438, 2.1931235790252686, 2.187643527984619, 2.1818594932556152, 2.181147813796997, 2.1757891178131104, 2.1734180450439453, 2.167189121246338, 2.1626765727996826, 2.1602845191955566, 2.1554758548736572, 2.160017967224121, 2.1600799560546875, 2.1580615043640137, 2.154996633529663, 2.150705099105835, 2.14933180809021, 2.1448981761932373, 2.1456756591796875, 2.1443943977355957, 2.1442513465881348, 2.1439929008483887, 2.1444735527038574, 2.143618106842041, 2.1384177207946777, 2.138488531112671, 2.1397910118103027, 2.137040138244629, 2.140249729156494, 2.1386289596557617, 2.1373684406280518, 2.1388587951660156, 2.1390488147735596, 2.1369667053222656, 2.1401922702789307, 2.1392948627471924, 2.1380746364593506, 2.1407105922698975, 2.136300802230835, 2.138477087020874, 2.137261390686035, 2.1395342350006104, 2.138374090194702, 2.1365914344787598, 2.1393325328826904, 2.1432950496673584, 2.140577793121338, 2.140500783920288, 2.140925407409668, 2.14021897315979, 2.139706611633301, 2.1368532180786133, 2.1410367488861084, 2.141455888748169, 2.1391053199768066, 2.1414504051208496, 2.1419639587402344, 2.1438448429107666, 2.14239501953125, 2.1418206691741943, 2.145357131958008, 2.143441677093506, 2.1425437927246094, 2.1437244415283203, 2.141284704208374, 2.142099618911743, 2.142360210418701, 2.142805576324463, 2.142141580581665, 2.1406807899475098, 2.140082597732544, 2.1411595344543457, 2.139941692352295, 2.141110897064209, 2.137993812561035, 2.1393814086914062, 2.1383538246154785, 2.1401429176330566, 2.1418495178222656, 2.1395010948181152, 2.1409082412719727, 2.1443631649017334, 2.1438052654266357, 2.1417877674102783, 2.1449296474456787, 2.140603542327881, 2.14233660697937, 2.144683361053467, 2.1434082984924316, 2.145402431488037, 2.1464266777038574, 2.1501450538635254, 2.150702953338623, 2.1492843627929688, 2.1473045349121094, 2.147373914718628, 2.145827293395996, 2.143667459487915, 2.144601345062256, 2.1457369327545166, 2.144975423812866, 2.1446406841278076, 2.1442532539367676, 2.143252372741699, 2.14451265335083, 2.144613742828369, 2.1450464725494385, 2.144216537475586, 2.1478450298309326, 2.145413875579834, 2.1479179859161377, 2.1466588973999023, 2.1461195945739746, 2.1437957286834717, 2.1455328464508057, 2.1459646224975586, 2.1458263397216797, 2.145392894744873, 2.1463842391967773, 2.1443731784820557, 2.1441569328308105, 2.14371395111084, 2.1449546813964844, 2.140833616256714, 2.134660243988037, 2.1424660682678223, 2.143671751022339, 2.1456758975982666, 2.1469674110412598, 2.1456966400146484, 2.1462955474853516, 2.144155740737915, 2.1461117267608643, 2.144268751144409, 2.1466870307922363, 2.148498058319092, 2.1492559909820557, 2.1481869220733643, 2.148329257965088, 2.1476681232452393, 2.1472764015197754, 2.148118495941162, 2.14681077003479, 2.1466946601867676, 2.146273136138916, 2.147839069366455, 2.147770881652832, 2.1477162837982178, 2.1477808952331543, 2.1492955684661865, 2.150383949279785, 2.1502394676208496, 2.148102283477783, 2.148465633392334, 2.1456079483032227, 2.1481049060821533, 2.1450369358062744, 2.1452651023864746, 2.145737409591675, 2.1474030017852783, 2.1463565826416016, 2.147339105606079, 2.1477882862091064, 2.1481423377990723, 2.1483120918273926, 2.1488685607910156, 2.1484923362731934, 2.148468255996704, 2.1469106674194336, 2.149484634399414, 2.1499786376953125, 2.150552749633789, 2.150570869445801, 2.1514320373535156, 2.1502299308776855, 2.148625612258911, 2.1447274684906006, 2.1448473930358887, 2.1460189819335938, 2.1465189456939697, 2.1428093910217285, 2.143432855606079, 2.1459803581237793, 2.14424991607666, 2.1456422805786133, 2.1463985443115234, 2.148914098739624, 2.147085428237915, 2.1489169597625732, 2.1488728523254395, 2.1498115062713623, 2.1492795944213867, 2.1466708183288574, 2.147535562515259, 2.1499130725860596, 2.1495630741119385, 2.1498825550079346, 2.149319648742676, 2.149404525756836, 2.1467597484588623, 2.147465705871582, 2.1480798721313477, 2.1471548080444336, 2.147569179534912, 2.1486616134643555, 2.1468472480773926, 2.1480860710144043, 2.151041030883789, 2.1522035598754883, 2.152174472808838, 2.152660608291626, 2.151881456375122, 2.149890422821045, 2.150552272796631, 2.1501176357269287, 2.150949478149414, 2.1520204544067383, 2.1508798599243164, 2.149003744125366, 2.151101589202881, 2.150707960128784, 2.1496851444244385, 2.1485679149627686, 2.1504592895507812, 2.150329113006592, 2.149078130722046, 2.1494665145874023, 2.1511619091033936, 2.152714729309082, 2.1507272720336914, 2.1509413719177246, 2.1511316299438477, 2.1524910926818848, 2.1523804664611816, 2.1516590118408203, 2.153743028640747, 2.153581142425537, 2.1552000045776367, 2.1571898460388184, 2.157878875732422, 2.1572117805480957, 2.155121326446533, 2.1560287475585938, 2.154970645904541, 2.1538569927215576, 2.152364492416382, 2.1524908542633057, 2.1535093784332275, 2.154905319213867, 2.1531641483306885, 2.1535370349884033, 2.152482748031616, 2.152736186981201, 2.151702880859375, 2.1521191596984863, 2.1531243324279785, 2.1523518562316895, 2.153440475463867, 2.1546144485473633, 2.1542434692382812, 2.1538889408111572, 2.154085397720337, 2.154975652694702, 2.157383918762207, 2.1576976776123047, 2.1561434268951416, 2.1563310623168945, 2.156702756881714, 2.155792713165283, 2.1557905673980713, 2.1543917655944824, 2.1543776988983154, 2.151455879211426, 2.1519267559051514, 2.152111530303955, 2.153646469116211, 2.153881788253784, 2.1555166244506836, 2.1558499336242676, 2.1564009189605713, 2.1531331539154053, 2.1545705795288086, 2.1544482707977295, 2.155113458633423, 2.156008720397949, 2.1559643745422363, 2.155526876449585, 2.158416986465454, 2.1594858169555664, 2.157015323638916, 2.1550586223602295, 2.1551599502563477, 2.156682014465332, 2.1557466983795166, 2.1563141345977783, 2.157780408859253, 2.1568493843078613, 2.1576027870178223, 2.157940149307251, 2.157771110534668, 2.156714916229248, 2.156872034072876, 2.1552536487579346, 2.1556806564331055, 2.1570334434509277, 2.1547679901123047, 2.1552529335021973, 2.1545963287353516, 2.152817487716675, 2.154482364654541, 2.1539106369018555, 2.154005765914917, 2.154445171356201, 2.1554064750671387, 2.155137777328491, 2.153757095336914, 2.154553174972534, 2.155404567718506, 2.155550956726074, 2.155061960220337, 2.151571035385132, 2.1533315181732178, 2.1540660858154297, 2.154787302017212, 2.1553616523742676, 2.1545042991638184, 2.1540262699127197, 2.153301477432251, 2.154165744781494, 2.1523799896240234, 2.1529603004455566, 2.1537790298461914, 2.15614914894104, 2.1558845043182373, 2.1564700603485107, 2.1572766304016113, 2.159606456756592, 2.160155773162842, 2.157437324523926, 2.158109664916992, 2.158507823944092, 2.1582136154174805, 2.1580843925476074, 2.1591949462890625, 2.1614322662353516, 2.1617894172668457, 2.1614856719970703, 2.1610331535339355, 2.1608657836914062, 2.161090850830078, 2.1610305309295654, 2.1596617698669434, 2.1591875553131104, 2.1625168323516846, 2.161633014678955, 2.159924268722534, 2.1594910621643066, 2.160116672515869, 2.159982681274414, 2.1611876487731934, 2.1603784561157227, 2.158874750137329, 2.158602714538574, 2.1588082313537598, 2.1584830284118652, 2.1594433784484863, 2.1613385677337646, 2.161842107772827], 'val_accuracy': [0.078125, 0.0625, 0.0625, 0.078125, 0.09375, 0.125, 0.09375, 0.0625, 0.109375, 0.109375, 0.078125, 0.09375, 0.046875, 0.09375, 0.109375, 0.078125, 0.078125, 0.0625, 0.0625, 0.078125, 0.078125, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.09375, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.078125, 0.078125, 0.078125, 0.078125, 0.09375, 0.09375, 0.09375, 0.09375, 0.09375, 0.09375, 0.09375, 0.09375, 0.09375, 0.09375, 0.09375, 0.078125, 0.078125, 0.078125, 0.078125, 0.09375, 0.09375, 0.109375, 0.09375, 0.09375, 0.09375, 0.09375, 0.09375, 0.09375, 0.125, 0.125, 0.140625, 0.140625, 0.140625, 0.140625, 0.140625, 0.140625, 0.15625, 0.15625, 0.15625, 0.1875, 0.171875, 0.1875, 0.1875, 0.1875, 0.1875, 0.1875, 0.1875, 0.1875, 0.1875, 0.1875, 0.1875, 0.1875, 0.203125, 0.203125, 0.203125, 0.203125, 0.203125, 0.21875, 0.21875, 0.21875, 0.21875, 0.21875, 0.21875, 0.21875, 0.21875, 0.21875, 0.234375, 0.234375, 0.234375, 0.234375, 0.25, 0.25, 0.25, 0.234375, 0.234375, 0.25, 0.234375, 0.234375, 0.25, 0.25, 0.265625, 0.265625, 0.25, 0.25, 0.265625, 0.28125, 0.28125, 0.296875, 0.296875, 0.28125, 0.296875, 0.28125, 0.296875, 0.296875, 0.3125, 0.296875, 0.3125, 0.328125, 0.359375, 0.359375, 0.34375, 0.359375, 0.359375, 0.34375, 0.34375, 0.34375, 0.359375, 0.359375, 0.34375, 0.34375, 0.34375, 0.328125, 0.3125, 0.328125, 0.328125, 0.328125, 0.328125, 0.328125, 0.328125, 0.328125, 0.328125, 0.328125, 0.328125, 0.328125, 0.328125, 0.3125, 0.3125, 0.3125, 0.3125, 0.3125, 0.3125, 0.3125, 0.3125, 0.3125, 0.3125, 0.3125, 0.3125, 0.3125, 0.328125, 0.3125, 0.3125, 0.3125, 0.3125, 0.3125, 0.3125, 0.328125, 0.328125, 0.328125, 0.328125, 0.3125, 0.3125, 0.3125, 0.3125, 0.3125, 0.3125, 0.3125, 0.3125, 0.3125, 0.3125, 0.3125, 0.328125, 0.328125, 0.328125, 0.328125, 0.3125, 0.3125, 0.328125, 0.328125, 0.328125, 0.328125, 0.328125, 0.328125, 0.34375, 0.328125, 0.328125, 0.328125, 0.328125, 0.34375, 0.328125, 0.3125, 0.3125, 0.3125, 0.3125, 0.34375, 0.328125, 0.3125, 0.328125, 0.34375, 0.328125, 0.328125, 0.3125, 0.3125, 0.3125, 0.328125, 0.3125, 0.3125, 0.3125, 0.3125, 0.3125, 0.3125, 0.328125, 0.328125, 0.328125, 0.328125, 0.328125, 0.328125, 0.3125, 0.34375, 0.3125, 0.328125, 0.3125, 0.328125, 0.328125, 0.34375, 0.328125, 0.34375, 0.34375, 0.328125, 0.34375, 0.328125, 0.328125, 0.34375, 0.328125, 0.328125, 0.328125, 0.328125, 0.328125, 0.328125, 0.328125, 0.328125, 0.328125, 0.34375, 0.34375, 0.34375, 0.34375, 0.328125, 0.34375, 0.328125, 0.328125, 0.328125, 0.34375, 0.328125, 0.328125, 0.34375, 0.328125, 0.328125, 0.328125, 0.328125, 0.328125, 0.328125, 0.328125, 0.328125, 0.34375, 0.328125, 0.328125, 0.328125, 0.328125, 0.328125, 0.328125, 0.328125, 0.328125, 0.34375, 0.328125, 0.328125, 0.328125, 0.328125, 0.328125, 0.328125, 0.328125, 0.328125, 0.328125, 0.328125, 0.328125, 0.328125, 0.328125, 0.328125, 0.328125, 0.328125, 0.34375, 0.34375, 0.34375, 0.34375, 0.34375, 0.34375, 0.328125, 0.328125, 0.328125, 0.328125, 0.34375, 0.34375, 0.34375, 0.34375, 0.34375, 0.34375, 0.34375, 0.34375, 0.34375, 0.34375, 0.328125, 0.328125, 0.34375, 0.34375, 0.34375, 0.34375, 0.34375, 0.34375, 0.34375, 0.34375, 0.34375, 0.34375, 0.34375, 0.34375, 0.34375, 0.34375, 0.34375, 0.34375, 0.34375, 0.34375, 0.34375, 0.34375, 0.34375, 0.34375, 0.34375, 0.34375, 0.34375, 0.34375, 0.34375, 0.34375, 0.34375, 0.34375, 0.34375, 0.328125, 0.34375, 0.34375, 0.34375, 0.34375, 0.328125, 0.328125, 0.328125, 0.328125, 0.328125, 0.328125, 0.328125, 0.34375, 0.328125, 0.34375, 0.34375, 0.34375, 0.34375, 0.34375, 0.34375, 0.34375, 0.34375, 0.34375, 0.34375, 0.34375, 0.34375, 0.34375, 0.34375, 0.34375, 0.34375, 0.34375, 0.34375, 0.328125, 0.34375, 0.34375, 0.34375, 0.328125, 0.328125, 0.328125, 0.328125, 0.34375, 0.34375, 0.34375, 0.34375, 0.34375, 0.328125, 0.328125, 0.328125, 0.328125, 0.328125, 0.328125, 0.328125, 0.328125, 0.328125, 0.328125, 0.328125, 0.34375, 0.34375, 0.34375, 0.34375, 0.34375, 0.34375, 0.34375, 0.34375, 0.34375, 0.34375, 0.34375, 0.34375, 0.34375, 0.34375, 0.34375, 0.34375, 0.34375, 0.34375, 0.34375, 0.34375, 0.34375, 0.328125, 0.328125, 0.328125, 0.328125, 0.328125, 0.328125, 0.328125, 0.328125, 0.328125, 0.328125, 0.328125, 0.328125, 0.328125, 0.328125, 0.328125, 0.328125, 0.34375, 0.34375, 0.34375, 0.328125, 0.328125, 0.328125, 0.328125, 0.34375, 0.34375, 0.34375, 0.328125, 0.328125, 0.328125, 0.328125, 0.34375, 0.328125, 0.328125, 0.328125, 0.34375, 0.34375, 0.328125, 0.328125, 0.328125, 0.328125, 0.328125, 0.328125, 0.34375, 0.34375, 0.328125, 0.328125, 0.328125, 0.328125, 0.328125, 0.328125, 0.328125, 0.328125, 0.34375, 0.328125, 0.328125]}\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "print(hist_s.history)\n",
        "import matplotlib.pyplot as plt\n",
        "plt.plot(hist_s.history[\"loss\"])\n",
        "plt.plot(hist_s.history[\"val_loss\"])\n",
        "plt.show()\n",
        "\n",
        "\n",
        "plt.plot(hist_s.history[\"accuracy\"])\n",
        "plt.plot(hist_s.history[\"val_accuracy\"])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {
        "id": "VvIt3tKbQTvR",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "simple_model_file = 'simple_model.h5'\n",
        "tf.keras.models.save_model(model_simple, simple_model_file,\n",
        "                        include_optimizer=False)\n",
        "simple_model_file = 'pruned_0.h5'\n",
        "tf.keras.models.save_model(new_pruned_model_0, simple_model_file,\n",
        "                        include_optimizer=False)\n",
        "simple_model_file = 'pruned_1.h5'\n",
        "tf.keras.models.save_model(new_pruned_model_1, simple_model_file,\n",
        "                        include_optimizer=False)\n",
        "simple_model_file = 'pruned_2.h5'\n",
        "tf.keras.models.save_model(new_pruned_model_2, simple_model_file,\n",
        "                        include_optimizer=False)\n",
        "simple_model_file = 'pruned_3.h5'\n",
        "tf.keras.models.save_model(new_pruned_model_3, simple_model_file,\n",
        "                        include_optimizer=False)\n",
        "simple_model_file = 'pruned_4.h5'\n",
        "tf.keras.models.save_model(new_pruned_model_4, simple_model_file,\n",
        "                        include_optimizer=False)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "This code saves the \"model_simple\" model to a file called \"simple_model.h5\"\n",
        "using the TensorFlow's save_model function. The function takes two arguments, \n",
        "the first is the model to save and the second is the file name.\n",
        "The include_optimizer=False argument is passed to the save_model function,\n",
        "which means that the optimizer state will not be saved. This is useful when\n",
        "we want to load the model and use a different optimizer or set of optimizer\n",
        "hyperparameters.\n",
        "\n",
        "The .h5 file format is a popular format for storing deep learning models.\n",
        "It is supported by TensorFlow, Keras, and other deep learning libraries, \n",
        "and can be used to save the model's architecture, weights, and optimizer state.\n",
        "This allows us to save the model and then reload it later to use for inference or transfer learning.\n",
        "\n",
        "It is important to note that this will only save the architecture and\n",
        "weights of the model, not the optimizer or other state. If you want to \n",
        "save the optimizer state as well, you can set include_optimizer=True, \n",
        "but it will increase the size of the file.\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eMk2Xta67CAS",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {
        "id": "31rZ1O2-GTeP",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "model1=Model(model_simple.input, model_simple.output)\n",
        "model1=model_simple.layers[2].output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yRzESRc2QQ22"
      },
      "source": [
        "#Quatisation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {
        "id": "RjloLyrDQPSE",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "def quantModel(model, pathx):\n",
        "  model_file=\"q_temp.h5\"\n",
        "  tf.keras.models.save_model(model, model_file,\n",
        "                        include_optimizer=False)\n",
        "  converter = tf.compat.v1.lite.TFLiteConverter.from_keras_model_file(model_file)\n",
        "\n",
        "  converter.optimizations = [tf.compat.v1.lite.Optimize.OPTIMIZE_FOR_SIZE]\n",
        "\n",
        "  tflite_quant_model = converter.convert()\n",
        "\n",
        "  tflite_quant_model_file = pathx\n",
        "  with open(tflite_quant_model_file, 'wb') as f:\n",
        "    f.write(tflite_quant_model)\n",
        "\n",
        "\n",
        "\"\"\"\"\n",
        "This code defines a function called \"quantModel\" that takes in two arguments, \n",
        "\"model\" and \"pathx\". The function first saves the model to a file called\n",
        "\"q_temp.h5\" using the save_model function as described before.\n",
        "\n",
        "\n",
        "The function then creates an instance of the TensorFlow Lite (TFLite)\n",
        "Converter by calling the \"from_keras_model_file\" function and passing\n",
        "it the \"q_temp.h5\" file. The TFLite converter is used to convert the \n",
        "saved keras model to a TensorFlow Lite model file, which is a lightweight \n",
        "format for deploying models on mobile and embedded devices.\n",
        "\n",
        "The code then sets the \"optimizations\" parameter of the converter \n",
        "to \"tf.compat.v1.lite.Optimize.OPTIMIZE_FOR_SIZE\". This optimization \n",
        "will reduce the size of the model by quantizing the model's weights\n",
        "to 8-bit integers, which can significantly reduce the size of the \n",
        "model without significantly affecting its accuracy.\n",
        "\n",
        "The function then calls the \"convert()\" function of the converter \n",
        "to convert the model to TensorFlow Lite format and saves the resulting \n",
        "TensorFlow Lite model to a file specified by the pathx argument.\n",
        "\n",
        "This function can be used to convert the model to TensorFlow Lite\n",
        "format, and then the resulting tflite file can be used to deploy\n",
        "the model on mobile and embedded devices.\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "\n",
        "def eval_model(lite_file, x_test, y_test):\n",
        "  interpreter = tf.compat.v1.lite.Interpreter(model_path=str(lite_file))\n",
        "  interpreter.allocate_tensors()\n",
        "  input_index = interpreter.get_input_details()[0][\"index\"]\n",
        "  output_index = interpreter.get_output_details()[0][\"index\"]\n",
        "  total_seen = 0\n",
        "  num_correct = 0\n",
        "  for img, label in zip(x_test, y_test):\n",
        "    inp = img.reshape((1, 50, 50, 3))\n",
        "    total_seen += 1\n",
        "    interpreter.set_tensor(input_index, inp)\n",
        "    interpreter.invoke()\n",
        "    predictions = interpreter.get_tensor(output_index)\n",
        "    if np.argmax(predictions) == np.argmax(label):\n",
        "      num_correct += 1\n",
        "  return float(num_correct) / float(total_seen)\n",
        "\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "This code defines a function called \"eval_model\" that takes in three arguments:\n",
        "\"lite_file\", \"x_test\", and \"y_test\".\n",
        "\n",
        "The function first creates an instance of the TensorFlow Lite Interpreter\n",
        "by passing it the path of the TensorFlow Lite model file (lite_file). \n",
        "The interpreter is used to execute the TensorFlow Lite model on a given input.\n",
        "\n",
        "Then the function allocates the tensors and gets the indices of the input\n",
        "and output tensors of the TensorFlow Lite model.\n",
        "\n",
        "The function then runs a for loop over the \"x_test\" and \"y_test\" data, \n",
        "where it first reshapes the image to the expected input shape of the model.\n",
        "It then sets the input tensor of the interpreter to the reshaped image and invokes the interpreter to get the predictions.\n",
        "\n",
        "The function then compares the predicted label (argmax of predictions) \n",
        "with the true label (argmax of label) and increments the num_correct counter\n",
        "if they match.\n",
        "\n",
        "After all the images have been processed, the function calculates the \n",
        "accuracy by dividing the number of correctly classified images by the \n",
        "total number of images seen and returns the accuracy.\n",
        "\n",
        "This function can be used to evaluate the performance of a TensorFlow \n",
        "Lite model on a given test dataset, it returns the accuracy of the model\n",
        "on the test dataset.\n",
        "\n",
        "\"\"\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m1ARvf9eQNgT",
        "outputId": "44844369-c425-407d-ebf0-24bd85f32f2e",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
            "WARNING:absl:Optimization option OPTIMIZE_FOR_SIZE is deprecated, please use optimizations=[Optimize.DEFAULT] instead.\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 4 of 4). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Optimization option OPTIMIZE_FOR_SIZE is deprecated, please use optimizations=[Optimize.DEFAULT] instead.\n",
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
            "WARNING:absl:Optimization option OPTIMIZE_FOR_SIZE is deprecated, please use optimizations=[Optimize.DEFAULT] instead.\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 4 of 4). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Optimization option OPTIMIZE_FOR_SIZE is deprecated, please use optimizations=[Optimize.DEFAULT] instead.\n",
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
            "WARNING:absl:Optimization option OPTIMIZE_FOR_SIZE is deprecated, please use optimizations=[Optimize.DEFAULT] instead.\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 4 of 4). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Optimization option OPTIMIZE_FOR_SIZE is deprecated, please use optimizations=[Optimize.DEFAULT] instead.\n",
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
            "WARNING:absl:Optimization option OPTIMIZE_FOR_SIZE is deprecated, please use optimizations=[Optimize.DEFAULT] instead.\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 4 of 4). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Optimization option OPTIMIZE_FOR_SIZE is deprecated, please use optimizations=[Optimize.DEFAULT] instead.\n",
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
            "WARNING:absl:Optimization option OPTIMIZE_FOR_SIZE is deprecated, please use optimizations=[Optimize.DEFAULT] instead.\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 4 of 4). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Optimization option OPTIMIZE_FOR_SIZE is deprecated, please use optimizations=[Optimize.DEFAULT] instead.\n"
          ]
        }
      ],
      "source": [
        "quantModel(model_simple, \"lite_simple.tflite\")\n",
        "quantModel(new_pruned_model_0, \"lite_0.tflite\")\n",
        "quantModel(new_pruned_model_1, \"lite_1.tflite\")\n",
        "quantModel(new_pruned_model_2, \"lite_2.tflite\")\n",
        "quantModel(new_pruned_model_3, \"lite_3.tflite\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JekF4M_6Tjvu",
        "outputId": "c3855814-3076-4feb-dbf6-9c968385dd02",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.359375\n",
            "0.28125\n",
            "0.171875\n",
            "0.25\n",
            "0.109375\n"
          ]
        }
      ],
      "source": [
        "print(eval_model(\"lite_simple.tflite\", X_test_50, y_test))\n",
        "print(eval_model(\"lite_0.tflite\", X_test_50, y_test))\n",
        "print(eval_model(\"lite_1.tflite\", X_test_50, y_test))\n",
        "print(eval_model(\"lite_2.tflite\", X_test_50, y_test))\n",
        "print(eval_model(\"lite_3.tflite\", X_test_50, y_test))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "BZ7iMwBaz-Xh"
      },
      "source": [
        "# FLOPS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {
        "id": "t07A-D4k0ByB",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import load_model\n",
        "import keras.backend as K\n",
        "import numpy as np\n",
        "def get_flops(model):\n",
        "  model_file=\"for_flops.h5\"\n",
        "  tf.keras.models.save_model(model, model_file,\n",
        "                        include_optimizer=False)\n",
        "  run_meta = tf.compat.v1.RunMetadata()\n",
        "  with tf.compat.v1.Session(graph=tf.Graph()) as sess:\n",
        "    tf.compat.v1.keras.backend.set_session(sess)\n",
        "    net = load_model(model_file)\n",
        "    x=np.ones([50,50,3])\n",
        "    x_placeholder =  tf.compat.v1.placeholder(tf.float32, shape=(None,50,50,3))\n",
        "    y = net(x_placeholder)\n",
        "\n",
        "\n",
        "    #opts = tf.profiler.ProfileOptionBuilder.float_operation()\n",
        "    opts=tf.compat.v1.profiler.ProfileOptionBuilder.float_operation() \n",
        "    flops = tf.compat.v1.profiler.profile(sess.graph, run_meta=run_meta, cmd='op', options=opts)\n",
        "\n",
        "    opts = tf.compat.v1.profiler.ProfileOptionBuilder.trainable_variables_parameter()    \n",
        "    params = tf.compat.v1.profiler.profile(sess.graph, run_meta=run_meta, cmd='op', options=opts)\n",
        "\n",
        "    return flops.total_float_ops, params.total_parameters\n",
        "  \n",
        "  \n",
        "  \n",
        "  \n",
        "  \"\"\"\n",
        "  This code defines a function called \"get_flops\" that takes in one argument \n",
        "  \"model\". The function first saves the model to a file called \"for_flops.h5\"\n",
        "  using the save_model function as described before.\n",
        "\n",
        "The function then creates a new TensorFlow session and sets the Keras \n",
        "backend session to that session. It then loads the saved model using the\n",
        "load_model function.\n",
        "\n",
        "The function creates a placeholder for the input tensor, and runs the\n",
        "model on this placeholder with an input of shape (50,50,3) to get the output tensor.\n",
        "\n",
        "The function then uses the TensorFlow profiler to profile the computation\n",
        "graph and get the number of FLOPs (floating point operations) and the\n",
        "number of parameters of the model.\n",
        "\n",
        "The profiler is used to measure the total number of floating point \n",
        "operations required to execute the model on a given input. The number\n",
        "of FLOPs is stored in the variable \"flops.total_float_ops\"\n",
        "\n",
        "The profiler is also used to measure the total number of trainable \n",
        "parameters in the model. The number of parameters is stored in the\n",
        "variable \"params.total_parameters\"\n",
        "\n",
        "The function then returns the number of FLOPs and parameters of the model.\n",
        "\n",
        "This function can be used to get the number of FLOPs and the\n",
        "number of parameters of a given model, which can be used to\n",
        "measure the computational cost\n",
        "  \n",
        "  \"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aAjqcW2G1eNS",
        "outputId": "49bd252d-489a-4b7e-f6fa-3f69b625e64c",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/keras/layers/normalization/batch_normalization.py:514: _colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/profiler/internal/flops_registry.py:138: tensor_shape_from_node_def_name (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.tensor_shape_from_node_def_name`\n",
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
          ]
        }
      ],
      "source": [
        "s=get_flops(model_simple)\n",
        "p0=get_flops(new_pruned_model_0)\n",
        "p1=get_flops(new_pruned_model_1)\n",
        "p2=get_flops(new_pruned_model_2)\n",
        "p3=get_flops(new_pruned_model_3)\n",
        "p4=get_flops(new_pruned_model_4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cXTLVCCl3SoF",
        "outputId": "9f26fbc3-8426-407f-8adc-f52a9e6438c9",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(758485, 755278)\n",
            "(49149, 48362)\n",
            "(32901, 32264)\n",
            "(19047, 18570)\n",
            "(9054, 8737)\n",
            "(2634, 2477)\n"
          ]
        }
      ],
      "source": [
        "print(s)\n",
        "print(p0)\n",
        "print(p1)\n",
        "print(p2)\n",
        "print(p3)\n",
        "print(p4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RSwUoSoVMLjR",
        "outputId": "869b878f-b8db-40b9-9460-dc4ffc228b7c",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Size of the model: 2.93 Mb\n",
            "Size of the model: 0.23 Mb\n",
            "Size of the model: 0.17 Mb\n",
            "Size of the model: 0.12 Mb\n",
            "Size of the model: 0.08 Mb\n",
            "Size of the model: 0.06 Mb\n"
          ]
        }
      ],
      "source": [
        "def printsize(f_model):\n",
        "  print(\"Size of the model: %.2f Mb\" \n",
        "      % (os.path.getsize(f_model) / float(2**20)))\n",
        "\n",
        "printsize(\"simple_model.h5\")\n",
        "printsize(\"pruned_0.h5\")\n",
        "printsize(\"pruned_1.h5\")\n",
        "printsize(\"pruned_2.h5\")\n",
        "printsize(\"pruned_3.h5\")\n",
        "printsize(\"pruned_4.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IVfPLQxi3mH7",
        "outputId": "8b7edde7-640d-413a-9102-b9146eb29ca9",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Size of the model: 0.74 Mb\n",
            "Size of the model: 0.06 Mb\n",
            "Size of the model: 0.04 Mb\n",
            "Size of the model: 0.03 Mb\n",
            "Size of the model: 0.02 Mb\n"
          ]
        }
      ],
      "source": [
        "def printsize(f_model):\n",
        "  print(\"Size of the model: %.2f Mb\" \n",
        "      % (os.path.getsize(f_model) / float(2**20)))\n",
        "\n",
        "printsize(\"lite_simple.tflite\")\n",
        "printsize(\"lite_0.tflite\")\n",
        "printsize(\"lite_1.tflite\")\n",
        "printsize(\"lite_2.tflite\")\n",
        "printsize(\"lite_3.tflite\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "name": "AlexNet_Compression_Seedlings_dataset.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
